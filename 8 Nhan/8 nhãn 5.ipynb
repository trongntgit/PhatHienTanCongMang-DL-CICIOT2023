{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6126678,"sourceType":"datasetVersion","datasetId":3512311}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn import preprocessing\nfrom sklearn.cluster import DBSCAN\nfrom tabulate import tabulate\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split \nimport seaborn as sns\nimport numpy as np\n# importing required libraries for normalizing data\nfrom sklearn.preprocessing import StandardScaler,LabelBinarizer,MinMaxScaler\nfrom sklearn.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\n# representation of model layers\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score , classification_report\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\nimport joblib\nfrom sklearn.svm import SVC\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:49:30.570039Z","iopub.execute_input":"2025-05-01T15:49:30.570258Z","iopub.status.idle":"2025-05-01T15:49:45.478846Z","shell.execute_reply.started":"2025-05-01T15:49:30.570232Z","shell.execute_reply":"2025-05-01T15:49:45.478020Z"}},"outputs":[{"name":"stderr","text":"2025-05-01 15:49:33.775667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746114573.971555      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746114574.023800      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **ƒê·ªåC D·ªÆ LI·ªÜU 8 NH√ÉN**","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib.pyplot as plt\nimport cudf  # D√πng cuDF ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu nhanh h∆°n tr√™n GPU\nimport numpy as np\nfrom sklearn.utils import resample\n\n# ƒê·ªãnh nghƒ©a th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# H√†m √°nh x·∫° nh√£n th√†nh 8 nh√≥m\ndef change_label(df):\n    mapping = {\n        'DDoS-ICMP_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS',\n        'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-RSTFINFlood': 'DDoS',\n        'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n        'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n        'DDoS-HTTP_Flood': 'DDoS', 'DDoS-SlowLoris': 'DDoS',\n        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n        'DictionaryBruteForce': 'BruteForce',\n        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n        'BenignTraffic': 'BENIGN'\n    }\n    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n    return df\n\n# ƒê·ªçc d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c\ndata_dir = \"/kaggle/input/cic-iot-2023/\"\nfile_list = glob.glob(f\"{data_dir}*.csv\")[:134]  # L·∫•y t·ªëi ƒëa 134 file\n\n# Gi·ªõi h·∫°n t·ªëi ƒëa v√† t·ªëi thi·ªÉu 400,000 d√≤ng cho m·ªói nh√£n\nMAX_ROWS_PER_LABEL = 400_000\nMIN_ROWS_PER_LABEL = 400_000\nlabel_counts = {\n    \"DDoS\": 0, \"DoS\": 0, \"Recon\": 0, \"Spoofing\": 0,\n    \"BruteForce\": 0, \"Web-based\": 0, \"Mirai\": 0, \"BENIGN\": 0\n}  # Theo d√µi s·ªë d√≤ng c·ªßa t·ª´ng nh√£n\n\ndef read_file(filename, index):\n    try:\n        # ƒê·ªçc file CSV b·∫±ng cuDF\n        df = cudf.read_csv(filename)\n        \n        # Ki·ªÉm tra c·ªôt 'label'\n        if 'label' not in df.columns:\n            print(f\"‚ùå File {filename}: Kh√¥ng t√¨m th·∫•y c·ªôt 'label'!\")\n            return None\n        \n        # √Ånh x·∫° nh√£n th√†nh 8 nh√≥m\n        df = change_label(df)\n        \n        # L·ªçc d·ªØ li·ªáu d·ª±a tr√™n gi·ªõi h·∫°n 400K cho m·ªói nh√£n\n        valid_rows = []\n        unique_labels = df['label'].unique().to_pandas().tolist()\n        for label in unique_labels:\n            current_count = label_counts.get(label, 0)\n            remaining_quota = MAX_ROWS_PER_LABEL - current_count\n            \n            if remaining_quota <= 0:\n                print(f\"‚ö† Nh√£n {label} ƒë√£ ƒë·ªß {MAX_ROWS_PER_LABEL:,} d√≤ng, kh√¥ng ƒë·ªçc th√™m!\")\n                continue\n            \n            # L·∫•y c√°c d√≤ng thu·ªôc nh√£n n√†y\n            label_df = df[df['label'] == label]\n            rows_to_take = min(len(label_df), remaining_quota)\n            \n            if rows_to_take > 0:\n                valid_rows.append(label_df[:rows_to_take])\n                label_counts[label] = current_count + rows_to_take\n                print(f\"üìå Nh√£n {label}: Th√™m {rows_to_take:,} d√≤ng, t·ªïng c·ªông {label_counts[label]:,} d√≤ng\")\n        \n        # G·ªôp c√°c d√≤ng h·ª£p l·ªá\n        if valid_rows:\n            df_filtered = cudf.concat(valid_rows, ignore_index=True)\n            print(f\"üìå File {index}: Gi·ªØ {df_filtered.shape[0]:,} d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\")\n            return df_filtered\n        else:\n            print(f\"‚ö† File {index}: Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c gi·ªØ l·∫°i!\")\n            return None\n    except Exception as e:\n        print(f\"‚ùå L·ªói khi ƒë·ªçc file {filename}: {e}\")\n        return None\n\n# ƒê·ªçc tu·∫ßn t·ª± t·ª´ng file\ndfs = []\nfor idx, fname in enumerate(file_list):\n    df = read_file(fname, idx)\n    if df is not None:\n        dfs.append(df)\n\n# N·ªëi d·ªØ li·ªáu v√† x·ª≠ l√Ω c√¢n b·∫±ng\nif dfs:\n    df_full = cudf.concat(dfs, ignore_index=True)\n    print(f\"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi! K√≠ch th∆∞·ªõc: {df_full.shape}\")\n    print(f\"üìã Nh√£n duy nh·∫•t: {df_full['label'].unique().to_pandas().tolist()}\")\n    \n    # Chuy·ªÉn sang pandas ƒë·ªÉ x·ª≠ l√Ω oversampling\n    df_pandas = df_full.to_pandas()\n    \n    # Ki·ªÉm tra ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng\n    print(\"\\nüìã Ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng:\")\n    label_distribution = df_pandas[\"label\"].value_counts()\n    print(label_distribution)\n    \n    # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng\n    fig, ax = plt.subplots(figsize=(12, 6))\n    bars = ax.bar(label_distribution.index, label_distribution.values, color=['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow'])\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of 8 Labels (Before Oversampling)')\n    for bar in bars:\n        height = bar.get_height()\n        ax.annotate(f'{int(height):,}',\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', fontsize=10)\n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/label_distribution_before_oversampling.png')\n    plt.show()\n    \n    # Chu·∫©n b·ªã d·ªØ li·ªáu cho oversampling\n    balanced_dfs = []\n    unique_labels = df_pandas['label'].unique()\n    \n    # √Åp d·ª•ng oversampling th·ªß c√¥ng cho m·ªói nh√£n\n    for label in unique_labels:\n        label_df = df_pandas[df_pandas['label'] == label]\n        current_count = len(label_df)\n        \n        if current_count < MIN_ROWS_PER_LABEL:\n            # Oversampling b·∫±ng resample\n            oversampled_df = resample(\n                label_df,\n                replace=True,  # Cho ph√©p sao ch√©p m·∫´u\n                n_samples=MIN_ROWS_PER_LABEL,  # ƒê·∫°t 400K\n                random_state=42\n            )\n            print(f\"üìå Oversampling nh√£n {label}: T·ª´ {current_count:,} l√™n {MIN_ROWS_PER_LABEL:,} d√≤ng\")\n            balanced_dfs.append(oversampled_df)\n        else:\n            print(f\"üìå Nh√£n {label}: ƒê√£ c√≥ {current_count:,} d√≤ng, gi·ªØ nguy√™n\")\n            balanced_dfs.append(label_df)\n    \n    # G·ªôp d·ªØ li·ªáu ƒë√£ c√¢n b·∫±ng\n    df_balanced = pd.concat(balanced_dfs, ignore_index=True)\n    \n    # Chuy·ªÉn l·∫°i th√†nh cuDF ƒë·ªÉ ƒë·ªìng b·ªô\n    df_full = cudf.from_pandas(df_balanced)\n    \n    # Ki·ªÉm tra ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng\n    print(\"\\nüìã Ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng b·∫±ng oversampling:\")\n    balanced_label_distribution = df_full[\"label\"].value_counts().to_pandas()\n    print(balanced_label_distribution)\n    \n    # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng\n    fig, ax = plt.subplots(figsize=(12, 6))\n    bars = ax.bar(balanced_label_distribution.index, balanced_label_distribution.values, color=['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow'])\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of 8 Labels (After Oversampling)')\n    for bar in bars:\n        height = bar.get_height()\n        ax.annotate(f'{int(height):,}',\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', fontsize=10)\n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/label_distribution_after_oversampling.png')\n    plt.show()\n    \n    # # L∆∞u df_full ƒë√£ c√¢n b·∫±ng ƒë·ªÉ ki·ªÉm tra\n    # df_full.to_pandas().to_csv(f'{output_dir}/balanced_data_8labels.csv', index=False)\n    # print(f\"‚úÖ D·ªØ li·ªáu ƒë√£ c√¢n b·∫±ng v√† l∆∞u t·∫°i '{output_dir}/balanced_data_8labels.csv'\")\n    \nelse:\n    print(\"‚ö† Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c ƒë·ªçc th√†nh c√¥ng ho·∫∑c t·∫•t c·∫£ d·ªØ li·ªáu r·ªóng!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:50:40.129348Z","iopub.execute_input":"2025-05-01T15:50:40.129946Z","iopub.status.idle":"2025-05-01T15:51:30.547466Z","shell.execute_reply.started":"2025-05-01T15:50:40.129919Z","shell.execute_reply":"2025-05-01T15:51:30.546783Z"}},"outputs":[{"name":"stdout","text":"üìå Nh√£n Mirai: Th√™m 13,351 d√≤ng, t·ªïng c·ªông 13,351 d√≤ng\nüìå Nh√£n DDoS: Th√™m 174,841 d√≤ng, t·ªïng c·ªông 174,841 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,572 d√≤ng, t·ªïng c·ªông 2,572 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,645 d√≤ng, t·ªïng c·ªông 5,645 d√≤ng\nüìå Nh√£n DoS: Th√™m 41,221 d√≤ng, t·ªïng c·ªông 41,221 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,876 d√≤ng, t·ªïng c·ªông 1,876 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 55 d√≤ng\nüìå Nh√£n Web-based: Th√™m 105 d√≤ng, t·ªïng c·ªông 105 d√≤ng\nüìå File 0: Gi·ªØ 239,666 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Recon: Th√™m 1,888 d√≤ng, t·ªïng c·ªông 3,764 d√≤ng\nüìå Nh√£n DoS: Th√™m 41,933 d√≤ng, t·ªïng c·ªông 83,154 d√≤ng\nüìå Nh√£n DDoS: Th√™m 176,390 d√≤ng, t·ªïng c·ªông 351,231 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,615 d√≤ng, t·ªïng c·ªông 26,966 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,544 d√≤ng, t·ªïng c·ªông 5,116 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,778 d√≤ng, t·ªïng c·ªông 11,423 d√≤ng\nüìå Nh√£n Web-based: Th√™m 147 d√≤ng, t·ªïng c·ªông 252 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 125 d√≤ng\nüìå File 1: Gi·ªØ 242,365 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n DoS: Th√™m 40,184 d√≤ng, t·ªïng c·ªông 123,338 d√≤ng\nüìå Nh√£n DDoS: Th√™m 48,769 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,440 d√≤ng, t·ªïng c·ªông 16,863 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,116 d√≤ng, t·ªïng c·ªông 40,082 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,448 d√≤ng, t·ªïng c·ªông 7,564 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,780 d√≤ng, t·ªïng c·ªông 5,544 d√≤ng\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 368 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 194 d√≤ng\nüìå File 2: Gi·ªØ 111,922 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n DoS: Th√™m 38,499 d√≤ng, t·ªïng c·ªông 161,837 d√≤ng\nüìå Nh√£n Mirai: Th√™m 12,555 d√≤ng, t·ªïng c·ªông 52,637 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,416 d√≤ng, t·ªïng c·ªông 22,279 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,340 d√≤ng, t·ªïng c·ªông 9,904 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,621 d√≤ng, t·ªïng c·ªông 7,165 d√≤ng\nüìå Nh√£n Web-based: Th√™m 109 d√≤ng, t·ªïng c·ªông 477 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 256 d√≤ng\nüìå File 3: Gi·ªØ 60,602 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Mirai: Th√™m 12,916 d√≤ng, t·ªïng c·ªông 65,553 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,394 d√≤ng, t·ªïng c·ªông 27,673 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n DoS: Th√™m 40,054 d√≤ng, t·ªïng c·ªông 201,891 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,384 d√≤ng, t·ªïng c·ªông 12,288 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,751 d√≤ng, t·ªïng c·ªông 8,916 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 327 d√≤ng\nüìå Nh√£n Web-based: Th√™m 119 d√≤ng, t·ªïng c·ªông 596 d√≤ng\nüìå File 4: Gi·ªØ 62,689 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,881 d√≤ng, t·ªïng c·ªông 10,797 d√≤ng\nüìå Nh√£n DoS: Th√™m 44,363 d√≤ng, t·ªïng c·ªông 246,254 d√≤ng\nüìå Nh√£n Mirai: Th√™m 14,296 d√≤ng, t·ªïng c·ªông 79,849 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,967 d√≤ng, t·ªïng c·ªông 33,640 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,745 d√≤ng, t·ªïng c·ªông 15,033 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 398 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 728 d√≤ng\nüìå File 5: Gi·ªØ 69,455 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,595 d√≤ng, t·ªïng c·ªông 39,235 d√≤ng\nüìå Nh√£n DoS: Th√™m 41,313 d√≤ng, t·ªïng c·ªông 287,567 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,503 d√≤ng, t·ªïng c·ªông 93,352 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,439 d√≤ng, t·ªïng c·ªông 17,472 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,792 d√≤ng, t·ªïng c·ªông 12,589 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 458 d√≤ng\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 841 d√≤ng\nüìå File 6: Gi·ªØ 64,815 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n DoS: Th√™m 75,694 d√≤ng, t·ªïng c·ªông 363,261 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,570 d√≤ng, t·ªïng c·ªông 22,042 d√≤ng\nüìå Nh√£n Mirai: Th√™m 24,591 d√≤ng, t·ªïng c·ªông 117,943 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,369 d√≤ng, t·ªïng c·ªông 15,958 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 10,315 d√≤ng, t·ªïng c·ªông 49,550 d√≤ng\nüìå Nh√£n Web-based: Th√™m 218 d√≤ng, t·ªïng c·ªông 1,059 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 113 d√≤ng, t·ªïng c·ªông 571 d√≤ng\nüìå File 7: Gi·ªØ 118,870 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,507 d√≤ng, t·ªïng c·ªông 60,057 d√≤ng\nüìå Nh√£n DoS: Th√™m 36,739 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\nüìå Nh√£n Mirai: Th√™m 25,726 d√≤ng, t·ªïng c·ªông 143,669 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,515 d√≤ng, t·ªïng c·ªông 19,473 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,731 d√≤ng, t·ªïng c·ªông 26,773 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 133 d√≤ng, t·ªïng c·ªông 704 d√≤ng\nüìå Nh√£n Web-based: Th√™m 238 d√≤ng, t·ªïng c·ªông 1,297 d√≤ng\nüìå File 8: Gi·ªØ 81,589 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 14,721 d√≤ng, t·ªïng c·ªông 158,390 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 6,171 d√≤ng, t·ªïng c·ªông 66,228 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,676 d√≤ng, t·ªïng c·ªông 29,449 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,036 d√≤ng, t·ªïng c·ªông 21,509 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 91 d√≤ng, t·ªïng c·ªông 795 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 1,440 d√≤ng\nüìå File 9: Gi·ªØ 25,838 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,570 d√≤ng, t·ªïng c·ªông 71,798 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,343 d√≤ng, t·ªïng c·ªông 171,733 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,808 d√≤ng, t·ªïng c·ªông 23,317 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,418 d√≤ng, t·ªïng c·ªông 31,867 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 1,555 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 860 d√≤ng\nüìå File 10: Gi·ªØ 23,319 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,096 d√≤ng, t·ªïng c·ªông 184,829 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,773 d√≤ng, t·ªïng c·ªông 25,090 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,409 d√≤ng, t·ªïng c·ªông 34,276 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,460 d√≤ng, t·ªïng c·ªông 77,258 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 923 d√≤ng\nüìå Nh√£n Web-based: Th√™m 119 d√≤ng, t·ªïng c·ªông 1,674 d√≤ng\nüìå File 11: Gi·ªØ 22,920 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,036 d√≤ng, t·ªïng c·ªông 197,865 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,432 d√≤ng, t·ªïng c·ªông 82,690 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,797 d√≤ng, t·ªïng c·ªông 26,887 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,467 d√≤ng, t·ªïng c·ªông 36,743 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 1,806 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 983 d√≤ng\nüìå File 12: Gi·ªØ 22,924 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,255 d√≤ng, t·ªïng c·ªông 92,945 d√≤ng\nüìå Nh√£n Mirai: Th√™m 24,651 d√≤ng, t·ªïng c·ªông 222,516 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,506 d√≤ng, t·ªïng c·ªông 41,249 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,300 d√≤ng, t·ªïng c·ªông 30,187 d√≤ng\nüìå Nh√£n Web-based: Th√™m 231 d√≤ng, t·ªïng c·ªông 2,037 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 116 d√≤ng, t·ªïng c·ªông 1,099 d√≤ng\nüìå File 13: Gi·ªØ 43,059 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,337 d√≤ng, t·ªïng c·ªông 235,853 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,740 d√≤ng, t·ªïng c·ªông 31,927 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,526 d√≤ng, t·ªïng c·ªông 98,471 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,448 d√≤ng, t·ªïng c·ªông 43,697 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 1,156 d√≤ng\nüìå Nh√£n Web-based: Th√™m 112 d√≤ng, t·ªïng c·ªông 2,149 d√≤ng\nüìå File 14: Gi·ªØ 23,220 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Mirai: Th√™m 13,949 d√≤ng, t·ªïng c·ªông 249,802 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,622 d√≤ng, t·ªïng c·ªông 46,319 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,774 d√≤ng, t·ªïng c·ªông 104,245 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,816 d√≤ng, t·ªïng c·ªông 33,743 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 58 d√≤ng, t·ªïng c·ªông 1,214 d√≤ng\nüìå Nh√£n Web-based: Th√™m 127 d√≤ng, t·ªïng c·ªông 2,276 d√≤ng\nüìå File 15: Gi·ªØ 24,346 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 25,078 d√≤ng, t·ªïng c·ªông 274,880 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,341 d√≤ng, t·ªïng c·ªông 114,586 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,581 d√≤ng, t·ªïng c·ªông 50,900 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,366 d√≤ng, t·ªïng c·ªông 37,109 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 139 d√≤ng, t·ªïng c·ªông 1,353 d√≤ng\nüìå Nh√£n Web-based: Th√™m 222 d√≤ng, t·ªïng c·ªông 2,498 d√≤ng\nüìå File 16: Gi·ªØ 43,727 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 6,034 d√≤ng, t·ªïng c·ªông 120,620 d√≤ng\nüìå Nh√£n Mirai: Th√™m 14,294 d√≤ng, t·ªïng c·ªông 289,174 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,915 d√≤ng, t·ªïng c·ªông 39,024 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,595 d√≤ng, t·ªïng c·ªông 53,495 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 1,425 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 2,638 d√≤ng\nüìå File 17: Gi·ªØ 25,050 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,400 d√≤ng, t·ªïng c·ªông 126,020 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,322 d√≤ng, t·ªïng c·ªông 302,496 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,742 d√≤ng, t·ªïng c·ªông 40,766 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,473 d√≤ng, t·ªïng c·ªông 55,968 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 1,480 d√≤ng\nüìå Nh√£n Web-based: Th√™m 125 d√≤ng, t·ªïng c·ªông 2,763 d√≤ng\nüìå File 18: Gi·ªØ 23,117 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,604 d√≤ng, t·ªïng c·ªông 316,100 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,478 d√≤ng, t·ªïng c·ªông 58,446 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,680 d√≤ng, t·ªïng c·ªông 131,700 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,832 d√≤ng, t·ªïng c·ªông 42,598 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 1,537 d√≤ng\nüìå Nh√£n Web-based: Th√™m 129 d√≤ng, t·ªïng c·ªông 2,892 d√≤ng\nüìå File 19: Gi·ªØ 23,780 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 11,949 d√≤ng, t·ªïng c·ªông 328,049 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 4,886 d√≤ng, t·ªïng c·ªông 136,586 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,606 d√≤ng, t·ªïng c·ªông 44,204 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,214 d√≤ng, t·ªïng c·ªông 60,660 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 1,604 d√≤ng\nüìå Nh√£n Web-based: Th√™m 103 d√≤ng, t·ªïng c·ªông 2,995 d√≤ng\nüìå File 20: Gi·ªØ 20,825 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 14,224 d√≤ng, t·ªïng c·ªông 342,273 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,716 d√≤ng, t·ªïng c·ªông 63,376 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,906 d√≤ng, t·ªïng c·ªông 142,492 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,001 d√≤ng, t·ªïng c·ªông 46,205 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 1,682 d√≤ng\nüìå Nh√£n Web-based: Th√™m 148 d√≤ng, t·ªïng c·ªông 3,143 d√≤ng\nüìå File 21: Gi·ªØ 25,073 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Mirai: Th√™m 15,456 d√≤ng, t·ªïng c·ªông 357,729 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,090 d√≤ng, t·ªïng c·ªông 48,295 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,905 d√≤ng, t·ªïng c·ªông 66,281 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 6,387 d√≤ng, t·ªïng c·ªông 148,879 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 3,265 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 92 d√≤ng, t·ªïng c·ªông 1,774 d√≤ng\nüìå File 22: Gi·ªØ 27,052 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,753 d√≤ng, t·ªïng c·ªông 50,048 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,082 d√≤ng, t·ªïng c·ªông 370,811 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,397 d√≤ng, t·ªïng c·ªông 154,276 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 1,838 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,376 d√≤ng, t·ªïng c·ªông 68,657 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 3,380 d√≤ng\nüìå File 23: Gi·ªØ 22,787 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 24,392 d√≤ng, t·ªïng c·ªông 395,203 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 10,210 d√≤ng, t·ªïng c·ªông 164,486 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,478 d√≤ng, t·ªïng c·ªông 73,135 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,429 d√≤ng, t·ªïng c·ªông 53,477 d√≤ng\nüìå Nh√£n Web-based: Th√™m 235 d√≤ng, t·ªïng c·ªông 3,615 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 128 d√≤ng, t·ªïng c·ªông 1,966 d√≤ng\nüìå File 24: Gi·ªØ 42,872 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 4,797 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,209 d√≤ng, t·ªïng c·ªông 75,344 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,158 d√≤ng, t·ªïng c·ªông 169,644 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,662 d√≤ng, t·ªïng c·ªông 55,139 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 3,732 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 2,036 d√≤ng\nüìå File 25: Gi·ªØ 14,013 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,864 d√≤ng, t·ªïng c·ªông 57,003 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,519 d√≤ng, t·ªïng c·ªông 77,863 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,609 d√≤ng, t·ªïng c·ªông 175,253 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 2,110 d√≤ng\nüìå Nh√£n Web-based: Th√™m 133 d√≤ng, t·ªïng c·ªông 3,865 d√≤ng\nüìå File 26: Gi·ªØ 10,199 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,447 d√≤ng, t·ªïng c·ªông 180,700 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,687 d√≤ng, t·ªïng c·ªông 58,690 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,309 d√≤ng, t·ªïng c·ªông 80,172 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 2,174 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 4,002 d√≤ng\nüìå File 27: Gi·ªØ 9,644 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,519 d√≤ng, t·ªïng c·ªông 82,691 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,830 d√≤ng, t·ªïng c·ªông 60,520 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,519 d√≤ng, t·ªïng c·ªông 186,219 d√≤ng\nüìå Nh√£n Web-based: Th√™m 131 d√≤ng, t·ªïng c·ªông 4,133 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 2,244 d√≤ng\nüìå File 28: Gi·ªØ 10,069 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,563 d√≤ng, t·ªïng c·ªông 196,782 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,245 d√≤ng, t·ªïng c·ªông 63,765 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,583 d√≤ng, t·ªïng c·ªông 87,274 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 118 d√≤ng, t·ªïng c·ªông 2,362 d√≤ng\nüìå Nh√£n Web-based: Th√™m 206 d√≤ng, t·ªïng c·ªông 4,339 d√≤ng\nüìå File 29: Gi·ªØ 18,715 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Spoofing: Th√™m 4,541 d√≤ng, t·ªïng c·ªông 91,815 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,566 d√≤ng, t·ªïng c·ªông 207,348 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,297 d√≤ng, t·ªïng c·ªông 67,062 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 127 d√≤ng, t·ªïng c·ªông 2,489 d√≤ng\nüìå Nh√£n Web-based: Th√™m 240 d√≤ng, t·ªïng c·ªông 4,579 d√≤ng\nüìå File 30: Gi·ªØ 18,771 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,432 d√≤ng, t·ªïng c·ªông 212,780 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,755 d√≤ng, t·ªïng c·ªông 68,817 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,403 d√≤ng, t·ªïng c·ªông 94,218 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 2,549 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 4,705 d√≤ng\nüìå File 31: Gi·ªØ 9,776 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,175 d√≤ng, t·ªïng c·ªông 217,955 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,256 d√≤ng, t·ªïng c·ªông 96,474 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,713 d√≤ng, t·ªïng c·ªông 70,530 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 2,626 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 4,844 d√≤ng\nüìå File 32: Gi·ªØ 9,360 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,221 d√≤ng, t·ªïng c·ªông 223,176 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,398 d√≤ng, t·ªïng c·ªông 98,872 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,636 d√≤ng, t·ªïng c·ªông 72,166 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 53 d√≤ng, t·ªïng c·ªông 2,679 d√≤ng\nüìå Nh√£n Web-based: Th√™m 134 d√≤ng, t·ªïng c·ªông 4,978 d√≤ng\nüìå File 33: Gi·ªØ 9,442 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,345 d√≤ng, t·ªïng c·ªông 228,521 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,820 d√≤ng, t·ªïng c·ªông 73,986 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,485 d√≤ng, t·ªïng c·ªông 101,357 d√≤ng\nüìå Nh√£n Web-based: Th√™m 98 d√≤ng, t·ªïng c·ªông 5,076 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 2,734 d√≤ng\nüìå File 34: Gi·ªØ 9,803 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,227 d√≤ng, t·ªïng c·ªông 238,748 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,382 d√≤ng, t·ªïng c·ªông 77,368 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,433 d√≤ng, t·ªïng c·ªông 105,790 d√≤ng\nüìå Nh√£n Web-based: Th√™m 243 d√≤ng, t·ªïng c·ªông 5,319 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 114 d√≤ng, t·ªïng c·ªông 2,848 d√≤ng\nüìå File 35: Gi·ªØ 18,399 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,481 d√≤ng, t·ªïng c·ªông 244,229 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,435 d√≤ng, t·ªïng c·ªông 108,225 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,744 d√≤ng, t·ªïng c·ªông 79,112 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 5,458 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 79 d√≤ng, t·ªïng c·ªông 2,927 d√≤ng\nüìå File 36: Gi·ªØ 9,878 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,163 d√≤ng, t·ªïng c·ªông 249,392 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,698 d√≤ng, t·ªïng c·ªông 80,810 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,311 d√≤ng, t·ªïng c·ªông 110,536 d√≤ng\nüìå Nh√£n Web-based: Th√™m 133 d√≤ng, t·ªïng c·ªông 5,591 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 2,989 d√≤ng\nüìå File 37: Gi·ªØ 9,367 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,845 d√≤ng, t·ªïng c·ªông 82,655 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,838 d√≤ng, t·ªïng c·ªông 255,230 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,582 d√≤ng, t·ªïng c·ªông 113,118 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 3,056 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 5,708 d√≤ng\nüìå File 38: Gi·ªØ 10,449 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 6,490 d√≤ng, t·ªïng c·ªông 261,720 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,106 d√≤ng, t·ªïng c·ªông 84,761 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,926 d√≤ng, t·ªïng c·ªông 116,044 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 3,129 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 5,848 d√≤ng\nüìå File 39: Gi·ªØ 11,735 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,722 d√≤ng, t·ªïng c·ªông 86,483 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,317 d√≤ng, t·ªïng c·ªông 267,037 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,335 d√≤ng, t·ªïng c·ªông 118,379 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 5,987 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 56 d√≤ng, t·ªïng c·ªông 3,185 d√≤ng\nüìå File 40: Gi·ªØ 9,569 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,451 d√≤ng, t·ªïng c·ªông 120,830 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,608 d√≤ng, t·ªïng c·ªông 272,645 d√≤ng\nüìå Nh√£n Web-based: Th√™m 123 d√≤ng, t·ªïng c·ªông 6,110 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,804 d√≤ng, t·ªïng c·ªông 88,287 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 3,250 d√≤ng\nüìå File 41: Gi·ªØ 10,051 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Spoofing: Th√™m 4,557 d√≤ng, t·ªïng c·ªông 125,387 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,348 d√≤ng, t·ªïng c·ªông 282,993 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,231 d√≤ng, t·ªïng c·ªông 91,518 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 232 d√≤ng, t·ªïng c·ªông 6,342 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 140 d√≤ng, t·ªïng c·ªông 3,390 d√≤ng\nüìå File 42: Gi·ªØ 18,508 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 3,462 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,464 d√≤ng, t·ªïng c·ªông 127,851 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,656 d√≤ng, t·ªïng c·ªông 288,649 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,843 d√≤ng, t·ªïng c·ªông 93,361 d√≤ng\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 6,470 d√≤ng\nüìå File 43: Gi·ªØ 10,163 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,367 d√≤ng, t·ªïng c·ªông 130,218 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,291 d√≤ng, t·ªïng c·ªông 293,940 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,639 d√≤ng, t·ªïng c·ªông 95,000 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 59 d√≤ng, t·ªïng c·ªông 3,521 d√≤ng\nüìå Nh√£n Web-based: Th√™m 119 d√≤ng, t·ªïng c·ªông 6,589 d√≤ng\nüìå File 44: Gi·ªØ 9,475 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,390 d√≤ng, t·ªïng c·ªông 299,330 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,345 d√≤ng, t·ªïng c·ªông 132,563 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,746 d√≤ng, t·ªïng c·ªông 96,746 d√≤ng\nüìå Nh√£n Web-based: Th√™m 155 d√≤ng, t·ªïng c·ªông 6,744 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 56 d√≤ng, t·ªïng c·ªông 3,577 d√≤ng\nüìå File 45: Gi·ªØ 9,692 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,699 d√≤ng, t·ªïng c·ªông 98,445 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,270 d√≤ng, t·ªïng c·ªông 134,833 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,199 d√≤ng, t·ªïng c·ªông 304,529 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 6,874 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 3,640 d√≤ng\nüìå File 46: Gi·ªØ 9,361 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,694 d√≤ng, t·ªïng c·ªông 139,527 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 10,417 d√≤ng, t·ªïng c·ªông 314,946 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,326 d√≤ng, t·ªïng c·ªông 101,771 d√≤ng\nüìå Nh√£n Web-based: Th√™m 249 d√≤ng, t·ªïng c·ªông 7,123 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 122 d√≤ng, t·ªïng c·ªông 3,762 d√≤ng\nüìå File 47: Gi·ªØ 18,808 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,656 d√≤ng, t·ªïng c·ªông 320,602 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,837 d√≤ng, t·ªïng c·ªông 103,608 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,431 d√≤ng, t·ªïng c·ªông 141,958 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 3,831 d√≤ng\nüìå Nh√£n Web-based: Th√™m 149 d√≤ng, t·ªïng c·ªông 7,272 d√≤ng\nüìå File 48: Gi·ªØ 10,142 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,779 d√≤ng, t·ªïng c·ªông 326,381 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,913 d√≤ng, t·ªïng c·ªông 105,521 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,497 d√≤ng, t·ªïng c·ªông 144,455 d√≤ng\nüìå Nh√£n Web-based: Th√™m 133 d√≤ng, t·ªïng c·ªông 7,405 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 3,896 d√≤ng\nüìå File 49: Gi·ªØ 10,387 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,874 d√≤ng, t·ªïng c·ªông 332,255 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,563 d√≤ng, t·ªïng c·ªông 147,018 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,759 d√≤ng, t·ªïng c·ªông 107,280 d√≤ng\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 7,540 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 3,950 d√≤ng\nüìå File 50: Gi·ªØ 10,385 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,325 d√≤ng, t·ªïng c·ªông 337,580 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,378 d√≤ng, t·ªïng c·ªông 149,396 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,714 d√≤ng, t·ªïng c·ªông 108,994 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 7,679 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 45 d√≤ng, t·ªïng c·ªông 3,995 d√≤ng\nüìå File 51: Gi·ªØ 9,601 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,200 d√≤ng, t·ªïng c·ªông 342,780 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,259 d√≤ng, t·ªïng c·ªông 151,655 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,629 d√≤ng, t·ªïng c·ªông 110,623 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 4,052 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 7,801 d√≤ng\nüìå File 52: Gi·ªØ 9,267 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,708 d√≤ng, t·ªïng c·ªông 112,331 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,467 d√≤ng, t·ªïng c·ªông 154,122 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,395 d√≤ng, t·ªïng c·ªông 348,175 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 4,114 d√≤ng\nüìå Nh√£n Web-based: Th√™m 118 d√≤ng, t·ªïng c·ªông 7,919 d√≤ng\nüìå File 53: Gi·ªØ 9,750 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,311 d√≤ng, t·ªïng c·ªông 156,433 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,463 d√≤ng, t·ªïng c·ªông 353,638 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,742 d√≤ng, t·ªïng c·ªông 114,073 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 8,040 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 52 d√≤ng, t·ªïng c·ªông 4,166 d√≤ng\nüìå File 54: Gi·ªØ 9,689 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,559 d√≤ng, t·ªïng c·ªông 359,197 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,459 d√≤ng, t·ªïng c·ªông 158,892 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,746 d√≤ng, t·ªïng c·ªông 115,819 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 8,172 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 4,243 d√≤ng\nüìå File 55: Gi·ªØ 9,973 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,421 d√≤ng, t·ªïng c·ªông 161,313 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,529 d√≤ng, t·ªïng c·ªông 364,726 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,731 d√≤ng, t·ªïng c·ªông 117,550 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 8,293 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 4,312 d√≤ng\nüìå File 56: Gi·ªØ 9,871 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,213 d√≤ng, t·ªïng c·ªông 369,939 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,719 d√≤ng, t·ªïng c·ªông 119,269 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,324 d√≤ng, t·ªïng c·ªông 163,637 d√≤ng\nüìå Nh√£n Web-based: Th√™m 103 d√≤ng, t·ªïng c·ªông 8,396 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 4,377 d√≤ng\nüìå File 57: Gi·ªØ 9,424 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,612 d√≤ng, t·ªïng c·ªông 120,881 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,186 d√≤ng, t·ªïng c·ªông 375,125 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,259 d√≤ng, t·ªïng c·ªông 165,896 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 8,511 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 50 d√≤ng, t·ªïng c·ªông 4,427 d√≤ng\nüìå File 58: Gi·ªØ 9,222 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 6,051 d√≤ng, t·ªïng c·ªông 381,176 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,935 d√≤ng, t·ªïng c·ªông 122,816 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,713 d√≤ng, t·ªïng c·ªông 168,609 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 48 d√≤ng, t·ªïng c·ªông 4,475 d√≤ng\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 8,641 d√≤ng\nüìå File 59: Gi·ªØ 10,877 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Recon: Th√™m 3,317 d√≤ng, t·ªïng c·ªông 126,133 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,568 d√≤ng, t·ªïng c·ªông 391,744 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,521 d√≤ng, t·ªïng c·ªông 173,130 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 120 d√≤ng, t·ªïng c·ªông 4,595 d√≤ng\nüìå Nh√£n Web-based: Th√™m 239 d√≤ng, t·ªïng c·ªông 8,880 d√≤ng\nüìå File 60: Gi·ªØ 18,765 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,430 d√≤ng, t·ªïng c·ªông 397,174 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,456 d√≤ng, t·ªïng c·ªông 175,586 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,823 d√≤ng, t·ªïng c·ªông 127,956 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 4,665 d√≤ng\nüìå Nh√£n Web-based: Th√™m 124 d√≤ng, t·ªïng c·ªông 9,004 d√≤ng\nüìå File 61: Gi·ªØ 9,903 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 2,826 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,752 d√≤ng, t·ªïng c·ªông 129,708 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,372 d√≤ng, t·ªïng c·ªông 177,958 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 4,719 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 9,125 d√≤ng\nüìå File 62: Gi·ªØ 7,125 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,561 d√≤ng, t·ªïng c·ªông 180,519 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,858 d√≤ng, t·ªïng c·ªông 131,566 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 87 d√≤ng, t·ªïng c·ªông 4,806 d√≤ng\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 9,255 d√≤ng\nüìå File 63: Gi·ªØ 4,636 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,382 d√≤ng, t·ªïng c·ªông 182,901 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,753 d√≤ng, t·ªïng c·ªông 133,319 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 9,370 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 4,868 d√≤ng\nüìå File 64: Gi·ªØ 4,312 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,717 d√≤ng, t·ªïng c·ªông 185,618 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,948 d√≤ng, t·ªïng c·ªông 135,267 d√≤ng\nüìå Nh√£n Web-based: Th√™m 103 d√≤ng, t·ªïng c·ªông 9,473 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 4,932 d√≤ng\nüìå File 65: Gi·ªØ 4,832 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,798 d√≤ng, t·ªïng c·ªông 137,065 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,468 d√≤ng, t·ªïng c·ªông 188,086 d√≤ng\nüìå Nh√£n Web-based: Th√™m 151 d√≤ng, t·ªïng c·ªông 9,624 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 5,003 d√≤ng\nüìå File 66: Gi·ªØ 4,488 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,751 d√≤ng, t·ªïng c·ªông 138,816 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,375 d√≤ng, t·ªïng c·ªông 190,461 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 123 d√≤ng, t·ªïng c·ªông 9,747 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 75 d√≤ng, t·ªïng c·ªông 5,078 d√≤ng\nüìå File 67: Gi·ªØ 4,324 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,307 d√≤ng, t·ªïng c·ªông 192,768 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,730 d√≤ng, t·ªïng c·ªông 140,546 d√≤ng\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 9,875 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 53 d√≤ng, t·ªïng c·ªông 5,131 d√≤ng\nüìå File 68: Gi·ªØ 4,218 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,324 d√≤ng, t·ªïng c·ªông 195,092 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,732 d√≤ng, t·ªïng c·ªông 142,278 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 82 d√≤ng, t·ªïng c·ªông 5,213 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 9,990 d√≤ng\nüìå File 69: Gi·ªØ 4,253 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,390 d√≤ng, t·ªïng c·ªông 197,482 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 5,275 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,762 d√≤ng, t·ªïng c·ªông 144,040 d√≤ng\nüìå Nh√£n Web-based: Th√™m 118 d√≤ng, t·ªïng c·ªông 10,108 d√≤ng\nüìå File 70: Gi·ªØ 4,332 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,690 d√≤ng, t·ªïng c·ªông 202,172 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,381 d√≤ng, t·ªïng c·ªông 147,421 d√≤ng\nüìå Nh√£n Web-based: Th√™m 261 d√≤ng, t·ªïng c·ªông 10,369 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 117 d√≤ng, t·ªïng c·ªông 5,392 d√≤ng\nüìå File 71: Gi·ªØ 8,449 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,495 d√≤ng, t·ªïng c·ªông 204,667 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,839 d√≤ng, t·ªïng c·ªông 149,260 d√≤ng\nüìå Nh√£n Web-based: Th√™m 129 d√≤ng, t·ªïng c·ªông 10,498 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 61 d√≤ng, t·ªïng c·ªông 5,453 d√≤ng\nüìå File 72: Gi·ªØ 4,524 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,677 d√≤ng, t·ªïng c·ªông 209,344 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,417 d√≤ng, t·ªïng c·ªông 152,677 d√≤ng\nüìå Nh√£n Web-based: Th√™m 239 d√≤ng, t·ªïng c·ªông 10,737 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 120 d√≤ng, t·ªïng c·ªông 5,573 d√≤ng\nüìå File 73: Gi·ªØ 8,453 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,692 d√≤ng, t·ªïng c·ªông 214,036 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,435 d√≤ng, t·ªïng c·ªông 156,112 d√≤ng\nüìå Nh√£n Web-based: Th√™m 232 d√≤ng, t·ªïng c·ªông 10,969 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 117 d√≤ng, t·ªïng c·ªông 5,690 d√≤ng\nüìå File 74: Gi·ªØ 8,476 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,740 d√≤ng, t·ªïng c·ªông 157,852 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,490 d√≤ng, t·ªïng c·ªông 216,526 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 11,106 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 61 d√≤ng, t·ªïng c·ªông 5,751 d√≤ng\nüìå File 75: Gi·ªØ 4,428 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,531 d√≤ng, t·ªïng c·ªông 219,057 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,773 d√≤ng, t·ªïng c·ªông 159,625 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 11,249 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 5,813 d√≤ng\nüìå File 76: Gi·ªØ 4,509 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,443 d√≤ng, t·ªïng c·ªông 221,500 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,796 d√≤ng, t·ªïng c·ªông 161,421 d√≤ng\nüìå Nh√£n Web-based: Th√™m 150 d√≤ng, t·ªïng c·ªông 11,399 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 5,878 d√≤ng\nüìå File 77: Gi·ªØ 4,454 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,550 d√≤ng, t·ªïng c·ªông 224,050 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,778 d√≤ng, t·ªïng c·ªông 163,199 d√≤ng\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 11,527 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 5,943 d√≤ng\nüìå File 78: Gi·ªØ 4,521 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,752 d√≤ng, t·ªïng c·ªông 164,951 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,383 d√≤ng, t·ªïng c·ªông 226,433 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 76 d√≤ng, t·ªïng c·ªông 6,019 d√≤ng\nüìå Nh√£n Web-based: Th√™m 136 d√≤ng, t·ªïng c·ªông 11,663 d√≤ng\nüìå File 79: Gi·ªØ 4,347 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,421 d√≤ng, t·ªïng c·ªông 228,854 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,821 d√≤ng, t·ªïng c·ªông 166,772 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 59 d√≤ng, t·ªïng c·ªông 6,078 d√≤ng\nüìå Nh√£n Web-based: Th√™m 105 d√≤ng, t·ªïng c·ªông 11,768 d√≤ng\nüìå File 80: Gi·ªØ 4,406 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,333 d√≤ng, t·ªïng c·ªông 231,187 d√≤ng\nüìå Nh√£n Web-based: Th√™m 114 d√≤ng, t·ªïng c·ªông 11,882 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,745 d√≤ng, t·ªïng c·ªông 168,517 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 6,132 d√≤ng\nüìå File 81: Gi·ªØ 4,246 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,285 d√≤ng, t·ªïng c·ªông 233,472 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,661 d√≤ng, t·ªïng c·ªông 170,178 d√≤ng\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 11,995 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 6,200 d√≤ng\nüìå File 82: Gi·ªØ 4,127 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,406 d√≤ng, t·ªïng c·ªông 235,878 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,729 d√≤ng, t·ªïng c·ªông 171,907 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 12,112 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 88 d√≤ng, t·ªïng c·ªông 6,288 d√≤ng\nüìå File 83: Gi·ªØ 4,340 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,746 d√≤ng, t·ªïng c·ªông 240,624 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,458 d√≤ng, t·ªïng c·ªông 175,365 d√≤ng\nüìå Nh√£n Web-based: Th√™m 269 d√≤ng, t·ªïng c·ªông 12,381 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 141 d√≤ng, t·ªïng c·ªông 6,429 d√≤ng\nüìå File 84: Gi·ªØ 8,614 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,534 d√≤ng, t·ªïng c·ªông 243,158 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,823 d√≤ng, t·ªïng c·ªông 177,188 d√≤ng\nüìå Nh√£n Web-based: Th√™m 146 d√≤ng, t·ªïng c·ªông 12,527 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 6,499 d√≤ng\nüìå File 85: Gi·ªØ 4,573 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,860 d√≤ng, t·ªïng c·ªông 179,048 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,444 d√≤ng, t·ªïng c·ªông 245,602 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 12,662 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 6,556 d√≤ng\nüìå File 86: Gi·ªØ 4,496 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,906 d√≤ng, t·ªïng c·ªông 180,954 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,585 d√≤ng, t·ªïng c·ªông 248,187 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 12,797 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 6,616 d√≤ng\nüìå File 87: Gi·ªØ 4,686 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,529 d√≤ng, t·ªïng c·ªông 184,483 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,713 d√≤ng, t·ªïng c·ªông 252,900 d√≤ng\nüìå Nh√£n Web-based: Th√™m 244 d√≤ng, t·ªïng c·ªông 13,041 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 135 d√≤ng, t·ªïng c·ªông 6,751 d√≤ng\nüìå File 88: Gi·ªØ 8,621 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,864 d√≤ng, t·ªïng c·ªông 186,347 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,685 d√≤ng, t·ªïng c·ªông 255,585 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 6,822 d√≤ng\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 13,176 d√≤ng\nüìå File 89: Gi·ªØ 4,755 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,436 d√≤ng, t·ªïng c·ªông 189,783 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,561 d√≤ng, t·ªïng c·ªông 260,146 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 125 d√≤ng, t·ªïng c·ªông 6,947 d√≤ng\nüìå Nh√£n Web-based: Th√™m 227 d√≤ng, t·ªïng c·ªông 13,403 d√≤ng\nüìå File 90: Gi·ªØ 8,349 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 7,013 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,695 d√≤ng, t·ªïng c·ªông 191,478 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,277 d√≤ng, t·ªïng c·ªông 262,423 d√≤ng\nüìå Nh√£n Web-based: Th√™m 108 d√≤ng, t·ªïng c·ªông 13,511 d√≤ng\nüìå File 91: Gi·ªØ 4,146 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,652 d√≤ng, t·ªïng c·ªông 265,075 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 7,091 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,873 d√≤ng, t·ªïng c·ªông 193,351 d√≤ng\nüìå Nh√£n Web-based: Th√™m 120 d√≤ng, t·ªïng c·ªông 13,631 d√≤ng\nüìå File 92: Gi·ªØ 4,723 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,508 d√≤ng, t·ªïng c·ªông 267,583 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,883 d√≤ng, t·ªïng c·ªông 195,234 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 13,763 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 7,165 d√≤ng\nüìå File 93: Gi·ªØ 4,597 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 13,884 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,440 d√≤ng, t·ªïng c·ªông 270,023 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,682 d√≤ng, t·ªïng c·ªông 196,916 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 7,234 d√≤ng\nüìå File 94: Gi·ªØ 4,312 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,543 d√≤ng, t·ªïng c·ªông 200,459 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,630 d√≤ng, t·ªïng c·ªông 274,653 d√≤ng\nüìå Nh√£n Web-based: Th√™m 249 d√≤ng, t·ªïng c·ªông 14,133 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 129 d√≤ng, t·ªïng c·ªông 7,363 d√≤ng\nüìå File 95: Gi·ªØ 8,551 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,287 d√≤ng, t·ªïng c·ªông 203,746 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,659 d√≤ng, t·ªïng c·ªông 279,312 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 104 d√≤ng, t·ªïng c·ªông 7,467 d√≤ng\nüìå Nh√£n Web-based: Th√™m 219 d√≤ng, t·ªïng c·ªông 14,352 d√≤ng\nüìå File 96: Gi·ªØ 8,269 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,779 d√≤ng, t·ªïng c·ªông 205,525 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,350 d√≤ng, t·ªïng c·ªông 281,662 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 7,540 d√≤ng\nüìå Nh√£n Web-based: Th√™m 127 d√≤ng, t·ªïng c·ªông 14,479 d√≤ng\nüìå File 97: Gi·ªØ 4,329 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 14,609 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,522 d√≤ng, t·ªïng c·ªông 284,184 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,693 d√≤ng, t·ªïng c·ªông 207,218 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 7,594 d√≤ng\nüìå File 98: Gi·ªØ 4,399 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,668 d√≤ng, t·ªïng c·ªông 286,852 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,917 d√≤ng, t·ªïng c·ªông 209,135 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 7,658 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 14,749 d√≤ng\nüìå File 99: Gi·ªØ 4,789 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,397 d√≤ng, t·ªïng c·ªông 289,249 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,792 d√≤ng, t·ªïng c·ªông 210,927 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 14,877 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 52 d√≤ng, t·ªïng c·ªông 7,710 d√≤ng\nüìå File 100: Gi·ªØ 4,369 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,398 d√≤ng, t·ªïng c·ªông 291,647 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 14,999 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,707 d√≤ng, t·ªïng c·ªông 212,634 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 7,767 d√≤ng\nüìå File 101: Gi·ªØ 4,284 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,539 d√≤ng, t·ªïng c·ªông 294,186 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,860 d√≤ng, t·ªïng c·ªông 214,494 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 15,136 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 7,830 d√≤ng\nüìå File 102: Gi·ªØ 4,599 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,918 d√≤ng, t·ªïng c·ªông 216,412 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,486 d√≤ng, t·ªïng c·ªông 296,672 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 15,262 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 80 d√≤ng, t·ªïng c·ªông 7,910 d√≤ng\nüìå File 103: Gi·ªØ 4,610 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,645 d√≤ng, t·ªïng c·ªông 301,317 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,325 d√≤ng, t·ªïng c·ªông 219,737 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 131 d√≤ng, t·ªïng c·ªông 8,041 d√≤ng\nüìå Nh√£n Web-based: Th√™m 263 d√≤ng, t·ªïng c·ªông 15,525 d√≤ng\nüìå File 104: Gi·ªØ 8,364 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,757 d√≤ng, t·ªïng c·ªông 304,074 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,007 d√≤ng, t·ªïng c·ªông 221,744 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 8,114 d√≤ng\nüìå Nh√£n Web-based: Th√™m 146 d√≤ng, t·ªïng c·ªông 15,671 d√≤ng\nüìå File 105: Gi·ªØ 4,983 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,773 d√≤ng, t·ªïng c·ªông 223,517 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,488 d√≤ng, t·ªïng c·ªông 306,562 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 125 d√≤ng, t·ªïng c·ªông 15,796 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 58 d√≤ng, t·ªïng c·ªông 8,172 d√≤ng\nüìå File 106: Gi·ªØ 4,444 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,740 d√≤ng, t·ªïng c·ªông 225,257 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,393 d√≤ng, t·ªïng c·ªông 308,955 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 8,226 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 15,928 d√≤ng\nüìå File 107: Gi·ªØ 4,319 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,796 d√≤ng, t·ªïng c·ªông 311,751 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,034 d√≤ng, t·ªïng c·ªông 227,291 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 16,071 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 8,299 d√≤ng\nüìå File 108: Gi·ªØ 5,046 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,880 d√≤ng, t·ªïng c·ªông 229,171 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,614 d√≤ng, t·ªïng c·ªông 314,365 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 16,193 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 8,367 d√≤ng\nüìå File 109: Gi·ªØ 4,684 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,586 d√≤ng, t·ªïng c·ªông 316,951 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,899 d√≤ng, t·ªïng c·ªông 231,070 d√≤ng\nüìå Nh√£n Web-based: Th√™m 131 d√≤ng, t·ªïng c·ªông 16,324 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 8,438 d√≤ng\nüìå File 110: Gi·ªØ 4,687 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,563 d√≤ng, t·ªïng c·ªông 319,514 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,837 d√≤ng, t·ªïng c·ªông 232,907 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 8,515 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 16,450 d√≤ng\nüìå File 111: Gi·ªØ 4,603 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,422 d√≤ng, t·ªïng c·ªông 321,936 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,851 d√≤ng, t·ªïng c·ªông 234,758 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 56 d√≤ng, t·ªïng c·ªông 8,571 d√≤ng\nüìå Nh√£n Web-based: Th√™m 109 d√≤ng, t·ªïng c·ªông 16,559 d√≤ng\nüìå File 112: Gi·ªØ 4,438 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,782 d√≤ng, t·ªïng c·ªông 236,540 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,476 d√≤ng, t·ªïng c·ªông 324,412 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 8,639 d√≤ng\nüìå Nh√£n Web-based: Th√™m 124 d√≤ng, t·ªïng c·ªông 16,683 d√≤ng\nüìå File 113: Gi·ªØ 4,450 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Spoofing: Th√™m 2,639 d√≤ng, t·ªïng c·ªông 327,051 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,849 d√≤ng, t·ªïng c·ªông 238,389 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 8,706 d√≤ng\nüìå Nh√£n Web-based: Th√™m 136 d√≤ng, t·ªïng c·ªông 16,819 d√≤ng\nüìå File 114: Gi·ªØ 4,691 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,513 d√≤ng, t·ªïng c·ªông 329,564 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,895 d√≤ng, t·ªïng c·ªông 240,284 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 8,774 d√≤ng\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 16,935 d√≤ng\nüìå File 115: Gi·ªØ 4,592 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,696 d√≤ng, t·ªïng c·ªông 241,980 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,259 d√≤ng, t·ªïng c·ªông 331,823 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 17,065 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 8,839 d√≤ng\nüìå File 116: Gi·ªØ 4,150 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,703 d√≤ng, t·ªïng c·ªông 336,526 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,340 d√≤ng, t·ªïng c·ªông 245,320 d√≤ng\nüìå Nh√£n Web-based: Th√™m 231 d√≤ng, t·ªïng c·ªông 17,296 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 113 d√≤ng, t·ªïng c·ªông 8,952 d√≤ng\nüìå File 117: Gi·ªØ 8,387 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,027 d√≤ng, t·ªïng c·ªông 247,347 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,644 d√≤ng, t·ªïng c·ªông 339,170 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 17,428 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 87 d√≤ng, t·ªïng c·ªông 9,039 d√≤ng\nüìå File 118: Gi·ªØ 4,890 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,936 d√≤ng, t·ªïng c·ªông 249,283 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,500 d√≤ng, t·ªïng c·ªông 341,670 d√≤ng\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 17,541 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 9,117 d√≤ng\nüìå File 119: Gi·ªØ 4,627 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,810 d√≤ng, t·ªïng c·ªông 251,093 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,365 d√≤ng, t·ªïng c·ªông 344,035 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 17,654 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 9,183 d√≤ng\nüìå File 120: Gi·ªØ 4,354 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,600 d√≤ng, t·ªïng c·ªông 346,635 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,914 d√≤ng, t·ªïng c·ªông 253,007 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 9,237 d√≤ng\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 17,789 d√≤ng\nüìå File 121: Gi·ªØ 4,703 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,692 d√≤ng, t·ªïng c·ªông 349,327 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,038 d√≤ng, t·ªïng c·ªông 255,045 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 17,929 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 9,306 d√≤ng\nüìå File 122: Gi·ªØ 4,939 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,538 d√≤ng, t·ªïng c·ªông 351,865 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,961 d√≤ng, t·ªïng c·ªông 257,006 d√≤ng\nüìå Nh√£n Web-based: Th√™m 134 d√≤ng, t·ªïng c·ªông 18,063 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 9,368 d√≤ng\nüìå File 123: Gi·ªØ 4,695 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,893 d√≤ng, t·ªïng c·ªông 258,899 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,524 d√≤ng, t·ªïng c·ªông 354,389 d√≤ng\nüìå Nh√£n Web-based: Th√™m 141 d√≤ng, t·ªïng c·ªông 18,204 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 9,445 d√≤ng\nüìå File 124: Gi·ªØ 4,635 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,510 d√≤ng, t·ªïng c·ªông 262,409 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,601 d√≤ng, t·ªïng c·ªông 358,990 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 129 d√≤ng, t·ªïng c·ªông 9,574 d√≤ng\nüìå Nh√£n Web-based: Th√™m 220 d√≤ng, t·ªïng c·ªông 18,424 d√≤ng\nüìå File 125: Gi·ªØ 8,460 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,939 d√≤ng, t·ªïng c·ªông 264,348 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,613 d√≤ng, t·ªïng c·ªông 361,603 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 9,640 d√≤ng\nüìå Nh√£n Web-based: Th√™m 127 d√≤ng, t·ªïng c·ªông 18,551 d√≤ng\nüìå File 126: Gi·ªØ 4,745 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,484 d√≤ng, t·ªïng c·ªông 364,087 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,808 d√≤ng, t·ªïng c·ªông 266,156 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 18,677 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 75 d√≤ng, t·ªïng c·ªông 9,715 d√≤ng\nüìå File 127: Gi·ªØ 4,493 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,495 d√≤ng, t·ªïng c·ªông 366,582 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,669 d√≤ng, t·ªïng c·ªông 267,825 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 18,799 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 9,784 d√≤ng\nüìå File 128: Gi·ªØ 4,355 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,590 d√≤ng, t·ªïng c·ªông 371,172 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,292 d√≤ng, t·ªïng c·ªông 271,117 d√≤ng\nüìå Nh√£n Web-based: Th√™m 255 d√≤ng, t·ªïng c·ªông 19,054 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 120 d√≤ng, t·ªïng c·ªông 9,904 d√≤ng\nüìå File 129: Gi·ªØ 8,257 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,630 d√≤ng, t·ªïng c·ªông 373,802 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,906 d√≤ng, t·ªïng c·ªông 273,023 d√≤ng\nüìå Nh√£n Web-based: Th√™m 142 d√≤ng, t·ªïng c·ªông 19,196 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 9,976 d√≤ng\nüìå File 130: Gi·ªØ 4,750 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,630 d√≤ng, t·ªïng c·ªông 376,432 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,966 d√≤ng, t·ªïng c·ªông 274,989 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 19,328 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 10,050 d√≤ng\nüìå File 131: Gi·ªØ 4,802 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Recon: Th√™m 1,733 d√≤ng, t·ªïng c·ªông 276,722 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,433 d√≤ng, t·ªïng c·ªông 378,865 d√≤ng\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 19,458 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 10,122 d√≤ng\nüìå File 132: Gi·ªØ 4,368 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,372 d√≤ng, t·ªïng c·ªông 280,094 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,655 d√≤ng, t·ªïng c·ªông 383,520 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 128 d√≤ng, t·ªïng c·ªông 10,250 d√≤ng\nüìå Nh√£n Web-based: Th√™m 251 d√≤ng, t·ªïng c·ªông 19,709 d√≤ng\nüìå File 133: Gi·ªØ 8,406 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi! K√≠ch th∆∞·ªõc: (2293573, 47)\nüìã Nh√£n duy nh·∫•t: ['Mirai', 'DDoS', 'Spoofing', 'BENIGN', 'DoS', 'Recon', 'BruteForce', 'Web-based']\n\nüìã Ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng:\nlabel\nMirai         400000\nDDoS          400000\nBENIGN        400000\nDoS           400000\nSpoofing      383520\nRecon         280094\nWeb-based      19709\nBruteForce     10250\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC0OklEQVR4nOzdeVxV1eL///dRBFQ8ICpTKuKQiGNpVzE1ExQVKz5aTuTQJcnCbmaZWeZUN0srbTDNe29pN72aZqakKI5Ukik5knLVMCs96JXgKE4g+/dHP/bXI2A4cCB5PR+P/Xh01l57rXX24hzh3d5rWwzDMAQAAAAAAAA4UaWyHgAAAAAAAAAqHkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAA/sDkyZNlsVic0lfXrl3VtWtX8/XmzZtlsVi0bNkyp/Q/fPhwNWjQwCl9Xa8zZ87o0UcflZ+fnywWi0aPHl3WQyqRBg0aqE+fPje1TYvFosmTJ9+09qZPn67g4GDl5+fftDaLs337dnXs2FHVq1eXxWLRrl27Sr1PlI0rv9eOHDkii8Wi+fPnl2q/zz//vNq3b1+qfQAAbgyhFACgQpk/f74sFou5ubu7KyAgQBEREXrnnXd0+vTpm9LPsWPHNHny5HL5h3Z5HltJvPrqq5o/f74ef/xx/fvf/9aQIUOKrZufn6+5c+eqTZs28vDwkK+vr3r16qWtW7f+YT8Ffzi/8cYbN3P45Zbdbtfrr7+ucePGqVKl//cr4uWfF4vFourVqyskJESvvPKKzp49e1195ebm6qGHHlJmZqZmzpypf//73woMDLxZb+WGpaam6uGHH9Ztt90mNzc3BQQEKDo6WqmpqWU9NFyD0aNHa/fu3Vq5cmVZDwUAUAyXsh4AAABlYerUqQoKClJubq5sNps2b96s0aNH66233tLKlSvVqlUrs+6ECRP0/PPPX1P7x44d05QpU9SgQQO1adOmxMetW7fumvq5Hlcb2z/+8Q+nXCVzIzZu3KgOHTpo0qRJf1h37Nixeuutt/Twww/riSeeUFZWlj744APdc889+uabb/SXv/zFCSP+c/jwww+Vl5enQYMGFdrXvXt3DR06VNLvV6p99dVXeumll7R7924tXbr0mvs6fPiwfvrpJ/3jH//Qo48+esNjv5mWL1+uQYMGydvbWzExMQoKCtKRI0f0r3/9S8uWLdPixYv1f//3f2U9zD+1wMBAnTt3TlWqVCnVfvz8/PTAAw/ojTfe0P3331+qfQEArg+hFACgQurVq5fatWtnvh4/frw2btyoPn366P7779f+/ftVtWpVSZKLi4tcXEr3n8yzZ8+qWrVqcnV1LdV+/khp/5F4M5w4cUIhISF/WC8vL09z5szRgw8+qH//+99m+UMPPaSGDRtq4cKFhFKX+eijj3T//ffL3d290L7bb79dDz/8sPl65MiRunjxopYvX67z588XeczVnDhxQpLk5eV1Q2O+XE5OjqpXr35DbRw+fFhDhgxRw4YNlZSUpDp16pj7nnrqKXXu3FlDhgzRnj171LBhwxsdcondjPdWnhRcpeoM/fv310MPPaQff/zRqXMGACgZbt8DAOD/161bN7300kv66aef9Mknn5jlRa0plZiYqE6dOsnLy0seHh5q2rSpXnjhBUm/rwN11113SZIeeeQR87angvVTunbtqhYtWiglJUVdunRRtWrVzGOvXHulwKVLl/TCCy/Iz89P1atX1/3336+ff/7ZoU6DBg00fPjwQsde3uYfja2oNaVycnL0zDPPqF69enJzc1PTpk31xhtvyDAMh3oWi0WjRo3SihUr1KJFC7m5ual58+ZKSEgo+oRf4cSJE4qJiZGvr6/c3d3VunVrLViwwNxfsL5Wenq6vvzyS3PsR44cKbK93NxcnTt3Tr6+vg7lPj4+qlSpkhk63qiPPvpI3bp1k4+Pj9zc3BQSEqI5c+YUW3/dunVq06aN3N3dFRISouXLlxeqk5WVpdGjR5vnvHHjxnr99df/8Cq206dPa/To0WrQoIHc3Nzk4+Oj7t276/vvv7/qcenp6dqzZ4/Cw8NL9qYlc02vKwPbbdu2qWfPnvL09FS1atXMq9IKDB8+XPfcc4+k3wNCi8Xi8DO/ceNGde7cWdWrV5eXl5ceeOAB7d+/36GPgs/kDz/8oMGDB6tmzZrq1KmTuf+TTz5R27ZtVbVqVXl7e2vgwIGFPi9FmTFjhs6ePat58+Y5BFKSVLt2bX3wwQfKycnR9OnTJUnLli2TxWLRli1bCrX1wQcfyGKxaN++fWbZgQMH9OCDD8rb21vu7u5q165doVvLCm4x3rJli5544gn5+Piobt26kko2v1999ZUeeugh1a9fX25ubqpXr56efvppnTt3zqGf4cOHy8PDQ0ePHlWfPn3k4eGh2267TbNnz5Yk7d27V926dVP16tUVGBioRYsWFTnOpKQkPfbYY6pVq5asVquGDh2q33777arnuag1pQrG8+uvvyoqKkoeHh6qU6eOnn32WV26dMnh+FOnTmnIkCGyWq3y8vLSsGHDtHv37iLXqSr4mf7iiy+uOiYAQNngSikAAC4zZMgQvfDCC1q3bp1GjBhRZJ3U1FT16dNHrVq10tSpU+Xm5qZDhw6Zf3g3a9ZMU6dO1cSJExUbG6vOnTtLkjp27Gi2cerUKfXq1UsDBw7Uww8/XCg4udLf//53WSwWjRs3TidOnNCsWbMUHh6uXbt2XVO4UpKxXc4wDN1///3atGmTYmJi1KZNG61du1Zjx47Vr7/+qpkzZzrU//rrr7V8+XI98cQTqlGjht555x3169dPR48eVa1atYod17lz59S1a1cdOnRIo0aNUlBQkJYuXarhw4crKytLTz31lJo1a6Z///vfevrpp1W3bl0988wzklQoPChQtWpVtW/fXvPnz1doaKg6d+6srKwsvfzyy6pZs6ZiY2NLfN6uZs6cOWrevLnuv/9+ubi4aNWqVXriiSeUn5+vuLg4h7oHDx7UgAEDNHLkSA0bNkwfffSRHnroISUkJKh79+6Sfr9q7p577tGvv/6qxx57TPXr19fWrVs1fvx4HT9+XLNmzSp2LCNHjtSyZcs0atQohYSE6NSpU/r666+1f/9+3XnnncUeV7DGVnF1zp8/r//973+Sfg8pv/nmGy1YsECDBw92CKU2btyoXr16qW3btpo0aZIqVapkhnZfffWV/vKXv+ixxx7TbbfdpldffVV/+9vfdNddd5k//+vXr1evXr3UsGFDTZ48WefOndO7776ru+++W99//32hwPShhx5SkyZN9Oqrr5oh6d///ne99NJL6t+/vx599FGdPHlS7777rrp06aKdO3de9eqsVatWqUGDBubn4kpdunRRgwYN9OWXX0qSIiMj5eHhoU8//dQM2gosWbJEzZs3V4sWLST9/r1x991367bbbtPzzz+v6tWr69NPP1VUVJQ+++yzQrcEPvHEE6pTp44mTpyonJwcSSWb36VLl+rs2bN6/PHHVatWLX333Xd699139csvvxS61fLSpUvq1auXunTpounTp2vhwoUaNWqUqlevrhdffFHR0dHq27ev5s6dq6FDhyo0NFRBQUEObYwaNUpeXl6aPHmy0tLSNGfOHP30009miHwtLl26pIiICLVv315vvPGG1q9frzfffFONGjXS448/Lun3deLuu+8+fffdd3r88ccVHBysL774QsOGDSuyTU9PTzVq1EjffPONnn766WsaDwDACQwAACqQjz76yJBkbN++vdg6np6exh133GG+njRpknH5P5kzZ840JBknT54sto3t27cbkoyPPvqo0L577rnHkGTMnTu3yH333HOP+XrTpk2GJOO2224z7Ha7Wf7pp58akoy3337bLAsMDDSGDRv2h21ebWzDhg0zAgMDzdcrVqwwJBmvvPKKQ70HH3zQsFgsxqFDh8wySYarq6tD2e7duw1Jxrvvvluor8vNmjXLkGR88sknZtnFixeN0NBQw8PDw+G9BwYGGpGRkVdtr8DBgweNO++805Bkbg0bNjQOHDjwh8emp6cbkowZM2Zctd7Zs2cLlUVERBgNGzZ0KAsMDDQkGZ999plZlp2dbfj7+zv8vL388stG9erVjf/+978Oxz///PNG5cqVjaNHj5plkoxJkyaZrz09PY24uLg/fG9XmjBhgiHJOH36dKF9l5+7y7eoqCjj/PnzZr38/HyjSZMmRkREhJGfn2+Wnz171ggKCjK6d+9ulhX8XC9dutShrzZt2hg+Pj7GqVOnzLLdu3cblSpVMoYOHWqWFXwmBw0a5HD8kSNHjMqVKxt///vfHcr37t1ruLi4FCq/XFZWliHJeOCBB4qtYxiGcf/99xuSzJ/JQYMGGT4+PkZeXp5Z5/jx40alSpWMqVOnmmVhYWFGy5YtC52zjh07Gk2aNDHLCr6jOnXq5NCmYZRsfov6eZw2bZphsViMn376ySwbNmyYIcl49dVXzbLffvvNqFq1qmGxWIzFixeb5QcOHCj0s1YwzrZt2xoXL140y6dPn25IMr744guz7MrvoILP1uXfQQXjufycGYZh3HHHHUbbtm3N15999pkhyZg1a5ZZdunSJaNbt27Ffq/16NHDaNasWaFyAEDZ4/Y9AACu4OHhcdWn8BVcafHFF19c96Lgbm5ueuSRR0pcf+jQoapRo4b5+sEHH5S/v79Wr159Xf2X1OrVq1W5cmX97W9/cyh/5plnZBiG1qxZ41AeHh6uRo0ama9btWolq9WqH3/88Q/78fPzc1hku0qVKvrb3/6mM2fOFHl7VEnUqFFDzZs3V1xcnJYvX673339feXl5ioqKMq/8uVGXX6mWnZ2t//3vf7rnnnv0448/Kjs726FuQECAwxUxBbc77dy5UzabTdLvV7p07txZNWvW1P/+9z9zCw8P16VLl5SUlFTsWLy8vLRt2zYdO3bsmt7DqVOn5OLiIg8PjyL3P/DAA0pMTFRiYqK++OILjR8/XgkJCRo8eLB5hdKuXbt08OBBDR48WKdOnTLHnZOTo7CwMCUlJV3183L8+HHt2rVLw4cPl7e3t1neqlUrde/evcif9ZEjRzq8Xr58ufLz89W/f3+Hc+fn56cmTZpo06ZNxfZf8Jm//HNWlIL9drtdkjRgwACdOHFCmzdvNussW7ZM+fn5GjBggCQpMzNTGzduVP/+/XX69GlzXKdOnVJERIQOHjyoX3/91aGfESNGqHLlyg5lJZnfy38ec3Jy9L///U8dO3aUYRjauXNnofqXLzTv5eWlpk2bqnr16urfv79Z3rRpU3l5eRX5OY6NjXVYi+7xxx+Xi4vLdX83XTmnnTt3dug3ISFBVapUcbiStVKlSoWuSrxcwWcJAFD+cPseAABXOHPmjHx8fIrdP2DAAP3zn//Uo48+queff15hYWHq27evHnzwQVWqVLL/33Pbbbdd06LmTZo0cXhtsVjUuHHjYtdTull++uknBQQEFPpDvVmzZub+y9WvX79QGzVr1vzDNWZ++uknNWnSpND5K66fksjLy1N4eLi6du2qd9991ywPDw9X8+bNNWPGDL3++uvX3O6VvvnmG02aNEnJyck6e/asw77s7Gx5enqarxs3blzolqbbb79d0u/r7Pj5+engwYPas2dPsbclFiwSXpTp06dr2LBhqlevntq2bavevXtr6NChN7zAc926dR3Wm7r//vtVq1YtPfvss4qPj9d9992ngwcPSlKxt1FJv5+PmjVrFrmvYI6bNm1aaF+zZs20du3aQgt+X3kr2cGDB2UYRqHPS4GrLeRf8DN+tUD68v0F9QvWz1qyZInCwsIk/X7rXps2bcy5PXTokAzD0EsvvaSXXnqpyHZPnDih2267rdj3JpVsfo8ePaqJEydq5cqVhT53V4ak7u7uhX7OPD09Vbdu3UI/p56enkV+jq881x4eHvL397+u76aixnPl98dPP/0kf39/VatWzaFe48aNi23XMIxrvpUQAOAchFIAAFzml19+UXZ29lX/wKlataqSkpK0adMmffnll0pISNCSJUvUrVs3rVu3rtDVDcW1cbMV90fXpUuXSjSmm6G4fowrFkV3hqSkJO3bt09vvfWWQ3mTJk3UrFkzh8W3r9fhw4cVFham4OBgvfXWW6pXr55cXV21evVqzZw587qupMvPz1f37t313HPPFbm/IOgoSv/+/dW5c2d9/vnnWrdunRm8LV++XL169Sr2uFq1aikvL0+nT5/+wyuFChQEMElJSbrvvvvM9zpjxgy1adOmyGOKuxLrel35OcrPz5fFYtGaNWuK/Fm8Wv+enp7y9/fXnj17rtrnnj17dNttt8lqtUr6/arHqKgoff7553r//feVkZGhb775Rq+++qrDuCTp2WefVURERJHtXvmdU9R3xB/N76VLl9S9e3dlZmZq3LhxCg4OVvXq1fXrr79q+PDhhX4ei/u8ltXnuLS+p3777TfVrl27VNoGANwYQikAAC7z73//W5KK/cOxQKVKlRQWFqawsDC99dZbevXVV/Xiiy9q06ZNCg8Pv+n/V77gKpQChmHo0KFDatWqlVlWs2ZNZWVlFTr2p59+criS4lrGFhgYqPXr1xcKKw4cOGDuvxkCAwO1Z88e5efnO1wtdSP9ZGRkSFKhJ3dJvz+ZLy8v7zpH+/+sWrVKFy5c0MqVKx2uEivuNrGCK2Yun4P//ve/kmQu4t2oUSOdOXPmmp6Edzl/f3898cQTeuKJJ3TixAndeeed+vvf/37VUCo4OFjS70/hu/xn6moKzt+ZM2fMcUu/35J4PWMvmOO0tLRC+w4cOKDatWs7XCVVlEaNGskwDAUFBV01vCtOnz599I9//ENff/21w9P8Cnz11Vc6cuSIHnvsMYfyAQMGaMGCBdqwYYP2798vwzDMW/ckmZ+/KlWqXPe8Frja/O7du1f//e9/tWDBAg0dOtQ8JjEx8Yb6vJqDBw/q3nvvNV+fOXNGx48fV+/evUulv8DAQG3atElnz551uFrq0KFDxR6Tnp6u1q1bl8p4AAA3hjWlAAD4/23cuFEvv/yygoKCFB0dXWy9zMzMQmUFV4ZcuHBBksw/nosKia7Hxx9/7HBb0bJly3T8+HGHoKFRo0b69ttvdfHiRbMsPj5eP//8s0Nb1zK23r1769KlS3rvvfccymfOnCmLxXLVoONa9O7dWzabTUuWLDHL8vLy9O6778rDw6PQk81KoiCUWLx4sUP5999/r7S0NN1xxx03Nmj9vys7Lr+CJDs7Wx999FGR9Y8dO6bPP//cfG232/Xxxx+rTZs28vPzk/T71TDJyclau3ZtoeOzsrKKDdMuXbpU6PYsHx8fBQQEmD+XxQkNDZUk7dix46r1Lrdq1SpJMv/Yb9u2rRo1aqQ33njDDKoud/Lkyau25+/vrzZt2mjBggUOP5v79u3TunXrShRy9O3bV5UrV9aUKVMKXdVjGIZOnTp11ePHjh2rqlWr6rHHHitUNzMzUyNHjlS1atU0duxYh33h4eHy9vbWkiVLtGTJEv3lL39xuP3Ox8dHXbt21QcffKDjx48X6vePzo1Usvkt6ufRMAy9/fbbf9j+9Zo3b55yc3PN13PmzFFeXt5N+264UkREhHJzc/WPf/zDLMvPz9fs2bOLrJ+dna3Dhw8X+4RRAEDZ4kopAECFtGbNGh04cEB5eXnKyMjQxo0blZiYqMDAQK1cuVLu7u7FHjt16lQlJSUpMjJSgYGBOnHihN5//33VrVvXvLqiUaNG8vLy0ty5c1WjRg1Vr15d7du3L3KdmJLw9vZWp06d9MgjjygjI0OzZs1S48aNHRb7ffTRR7Vs2TL17NlT/fv31+HDh/XJJ584LDx+rWO77777dO+99+rFF1/UkSNH1Lp1a61bt05ffPGFRo8eXajt6xUbG6sPPvhAw4cPV0pKiho0aKBly5bpm2++0axZs0p8S9nl2rZtq+7du2vBggWy2+3q0aOHjh8/rnfffVdVq1bV6NGjS9TOhg0bdP78+ULlUVFR6tGjh1xdXXXffffpscce05kzZ/SPf/xDPj4+RYYPt99+u2JiYrR9+3b5+vrqww8/VEZGhkOINXbsWK1cuVJ9+vTR8OHD1bZtW+Xk5Gjv3r1atmyZjhw5UuStSKdPn1bdunX14IMPqnXr1vLw8ND69eu1fft2vfnmm1d9jw0bNlSLFi20fv16/fWvfy20/7///a8++eQTSdLZs2f17bffasGCBWrcuLGGDBki6ferB//5z3+qV69eat68uR555BHddttt+vXXX7Vp0yZZrVYzyCrOjBkz1KtXL4WGhiomJkbnzp3Tu+++K09PT02ePPmqx0q//2y/8sorGj9+vI4cOaKoqCjVqFFD6enp+vzzzxUbG6tnn3222OObNGmiBQsWKDo6Wi1btlRMTIyCgoJ05MgR/etf/9L//vc//ec//yn0c1+lShX17dtXixcvVk5Ojt54441Cbc+ePVudOnVSy5YtNWLECDVs2FAZGRlKTk7WL7/8ot27d1/1vZVkfoODg9WoUSM9++yz+vXXX2W1WvXZZ5/94ZpuN+LixYsKCwtT//79lZaWpvfff1+dOnXS/fffXyr9RUVF6S9/+YueeeYZHTp0SMHBwVq5cqX5PwuuvBJ0/fr1MgxDDzzwQKmMBwBwg5z9uD8AAMpSwWPMCzZXV1fDz8/P6N69u/H222+bj3m/XMHj5wts2LDBeOCBB4yAgADD1dXVCAgIMAYNGmT897//dTjuiy++MEJCQgwXFxeHR5Xfc889RvPmzYsc35WPTt+0aZMhyfjPf/5jjB8/3vDx8TGqVq1qREZGOjzevcCbb75p3HbbbYabm5tx9913Gzt27CjU5tXGNmzYMCMwMNCh7unTp42nn37aCAgIMKpUqWI0adLEmDFjhpGfn+9QT1KRj6sPDAw0hg0bVuT7vVxGRobxyCOPGLVr1zZcXV2Nli1bFvl498DAQCMyMvIP2zMMwzh79qwxdepUIyQkxKhatarh6elp9OnTx9i5c+cfHlvw2Pritn//+9+GYRjGypUrjVatWhnu7u5GgwYNjNdff9348MMPDUlGenp6oXGvXbvWaNWqleHm5mYEBwcbS5cuLdT36dOnjfHjxxuNGzc2XF1djdq1axsdO3Y03njjDePixYtmPUnGpEmTDMMwjAsXLhhjx441WrdubdSoUcOoXr260bp1a+P9998v0bl66623DA8PD+Ps2bMO5Ve+78qVKxt169Y1YmNjjYyMjELt7Ny50+jbt69Rq1Ytw83NzQgMDDT69+9vbNiwwaxT8HNd1Htfv369cffddxtVq1Y1rFarcd999xk//PCDQ52Cz+TJkyeLfC+fffaZ0alTJ6N69epG9erVjeDgYCMuLs5IS0sr0bnYs2ePMWjQIMPf39+oUqWK4efnZwwaNMjYu3dvscckJiYakgyLxWL8/PPPRdY5fPiwMXToUMPPz8+oUqWKcdtttxl9+vQxli1bZtYp+I7avn27w7Elnd8ffvjBCA8PNzw8PIzatWsbI0aMMHbv3u3wOTeM3z/r1atXLzTG4r6frvzcFYxzy5YtRmxsrFGzZk3Dw8PDiI6ONk6dOlWozcu/gwo+WyUZz5Xfv4ZhGCdPnjQGDx5s1KhRw/D09DSGDx9ufPPNN4YkY/HixQ51BwwYYHTq1KlQuwCA8sFiGGWw8igAAADKlezsbDVs2FDTp09XTExMWQ8H5dz8+fP1yCOPaPv27WrXrl1ZD0crVqzQ//3f/+nrr7/W3XffLUmy2WwKCgrS4sWLuVIKAMop1pQCAACAPD099dxzz2nGjBnX9dRAwFnOnTvn8PrSpUt69913ZbVadeedd5rls2bNUsuWLQmkAKAcY00pAAAASJLGjRuncePGlfUwgKt68sknde7cOYWGhurChQtavny5tm7dqldffVVVq1Y167322mtlOEoAQEkQSgEAAAD40+jWrZvefPNNxcfH6/z582rcuLHeffddjRo1qqyHBgC4RqwpBQAAAAAAAKdjTSkAAAAAAAA4HaEUAAAAAAAAnI41pcpQfn6+jh07pho1ashisZT1cAAAAAAAAG6YYRg6ffq0AgICVKlS8ddDEUqVoWPHjqlevXplPQwAAAAAAICb7ueff1bdunWL3U8oVYZq1Kgh6fdJslqtZTwaAAAAAACAG2e321WvXj0z9ygOoVQZKrhlz2q1EkoBAAAAAIBbyh8tVcRC5wAAAAAAAHA6QikAAAAAAAA4HaEU/lRee+01WSwWjR492iw7f/684uLiVKtWLXl4eKhfv37KyMhwOO7o0aOKjIxUtWrV5OPjo7FjxyovL++qfWVmZio6OlpWq1VeXl6KiYnRmTNnHOrs2bNHnTt3lru7u+rVq6fp06cXamfp0qUKDg6Wu7u7WrZsqdWrV1//CajAmPuKiXmvmJh3AACACsJAmcnOzjYkGdnZ2WU9lD+F7777zmjQoIHRqlUr46mnnjLLR44cadSrV8/YsGGDsWPHDqNDhw5Gx44dzf15eXlGixYtjPDwcGPnzp3G6tWrjdq1axvjx4+/an89e/Y0WrdubXz77bfGV199ZTRu3NgYNGiQuT87O9vw9fU1oqOjjX379hn/+c9/jKpVqxoffPCBWeebb74xKleubEyfPt344YcfjAkTJhhVqlQx9u7de/NOTAXA3FdMzHvFxLwDAAD8+ZU07yCUKkOEUiV3+vRpo0mTJkZiYqJxzz33mH+oZGVlGVWqVDGWLl1q1t2/f78hyUhOTjYMwzBWr15tVKpUybDZbGadOXPmGFar1bhw4UKR/f3www+GJGP79u1m2Zo1awyLxWL8+uuvhmEYxvvvv2/UrFnToY1x48YZTZs2NV/379/fiIyMdGi7ffv2xmOPPXadZ6LiYe4rJua9YmLeAQAAbg0lzTu4fQ9/CnFxcYqMjFR4eLhDeUpKinJzcx3Kg4ODVb9+fSUnJ0uSkpOT1bJlS/n6+pp1IiIiZLfblZqaWmR/ycnJ8vLyUrt27cyy8PBwVapUSdu2bTPrdOnSRa6urg7tpqWl6bfffjPrXDnmiIgIc2z4Y8x9xcS8V0zMOwAAQMXiUtYDAP7I4sWL9f3332v79u2F9tlsNrm6usrLy8uh3NfXVzabzaxz+R8pBfsL9hXFZrPJx8fHoczFxUXe3t4O7QYFBRXbbs2aNYvtu7h+4Yi5r5iY94qJeQcAAKh4CKVQrv3888966qmnlJiYKHd397IeDpyIua+YmPeKiXkHAAComLh9D+VaSkqKTpw4oTvvvFMuLi5ycXHRli1b9M4778jFxUW+vr66ePGisrKyHI7LyMiQn5+fJMnPz6/QE5oKXhfUuZKfn59OnDjhUJaXl6fMzMxrare4OsX1i/+Hua+YmPeKiXkHAAComAilUK6FhYVp79692rVrl7m1a9dO0dHR5n9XqVJFGzZsMI9JS0vT0aNHFRoaKkkKDQ3V3r17Hf7wSExMlNVqVUhISJH9hoaGKisrSykpKWbZxo0blZ+fr/bt25t1kpKSlJub69Bu06ZNVbNmTbPO5WMrqFMwNhSPua+YmPeKiXkHAACooJy08DqKwNP3rs/lT2QyjN8fE16/fn1j48aNxo4dO4zQ0FAjNDTU3F/wmPAePXoYu3btMhISEow6deqU6DHhd9xxh7Ft2zbj66+/Npo0aeLwmPCsrCzD19fXGDJkiLFv3z5j8eLFRrVq1Qo9JtzFxcV44403jP379xuTJk3iMeE3gLmvmJj3iol5BwAA+PMqad5BKFWGCKWuz5V/qJw7d8544oknjJo1axrVqlUz/u///s84fvy4wzFHjhwxevXqZVStWtWoXbu28cwzzxi5ubnm/vT0dEOSsWnTJrPs1KlTxqBBgwwPDw/DarUajzzyiHH69GmHdnfv3m106tTJcHNzM2677TbjtddeKzTeTz/91Lj99tsNV1dXo3nz5saXX355c05EBcTcV0zMe8XEvAMAAPx5lTTvsBiGYZTddVoVm91ul6enp7Kzs2W1Wst6OBXapk2b1LdvX/3444/m7RioGJj7iol5r5iYdwAAAOcoad7BmlKApNWrV+uFF17gj5QKiLmvmJj3iol5BwAAKF/KTSj12muvyWKxaPTo0WbZ+fPnFRcXp1q1asnDw0P9+vUr9HSbo0ePKjIyUtWqVZOPj4/Gjh2rvLy8q/aVmZmp6OhoWa1WeXl5KSYmRmfOnHGos2fPHnXu3Fnu7u6qV6+epk+fXqidpUuXKjg4WO7u7mrZsqVWr159/ScAZWrGjBkaO3ZsWQ8DZYC5r5iY94qJeQcAAChfykUotX37dn3wwQdq1aqVQ/nTTz+tVatWaenSpdqyZYuOHTumvn37mvsvXbqkyMhIXbx4UVu3btWCBQs0f/58TZw48ar9RUdHKzU1VYmJiYqPj1dSUpJiY2PN/Xa7XT169FBgYKBSUlI0Y8YMTZ48WfPmzTPrbN26VYMGDVJMTIx27typqKgoRUVFad++fTfprAAAAAAAANy6ynxNqTNnzujOO+/U+++/r1deeUVt2rTRrFmzlJ2drTp16mjRokV68MEHJUkHDhxQs2bNlJycrA4dOmjNmjXq06ePjh07Jl9fX0nS3LlzNW7cOJ08eVKurq6F+tu/f79CQkK0fft2tWvXTpKUkJCg3r1765dfflFAQIDmzJmjF198UTabzWzj+eef14oVK3TgwAFJ0oABA5STk6P4+Hiz7Q4dOqhNmzaaO3duid47a0oBAAAAAIBbzZ9mTam4uDhFRkYqPDzcoTwlJUW5ubkO5cHBwapfv76Sk5MlScnJyWrZsqUZSElSRESE7Ha7UlNTi+wvOTlZXl5eZiAlSeHh4apUqZK2bdtm1unSpYtDqBUREaG0tDT99ttvZp0rxxwREWGODQAAAAAAAMVzKcvOFy9erO+//17bt28vtK/gKiUvLy+Hcl9fX9lsNrPO5YFUwf6CfUWx2Wzy8fFxKHNxcZG3t7dDu0FBQcW2W7NmzWL7Lq5fSbpw4YIuXLhgvrbb7cXWBQAAAAAAuJWVWSj1888/66mnnlJiYqLc3d3LahhONW3aNE2ZMqWsh1EqLJayHgGu5JQbc5n48scJE2+ZwryXN8ak0p/3KZZb89+vP7tJxqSyHgIAAMB1K7Pb91JSUnTixAndeeedcnFxkYuLi7Zs2aJ33nlHLi4u8vX11cWLF5WVleVwXEZGhvz8/CRJfn5+hZ7GV/C6oM6V/Pz8dOLECYeyvLw8ZWZmXlO7xdUprl9JGj9+vLKzs83t559/LrYuAADArW7OnDlq1aqVrFarrFarQkNDtWbNGnO/zWbTkCFD5Ofnp+rVq+vOO+/UZ5995tDG/fffr/r168vd3V3+/v4aMmSIjh07dtV+u3btKovF4rCNHDnS3L97924NGjRI9erVU9WqVdWsWTO9/fbbhdrZvHmz7rzzTrm5ualx48aaP3/+jZ0QAAAqmDILpcLCwrR3717t2rXL3Nq1a6fo6Gjzv6tUqaINGzaYx6Slpeno0aMKDQ2VJIWGhmrv3r0OIVNiYqKsVqtCQkKK7Dc0NFRZWVlKSUkxyzZu3Kj8/Hy1b9/erJOUlKTc3FyHdps2baqaNWuadS4fW0GdgrEVxc3Nzfylq2ADAACoqOrWravXXntNKSkp2rFjh7p166YHHnjAXBt06NChSktL08qVK7V371717dtX/fv3186dO8027r33Xn366adKS0vTZ599psOHD5sPybmaESNG6Pjx4+Y2ffp0c19KSop8fHz0ySefKDU1VS+++KLGjx+v9957z6yTnp6uyMhI3Xvvvdq1a5dGjx6tRx99VGvXrr2JZwgAgFtbmT9973Jdu3Y1n74nSY8//rhWr16t+fPny2q16sknn5Qkbd26VZJ06dIltWnTRgEBAZo+fbr5f9MeffRRvfrqq8X206tXL2VkZGju3LnKzc3VI488onbt2mnRokWSpOzsbDVt2lQ9evTQuHHjtG/fPv31r3/VzJkzFRsba47hnnvu0WuvvabIyEgtXrxYr776qr7//nu1aNGiRO/3Vnr6HndxlT/cvldBcftehcTtexXXrXj7nre3t2bMmKGYmBh5eHhozpw5GjJkiLm/Vq1aev311/Xoo48WefzKlSsVFRWlCxcuqEqVKkXWufJ3zpKIi4vT/v37tXHjRknSuHHj9OWXX2rfvn1mnYEDByorK0sJCQklbhcAgFvRn+bpe1czc+ZM9enTR/369VOXLl3k5+en5cuXm/srV66s+Ph4Va5cWaGhoXr44Yc1dOhQTZ061axz5MgRWSwWbd682SxbuHChgoODFRYWpt69e6tTp06aN2+eud/T01Pr1q1Tenq62rZtq2eeeUYTJ040AylJ6tixoxYtWqR58+apdevWWrZsmVasWFHiQAoAAAD/z6VLl7R48WLl5OSYV5537NhRS5YsUWZmpvLz87V48WKdP39eXbt2LbKNzMxMLVy4UB07diw2kCqwcOFC1a5dWy1atND48eN19uzZq9bPzs6Wt7e3+ZonMQMAcOPK9Ol7V7o8OJIkd3d3zZ49W7Nnzy72mMDAQK1evbrY/enp6fLy8lLr1q3NMm9vb/OqqOK0atVKX3311VXrPPTQQ3rooYeuWgcAAADF27t3r0JDQ3X+/Hl5eHjo888/N5dh+PTTTzVgwADVqlVLLi4uqlatmj7//HM1btzYoY1x48bpvffe09mzZ9WhQwfFx8dftc/BgwcrMDBQAQEB2rNnj8aNG6e0tDSH//l5ua1bt2rJkiX68ssvzbLinsRst9t17tw5Va1a9XpOBwAAFUq5CqVKw+rVq/XCCy+Ya0EBAACg/GjatKl27dql7OxsLVu2TMOGDdOWLVsUEhKil156SVlZWVq/fr1q166tFStWqH///vrqq6/UsmVLs42xY8cqJiZGP/30k6ZMmaKhQ4cqPj5elmJuM7/86veWLVvK399fYWFhOnz4sBo1auRQd9++fXrggQc0adIk9ejRo3ROAgAAFdQtH0rNmDGjrIcAAACAYri6uppXPrVt21bbt2/X22+/reeee07vvfee9u3bp+bNm0uSWrdura+++kqzZ8/W3LlzzTZq166t2rVr6/bbb1ezZs1Ur149ffvtt1d9AM3lCh52c+jQIYdQ6ocfflBYWJhiY2M1YcIEh2OKexKz1WrlKikAAEqoXK8pBQAAgIolPz9fFy5cMNd4qlTJ8dfVypUrKz8//6rHS9KFCxdK3OeuXbskSf7+/mZZamqq7r33Xg0bNkx///vfCx1zPU9iBgAAjm75K6UAAABQPo0fP169evVS/fr1dfr0aS1atEibN2/W2rVrFRwcrMaNG+uxxx7TG2+8oVq1amnFihVKTEw014zatm2btm/frk6dOqlmzZo6fPiwXnrpJTVq1KjYcOjw4cNatGiRevfurVq1amnPnj16+umn1aVLF7Vq1UrS77fsdevWTRERERozZoxsNpuk3wOxOnXqSJJGjhyp9957T88995z++te/auPGjfr0008d1p0CAABXx5VSAAAAKBMnTpzQ0KFD1bRpU4WFhWn79u1au3atunfvripVqmj16tWqU6eO7rvvPrVq1Uoff/yxFixYoN69e0uSqlWrpuXLlyssLExNmzZVTEyMWrVqpS1btsjNzc3sx2KxaP78+ZJ+v11w/fr16tGjh4KDg/XMM8+oX79+WrVqlVl/2bJlOnnypD755BP5+/ub21133WXWCQoK0pdffqnExES1bt1ab775pv75z38qIiLCOScPAIBbgMUwDKOsB1FR2e12eXp6Kjs7W1artayHc0OKWUcUZcgpn2wmvvxxwsRbpjDv5Y0xqfTnfYplSqn3gWs3yZhU1kMo99LT03X77bfrhx9+UJMmTcp6OAAAVAglzTu4UgoAAAC3rNWrVys2NpZACgCAcog1pQAAAHDLiouLK+shAACAYnClFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNOx0DkAAACKt8hS1iPAlQYbZT0CAABuCq6UAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcrkxDqTlz5qhVq1ayWq2yWq0KDQ3VmjVrzP1du3aVxWJx2EaOHOnQxtGjRxUZGalq1arJx8dHY8eOVV5e3lX7zczMVHR0tKxWq7y8vBQTE6MzZ8441NmzZ486d+4sd3d31atXT9OnTy/UztKlSxUcHCx3d3e1bNlSq1evvoGzAQAAAAAAUHGUaShVt25dvfbaa0pJSdGOHTvUrVs3PfDAA0pNTTXrjBgxQsePHze3y8OhS5cuKTIyUhcvXtTWrVu1YMECzZ8/XxMnTrxqv9HR0UpNTVViYqLi4+OVlJSk2NhYc7/dblePHj0UGBiolJQUzZgxQ5MnT9a8efPMOlu3btWgQYMUExOjnTt3KioqSlFRUdq3b99NPEMAAAAAAAC3JothGEZZD+Jy3t7emjFjhmJiYtS1a1e1adNGs2bNKrLumjVr1KdPHx07dky+vr6SpLlz52rcuHE6efKkXF1dCx2zf/9+hYSEaPv27WrXrp0kKSEhQb1799Yvv/yigIAAzZkzRy+++KJsNpvZxvPPP68VK1bowIEDkqQBAwYoJydH8fHxZtsdOnRQmzZtNHfu3BK9V7vdLk9PT2VnZ8tqtZb4HJVHFktZjwBXcsonm4kvf5ww8ZYpzHt5Y0wq/XmfYplS6n3g2k0yJpV+J4v4zJc7g8vVr+8AABRS0ryj3KwpdenSJS1evFg5OTkKDQ01yxcuXKjatWurRYsWGj9+vM6ePWvuS05OVsuWLc1ASpIiIiJkt9sdrra6XHJysry8vMxASpLCw8NVqVIlbdu2zazTpUsXh1ArIiJCaWlp+u2338w64eHhDm1HREQoOTn5Bs4CAAAAAABAxeBS1gPYu3evQkNDdf78eXl4eOjzzz9XSEiIJGnw4MEKDAxUQECA9uzZo3HjxiktLU3Lly+XJNlsNodASpL52mazFdmfzWaTj4+PQ5mLi4u8vb3NY2w2m4KCgoptt2bNmsX2XVy/knThwgVduHDBfG2324utCwAAAAAAcCsr81CqadOm2rVrl7Kzs7Vs2TINGzZMW7ZsUUhIiMM6Ty1btpS/v7/CwsJ0+PBhNWrUqAxHfX2mTZumKVO4/QEAAAAAAKDMb99zdXVV48aN1bZtW02bNk2tW7fW22+/XWTd9u3bS5IOHTokSfLz81NGRoZDnYLXfn5+Rbbh5+enEydOOJTl5eUpMzPTPKYk7RZXp7h+JWn8+PHKzs42t59//rnYugAAAAAAALeyMg+lrpSfn+9wi9vldu3aJUny9/eXJIWGhmrv3r0OIVNiYqKsVqt5C+CVQkNDlZWVpZSUFLNs48aNys/PN0Ov0NBQJSUlKTc316Hdpk2bqmbNmmadDRs2OLSdmJjosB7Wldzc3GS1Wh02AAAAAACAiqhMQ6nx48crKSlJR44c0d69ezV+/Hht3rxZ0dHROnz4sF5++WWlpKToyJEjWrlypYYOHaouXbqoVatWkqQePXooJCREQ4YM0e7du7V27VpNmDBBcXFxcnNzK7LPZs2aqWfPnhoxYoS+++47ffPNNxo1apQGDhyogIAASb+vZeXq6qqYmBilpqZqyZIlevvttzVmzBiznaeeekoJCQl68803deDAAU2ePFk7duzQqFGjSv/EAQAAAAAA/MmVaSh14sQJDR06VE2bNlVYWJi2b9+utWvXqnv37nJ1ddX69evVo0cPBQcH65lnnlG/fv20atUq8/jKlSsrPj5elStXVmhoqB5++GENHTpUU6dONescOXJEFotFmzdvNssWLlyo4OBghYWFqXfv3urUqZPmzZtn7vf09NS6deuUnp6utm3b6plnntHEiRMd1rjq2LGjFi1apHnz5ql169ZatmyZVqxYoRYtWpTuSQMAAAAAALgFWAzDMMp6EKVp06ZN6tu3r3788Ufz1rvywm63y9PTU9nZ2X/6W/kslrIeAa7klE82E1/+OGHiLVOY9/LGmFT68z7FwoM6yqNJxqTS72QRn/lyZ/At/es7AOAWUNK8o9ytKXWzrV69Wi+88EK5C6QAAAAAAAAqMpeyHkBpmzFjRlkPAQAAAAAAAFe45a+UAgAAAAAAQPlDKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcr01Bqzpw5atWqlaxWq6xWq0JDQ7VmzRpz//nz5xUXF6datWrJw8ND/fr1U0ZGhkMbR48eVWRkpKpVqyYfHx+NHTtWeXl5V+03MzNT0dHRslqt8vLyUkxMjM6cOeNQZ8+ePercubPc3d1Vr149TZ8+vVA7S5cuVXBwsNzd3dWyZUutXr36Bs4GAAAAAABAxVGmoVTdunX12muvKSUlRTt27FC3bt30wAMPKDU1VZL09NNPa9WqVVq6dKm2bNmiY8eOqW/fvubxly5dUmRkpC5evKitW7dqwYIFmj9/viZOnHjVfqOjo5WamqrExETFx8crKSlJsbGx5n673a4ePXooMDBQKSkpmjFjhiZPnqx58+aZdbZu3apBgwYpJiZGO3fuVFRUlKKiorRv376bfJYAAAAAAABuPRbDMIyyHsTlvL29NWPGDD344IOqU6eOFi1apAcffFCSdODAATVr1kzJycnq0KGD1qxZoz59+ujYsWPy9fWVJM2dO1fjxo3TyZMn5erqWqj9/fv3KyQkRNu3b1e7du0kSQkJCerdu7d++eUXBQQEaM6cOXrxxRdls9nMNp5//nmtWLFCBw4ckCQNGDBAOTk5io+PN9vu0KGD2rRpo7lz55bovdrtdnl6eio7O1tWq/X6T1o5YLGU9QhwJad8spn48scJE2+ZwryXN8ak0p/3KZYppd4Hrt0kY1Lpd7KIz3y5M7hc/foOAEAhJc07ys2aUpcuXdLixYuVk5Oj0NBQpaSkKDc3V+Hh4Wad4OBg1a9fX8nJyZKk5ORktWzZ0gykJCkiIkJ2u9282upKycnJ8vLyMgMpSQoPD1elSpW0bds2s06XLl0cQq2IiAilpaXpt99+M+tcPraCOgVjK8qFCxdkt9sdNgAAAAAAgIqozEOpvXv3ysPDQ25ubho5cqQ+//xzhYSEmFcpeXl5OdT39fWVzWaTJNlsNodAqmB/wb6i2Gw2+fj4OJS5uLjI29v7mtotrk5x/UrStGnT5OnpaW716tUrti4AAAAAAMCtrMxDqaZNm2rXrl3atm2bHn/8cQ0bNkw//PBDWQ+rVIwfP17Z2dnm9vPPP5f1kAAAAAAAAMqES1kPwNXVVY0bN5YktW3bVtu3b9fbb7+tAQMG6OLFi8rKynK4WiojI0N+fn6SJD8/P3333XcO7RU8na+gzpX8/Px04sQJh7K8vDxlZmY6tHvlU/6ubLe4OsX1K0lubm5yc3Mrdj8AAAAAAEBFUeZXSl0pPz9fFy5cUNu2bVWlShVt2LDB3JeWlqajR48qNDRUkhQaGqq9e/c6hEyJiYmyWq0KCQkpsv3Q0FBlZWUpJSXFLNu4caPy8/PVvn17s05SUpJyc3Md2m3atKlq1qxp1rl8bAV1CsYGAAAAAACA4pVpKDV+/HglJSXpyJEj2rt3r8aPH6/NmzcrOjpanp6eiomJ0ZgxY7Rp0yalpKTokUceUWhoqDp06CBJ6tGjh0JCQjRkyBDt3r1ba9eu1YQJExQXF1fsFUnNmjVTz549NWLECH333Xf65ptvNGrUKA0cOFABAQGSpMGDB8vV1VUxMTFKTU3VkiVL9Pbbb2vMmDFmO0899ZQSEhL05ptv6sCBA5o8ebJ27NihUaNGlf6JAwAAAP6kpk2bprvuuks1atSQj4+PoqKilJaW5lDHZrNpyJAh8vPzU/Xq1XXnnXfqs88+c6iTmZmp6OhoWa1WeXl5KSYmRmfOnLlq3+fPn1dcXJxq1aolDw8P9evXr9DdDxs2bFDHjh1Vo0YN+fn5ady4ccrLyyuyvUOHDqlGjRqF1sEFAJRMmYZSJ06c0NChQ9W0aVOFhYVp+/btWrt2rbp37y5Jmjlzpvr06aN+/fqpS5cu8vPz0/Lly83jK1eurPj4eFWuXFmhoaF6+OGHNXToUE2dOtWsc+TIEVksFm3evNksW7hwoYKDgxUWFqbevXurU6dOmjdvnrnf09NT69atU3p6utq2batnnnlGEydOVGxsrFmnY8eOWrRokebNm6fWrVtr2bJlWrFihVq0aFGKZwwAAAD4c9uyZYvi4uL07bffKjExUbm5uerRo4dycnLMOkOHDlVaWppWrlypvXv3qm/fvurfv7927txp1omOjlZqaqoSExMVHx+vpKQkh9/Xi/L0009r1apVWrp0qbZs2aJjx46pb9++5v7du3erd+/e6tmzp3bu3KklS5Zo5cqVev755wu1lZubq0GDBqlz58434awAQMVkMQzDKOtBlKZNmzapb9+++vHHH81b78oLu90uT09PZWdny2q1lvVwbojFUtYjwJWc8slm4ssfJ0y8ZQrzXt4Yk0p/3qdYppR6H7h2k4xJpd/JIj7z5c7gW+vX95MnT8rHx0dbtmxRly5dJEkeHh6aM2eOhgwZYtarVauWXn/9dT366KPav3+/QkJCtH37drVr106SlJCQoN69e+uXX34x74C4XHZ2turUqaNFixbpwQcflCQdOHBAzZo1U3Jysjp06KAXXnhBiYmJ2r59u3ncqlWr1L9/f504cUI1atQwy8eNG6djx44pLCxMo0ePVlZWVmmcHgD4Uypp3lHu1pS62VavXq0XXnih3AVSAAAAAH4PiyTJ29vbLOvYsaOWLFmizMxM5efna/HixTp//ry6du0qSUpOTpaXl5cZSElSeHi4KlWqpG3bthXZT0pKinJzcxUeHm6WBQcHq379+kpOTpYkXbhwQe7u7g7HVa1aVefPny+0Ju3SpUs1e/bsG3vzAFDBlfnT90rbjBkzynoIAAAAAIqQn5+v0aNH6+6773ZYBuPTTz/VgAEDVKtWLbm4uKhatWr6/PPPzad222w2+fj4OLTl4uIib29v2Wy2Ivuy2WxydXUttP6Tr6+veUxERIRmzZql//znP+rfv79sNpu5NMjx48clSadOndLw4cP1ySef/OnvdgCAsnbLXykFAAAAoHyKi4vTvn37tHjxYofyl156SVlZWVq/fr127NihMWPGqH///tq7d2+pjqdHjx6aMWOGRo4cKTc3N91+++3q3bu3JKlSpd//dBoxYoQGDx5s3moIALh+hFIAAAAAnG7UqFGKj4/Xpk2bVLduXbP88OHDeu+99/Thhx8qLCxMrVu31qRJk9SuXTvzdjk/Pz+dOHHCob28vDxlZmbKz8+vyP78/Px08eLFQms/ZWRkOBwzZswYZWVl6ejRo/rf//6nBx54QJLUsGFDSb/fuvfGG2/IxcVFLi4uiomJUXZ2tlxcXPThhx/e8HkBgIrklr99DwAAAED5YRiGnnzySX3++efavHmzgoKCHPafPXtW0v+7MqlA5cqVlZ+fL0kKDQ1VVlaWUlJS1LZtW0m/h0X5+flq3759kf22bdtWVapU0YYNG9SvXz9JUlpamo4eParQ0FCHuhaLxVws/T//+Y/q1aunO++8U9Lv61ldunTJrPvFF1/o9ddf19atW3Xbbbdd1zkBgIqKUAoAAACA08TFxWnRokX64osvVKNGDXM9J09PT1WtWlXBwcFq3LixHnvsMb3xxhuqVauWVqxYocTERMXHx0uSmjVrpp49e2rEiBGaO3eucnNzNWrUKA0cOLDIJ+8VtB8TE6MxY8bI29tbVqtVTz75pEJDQ9WhQwez3owZM9SzZ09VqlRJy5cv12uvvaZPP/1UlStXNvu+3I4dO1SpUiWHNbEAACXD7XsAAAAAnGbOnDnKzs5W165d5e/vb25LliyRJFWpUkWrV69WnTp1dN9996lVq1b6+OOPtWDBAnN9J0lauHChgoODFRYWpt69e6tTp06aN2+eQ18Wi0Xz5883X8+cOVN9+vRRv3791KVLF/n5+Wn58uUOx6xZs0adO3dWu3bt9OWXX+qLL75QVFRUqZ0PAKjILIZhGGU9iIrKbrfL09NT2dnZf/ond1gsZT0CXMkpn2wmvvxxwsRbpjDv5Y0xqfTnfYplSqn3gWs3yZhU+p0s4jNf7gzm1/eSSE9P1+23364ffvhBTZo0KevhAECFUtK8gyulAAAAANxyVq9erdjYWAIpACjHWFMKAAAAwC0nLi6urIcAAPgDXCkFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDqevgcAAADAgaWsB4BCjLIeAACUAq6UAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdGUaSk2bNk133XWXatSoIR8fH0VFRSktLc2hTteuXWWxWBy2kSNHOtQ5evSoIiMjVa1aNfn4+Gjs2LHKy8u7at+ZmZmKjo6W1WqVl5eXYmJidObMGYc6e/bsUefOneXu7q569epp+vTphdpZunSpgoOD5e7urpYtW2r16tXXeTYAAAAAAAAqjjINpbZs2aK4uDh9++23SkxMVG5urnr06KGcnByHeiNGjNDx48fN7fJw6NKlS4qMjNTFixe1detWLViwQPPnz9fEiROv2nd0dLRSU1OVmJio+Ph4JSUlKTY21txvt9vVo0cPBQYGKiUlRTNmzNDkyZM1b948s87WrVs1aNAgxcTEaOfOnYqKilJUVJT27dt3k84QAAAAAADArcliGIZR1oMocPLkSfn4+GjLli3q0qWLpN+vlGrTpo1mzZpV5DFr1qxRnz59dOzYMfn6+kqS5s6dq3HjxunkyZNydXUtdMz+/fsVEhKi7du3q127dpKkhIQE9e7dW7/88osCAgI0Z84cvfjii7LZbGYbzz//vFasWKEDBw5IkgYMGKCcnBzFx8ebbXfo0EFt2rTR3Llz//D92u12eXp6Kjs7W1arteQnqhyyWMp6BLiSUz7ZTHz544SJt0xh3ssbY1Lpz/sUy5RS7wPXbpIxqfQ7WcRnvtwZ7ITv+lLvAdeq3PzRBgAlUNK8o1ytKZWdnS1J8vb2dihfuHChateurRYtWmj8+PE6e/asuS85OVktW7Y0AylJioiIkN1uV2pqapH9JCcny8vLywykJCk8PFyVKlXStm3bzDpdunRxCLUiIiKUlpam3377zawTHh7u0HZERISSk5OL7PfChQuy2+0OGwAAAAAAQEXkUtYDKJCfn6/Ro0fr7rvvVosWLczywYMHKzAwUAEBAdqzZ4/GjRuntLQ0LV++XJJks9kcAilJ5mubzVZkXzabTT4+Pg5lLi4u8vb2No+x2WwKCgoqtt2aNWsW23dx/U6bNk1TpvB/mgEAAAAAAMpNKBUXF6d9+/bp66+/dii/fJ2nli1byt/fX2FhYTp8+LAaNWrk7GHekPHjx2vMmDHma7vdrnr16pXhiAAAAAAAAMpGubh9b9SoUYqPj9emTZtUt27dq9Zt3769JOnQoUOSJD8/P2VkZDjUKXjt5+dXZBt+fn46ceKEQ1leXp4yMzPNY0rSbnF1iuvXzc1NVqvVYQMAAAAAAKiIyjSUMgxDo0aN0ueff66NGzcWul2uKLt27ZIk+fv7S5JCQ0O1d+9eh5ApMTFRVqtVISEhRbYRGhqqrKwspaSkmGUbN25Ufn6+GXqFhoYqKSlJubm5Du02bdpUNWvWNOts2LDBoe3ExESFhoaW4N0DAAAAAABUXGUaSsXFxemTTz7RokWLVKNGDdlsNtlsNp07d06SdPjwYb388stKSUnRkSNHtHLlSg0dOlRdunRRq1atJEk9evRQSEiIhgwZot27d2vt2rWaMGGC4uLi5ObmVmS/zZo1U8+ePTVixAh99913+uabbzRq1CgNHDhQAQEBkn5fy8rV1VUxMTFKTU3VkiVL9PbbbzvcfvfUU08pISFBb775pg4cOKDJkydrx44dGjVqVCmfOQAAAAAAgD+3Mg2l5syZo+zsbHXt2lX+/v7mtmTJEkmSq6ur1q9frx49eig4OFjPPPOM+vXrp1WrVpltVK5cWfHx8apcubJCQ0P18MMPa+jQoZo6dapZ58iRI7JYLNq8ebNZtnDhQgUHByssLEy9e/dWp06dNG/ePHO/p6en1q1bp/T0dLVt21bPPPOMJk6c6LDGVceOHbVo0SLNmzdPrVu31rJly7RixQqHhdoBAAAAAABQmMUwDKOsB1HaNm3apL59++rHH380b70rD+x2uzw9PZWdnf2nX1/KYinrEeBKTvlkM/HljxMm3jKFeS9vjEmlP+9TLDw9tjyaZEwq/U4W8ZkvdwY74bu+1HvAtbrl/2gDcEspad5RLhY6L22rV6/WCy+8UK4CKQAAAAAAgIrMpawH4AwzZswo6yEAAAAAAADgMhXiSikAAAAAAACUL4RSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOmuK5Rq2LChTp06Vag8KytLDRs2vOFBAQAAAAAA4NZ2XaHUkSNHdOnSpULlFy5c0K+//nrDgwIAAAAAAMCtzeVaKq9cudL877Vr18rT09N8fenSJW3YsEENGjS4aYMDAAAAAADAremaQqmoqChJksVi0bBhwxz2ValSRQ0aNNCbb7550wYHAAAAAACAW9M1hVL5+fmSpKCgIG3fvl21a9culUEBAAAAAADg1nZNoVSB9PT0mz0OAAAAAAAAVCDXFUpJ0oYNG7RhwwadOHHCvIKqwIcffnjDAwMAAAAAAMCt67pCqSlTpmjq1Klq166d/P39ZbFYbva4AAAAAAAAcAu7rlBq7ty5mj9/voYMGXKzxwMAAAAAAIAKoNL1HHTx4kV17NjxZo8FAAAAAAAAFcR1hVKPPvqoFi1adLPHAgAAAAAAgArium7fO3/+vObNm6f169erVatWqlKlisP+t95666YMDgAAAAAAALem6wql9uzZozZt2kiS9u3b57CPRc8BAAAAAADwR64rlNq0adPNHgcAAAAAAAAqkOtaUwoAAAAAAAC4Edd1pdS999571dv0Nm7ceN0DAgAAAAAAwK3vukKpgvWkCuTm5mrXrl3at2+fhg0bdjPGBQAAAAAAgFvYdYVSM2fOLLJ88uTJOnPmzA0NCAAAAAAAALe+m7qm1MMPP6wPP/zwZjYJAAAAAACAW9BNDaWSk5Pl7u5+M5sEAAAAAADALei6bt/r27evw2vDMHT8+HHt2LFDL7300k0ZGAAAAAAAAG5d1xVKeXp6OryuVKmSmjZtqqlTp6pHjx43ZWAAAAAAAAC4dV1XKPXRRx/d7HEAAAAAAACgArmuUKpASkqK9u/fL0lq3ry57rjjjpsyKAAAAAAAANzariuUOnHihAYOHKjNmzfLy8tLkpSVlaV7771XixcvVp06dW7mGAEAAAAAAHCLua6n7z355JM6ffq0UlNTlZmZqczMTO3bt092u11/+9vfStzOtGnTdNddd6lGjRry8fFRVFSU0tLSHOqcP39ecXFxqlWrljw8PNSvXz9lZGQ41Dl69KgiIyNVrVo1+fj4aOzYscrLy7tq35mZmYqOjpbVapWXl5diYmJ05swZhzp79uxR586d5e7urnr16mn69OmF2lm6dKmCg4Pl7u6uli1bavXq1SV+/wAAAAAAABXVdYVSCQkJev/999WsWTOzLCQkRLNnz9aaNWtK3M6WLVsUFxenb7/9VomJicrNzVWPHj2Uk5Nj1nn66ae1atUqLV26VFu2bNGxY8ccnv536dIlRUZG6uLFi9q6dasWLFig+fPna+LEiVftOzo6WqmpqUpMTFR8fLySkpIUGxtr7rfb7erRo4cCAwOVkpKiGTNmaPLkyZo3b55ZZ+vWrRo0aJBiYmK0c+dORUVFKSoqSvv27SvxOQAAAAAAAKiILIZhGNd6UI0aNfTVV1+pTZs2DuU7d+7UPffcI7vdfl2DOXnypHx8fLRlyxZ16dJF2dnZqlOnjhYtWqQHH3xQknTgwAE1a9ZMycnJ6tChg9asWaM+ffro2LFj8vX1lSTNnTtX48aN08mTJ+Xq6lqon/379yskJETbt29Xu3btJP0etPXu3Vu//PKLAgICNGfOHL344ouy2WxmG88//7xWrFihAwcOSJIGDBignJwcxcfHm2136NBBbdq00dy5c//w/drtdnl6eio7O1tWq/W6zll5YbGU9QhwpWv/ZF8HJr78ccLEW6Yw7+WNMan0532KZUqp94FrN8mYVPqdLOIzX+4MdsJ3fan3gGvljF/tAOBmKWnecV1XSnXr1k1PPfWUjh07Zpb9+uuvevrppxUWFnY9TUqSsrOzJUne3t6Sfl9IPTc3V+Hh4Wad4OBg1a9fX8nJyZKk5ORktWzZ0gykJCkiIkJ2u12pqalF9pOcnCwvLy8zkJKk8PBwVapUSdu2bTPrdOnSxSHUioiIUFpamn777TezzuVjK6hTMLYrXbhwQXa73WEDAAAAAACoiK4rlHrvvfdkt9vVoEEDNWrUSI0aNVJQUJDsdrvefffd6xpIfn6+Ro8erbvvvlstWrSQJPMqpYLF1Av4+vrKZrOZdS4PpAr2F+wris1mk4+Pj0OZi4uLvL29r6nd4uoU1++0adPk6elpbvXq1SuyHgAAAAAAwK3uup6+V69ePX3//fdav369eStbs2bNCl01dC3i4uK0b98+ff3119fdRnk3fvx4jRkzxnxtt9sJpgAAAAAAQIV0TVdKbdy4USEhIbLb7bJYLOrevbuefPJJPfnkk7rrrrvUvHlzffXVV9c8iFGjRik+Pl6bNm1S3bp1zXI/Pz9dvHhRWVlZDvUzMjLk5+dn1rnyaXwFrwvqXMnPz08nTpxwKMvLy1NmZuY1tVtcneL6dXNzk9VqddgAAAAAAAAqomsKpWbNmqURI0YUGaZ4enrqscce01tvvVXi9gzD0KhRo/T5559r48aNCgoKctjftm1bValSRRs2bDDL0tLSdPToUYWGhkqSQkNDtXfvXoeQKTExUVarVSEhIUX2GxoaqqysLKWkpJhlGzduVH5+vtq3b2/WSUpKUm5urkO7TZs2Vc2aNc06l4+toE7B2AAAAAAAAFC0awqldu/erZ49exa7v0ePHg5Bzx+Ji4vTJ598okWLFqlGjRqy2Wyy2Ww6d+6cpN+DrpiYGI0ZM0abNm1SSkqKHnnkEYWGhqpDhw5mnyEhIRoyZIh2796ttWvXasKECYqLi5Obm1uR/TZr1kw9e/bUiBEj9N133+mbb77RqFGjNHDgQAUEBEiSBg8eLFdXV8XExCg1NVVLlizR22+/7XD73VNPPaWEhAS9+eabOnDggCZPnqwdO3Zo1KhRJT4HAAAAAAAAFdE1hVIZGRmqUqVKsftdXFx08uTJErc3Z84cZWdnq2vXrvL39ze3JUuWmHVmzpypPn36qF+/furSpYv8/Py0fPlyc3/lypUVHx+vypUrKzQ0VA8//LCGDh2qqVOnmnWOHDkii8WizZs3m2ULFy5UcHCwwsLC1Lt3b3Xq1Enz5s0z93t6emrdunVKT09X27Zt9cwzz2jixImKjY0163Ts2FGLFi3SvHnz1Lp1ay1btkwrVqwwF2oHAAAAAABA0a5pofPbbrtN+/btU+PGjYvcv2fPHvn7+5e4PcMw/rCOu7u7Zs+erdmzZxdbJzAwUKtXry52f3p6ury8vNS6dWuzzNvbW4sWLbpq361atfrDNbIeeughPfTQQ1etAwAAAAAAAEfXdKVU79699dJLL+n8+fOF9p07d06TJk1Snz59btrgbpbVq1frhRdeMNeCAgAAAAAAQNm6piulJkyYoOXLl+v222/XqFGj1LRpU0nSgQMHNHv2bF26dEkvvvhiqQz0RsyYMaOshwAAAAAAAIDLXFMo5evrq61bt+rxxx/X+PHjzdvvLBaLIiIiNHv2bPn6+pbKQAEAAAAAAHDruKZQSvp/6zf99ttvOnTokAzDUJMmTbg1DgAAAAAAACV2zaFUgZo1a+quu+66mWMBAAAAAABABXFNC50DAAAAAAAANwOhFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6co0lEpKStJ9992ngIAAWSwWrVixwmH/8OHDZbFYHLaePXs61MnMzFR0dLSsVqu8vLwUExOjM2fOXLXf8+fPKy4uTrVq1ZKHh4f69eunjIwMhzpHjx5VZGSkqlWrJh8fH40dO1Z5eXkOdTZv3qw777xTbm5uaty4sebPn3/d5wIAAAAAAKAiKdNQKicnR61bt9bs2bOLrdOzZ08dP37c3P7zn/847I+OjlZqaqoSExMVHx+vpKQkxcbGXrXfp59+WqtWrdLSpUu1ZcsWHTt2TH379jX3X7p0SZGRkbp48aK2bt2qBQsWaP78+Zo4caJZJz09XZGRkbr33nu1a9cujR49Wo8++qjWrl17nWcDAAAAAACg4nApy8579eqlXr16XbWOm5ub/Pz8ity3f/9+JSQkaPv27WrXrp0k6d1331Xv3r31xhtvKCAgoNAx2dnZ+te//qVFixapW7dukqSPPvpIzZo107fffqsOHTpo3bp1+uGHH7R+/Xr5+vqqTZs2evnllzVu3DhNnjxZrq6umjt3roKCgvTmm29Kkpo1a6avv/5aM2fOVERExI2cFgAAAAAAgFteuV9TavPmzfLx8VHTpk31+OOP69SpU+a+5ORkeXl5mYGUJIWHh6tSpUratm1bke2lpKQoNzdX4eHhZllwcLDq16+v5ORks92WLVvK19fXrBMRESG73a7U1FSzzuVtFNQpaKMoFy5ckN1ud9gAAAAAAAAqonIdSvXs2VMff/yxNmzYoNdff11btmxRr169dOnSJUmSzWaTj4+PwzEuLi7y9vaWzWYrsk2bzSZXV1d5eXk5lPv6+prH2Gw2h0CqYH/BvqvVsdvtOnfuXJF9T5s2TZ6enuZWr169EpwFAAAAAACAW0+Z3r73RwYOHGj+d8uWLdWqVSs1atRImzdvVlhYWBmO7PqMHz9eY8aMMV/b7XaCKQAAAAAAUCGV6yulrtSwYUPVrl1bhw4dkiT5+fnpxIkTDnXy8vKUmZlZ7DpUfn5+unjxorKyshzKMzIyzGP8/PwKPY2v4PUf1bFarapatWqRfbu5uclqtTpsAAAAAAAAFdGfKpT65ZdfdOrUKfn7+0uSQkNDlZWVpZSUFLPOxo0blZ+fr/bt2xfZRtu2bVWlShVt2LDBLEtLS9PRo0cVGhpqtrt3716HwCsxMVFWq1UhISFmncvbKKhT0AYAAAAAAACKV6a37505c8a86kmS0tPTtWvXLnl7e8vb21tTpkxRv3795Ofnp8OHD+u5555T48aNzafbNWvWTD179tSIESM0d+5c5ebmatSoURo4cGCRT96TJE9PT8XExGjMmDHy9vaW1WrVk08+qdDQUHXo0EGS1KNHD4WEhGjIkCGaPn26bDabJkyYoLi4OLm5uUmSRo4cqffee0/PPfec/vrXv2rjxo369NNP9eWXX5byWQMAAAAAAPjzK9MrpXbs2KE77rhDd9xxhyRpzJgxuuOOOzRx4kRVrlxZe/bs0f3336/bb79dMTExatu2rb766iszGJKkhQsXKjg4WGFhYerdu7c6deqkefPmOfRjsVg0f/588/XMmTPVp08f9evXT126dJGfn5+WL19u7q9cubLi4+NVuXJlhYaG6uGHH9bQoUM1depUs05QUJC+/PJLJSYmqnXr1nrzzTf1z3/+0wzMAAAAAAAAUDyLYRhGWQ+iNKWnp+v222/XDz/8oCZNmpT1cBzY7XZ5enoqOzv7T7++lMVS1iPAlZzyyWbiyx8nTLxlCvNe3hiTSn/ep1imlHofuHaTjEml38kiPvPlzmAnfNeXeg+4Vrf0H20AbjklzTv+VGtKXY/Vq1crNja23AVSAAAAAAAAFVmZrinlDHFxcWU9BAAAAAAAAFzhlr9SCgAAAAAAAOUPoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOF2ZhlJJSUm67777FBAQIIvFohUrVjjsNwxDEydOlL+/v6pWrarw8HAdPHjQoU5mZqaio6NltVrl5eWlmJgYnTlz5qr9nj9/XnFxcapVq5Y8PDzUr18/ZWRkONQ5evSoIiMjVa1aNfn4+Gjs2LHKy8tzqLN582bdeeedcnNzU+PGjTV//vzrPhcAAAAAAAAVSZmGUjk5OWrdurVmz55d5P7p06frnXfe0dy5c7Vt2zZVr15dEREROn/+vFknOjpaqampSkxMVHx8vJKSkhQbG3vVfp9++mmtWrVKS5cu1ZYtW3Ts2DH17dvX3H/p0iVFRkbq4sWL2rp1qxYsWKD58+dr4sSJZp309HRFRkbq3nvv1a5duzR69Gg9+uijWrt27Q2eFQAAAAAAgFufxTAMo6wHIUkWi0Wff/65oqKiJP1+lVRAQICeeeYZPfvss5Kk7Oxs+fr6av78+Ro4cKD279+vkJAQbd++Xe3atZMkJSQkqHfv3vrll18UEBBQqJ/s7GzVqVNHixYt0oMPPihJOnDggJo1a6bk5GR16NBBa9asUZ8+fXTs2DH5+vpKkubOnatx48bp5MmTcnV11bhx4/Tll19q3759ZtsDBw5UVlaWEhISSvSe7Xa7PD09lZ2dLavVet3nrjywWMp6BLiSUz7ZTHz544SJt0xh3ssbY1Lpz/sUy5RS7wPXbpIxqfQ7WcRnvtwZ7ITv+lLvAdeqXPzRBgAlVNK8o9yuKZWeni6bzabw8HCzzNPTU+3bt1dycrIkKTk5WV5eXmYgJUnh4eGqVKmStm3bVmS7KSkpys3NdWg3ODhY9evXd2i3ZcuWZiAlSREREbLb7UpNTTXrXN5GQZ2CNopy4cIF2e12hw0AAAAAAKAiKrehlM1mkySHYKjgdcE+m80mHx8fh/0uLi7y9vY26xTVrqurq7y8vK7ablH9Xj6u4urY7XadO3euyL6nTZsmT09Pc6tXr16R9QAAAAAAAG515TaUuhWNHz9e2dnZ5vbzzz+X9ZAAAAAAAADKRLkNpfz8/CSp0FPxMjIyzH1+fn46ceKEw/68vDxlZmaadYpq9+LFi8rKyrpqu0X1e/m4iqtjtVpVtWrVIvt2c3OT1Wp12AAAAAAAACqichtKBQUFyc/PTxs2bDDL7Ha7tm3bptDQUElSaGiosrKylJKSYtbZuHGj8vPz1b59+yLbbdu2rapUqeLQblpamo4ePerQ7t69ex0Cr8TERFmtVoWEhJh1Lm+joE5BGwAAAAAAACieS1l2fubMGR06dMh8nZ6erl27dsnb21v169fX6NGj9corr6hJkyYKCgrSSy+9pICAAPMJfc2aNVPPnj01YsQIzZ07V7m5uRo1apQGDhxY5JP3pN8XS4+JidGYMWPk7e0tq9WqJ598UqGhoerQoYMkqUePHgoJCdGQIUM0ffp02Ww2TZgwQXFxcXJzc5MkjRw5Uu+9956ee+45/fWvf9XGjRv16aef6ssvvyzdkwYAAAAAAHALKNMrpXbs2KE77rhDd9xxhyRpzJgxuuOOOzRx4kRJ0nPPPacnn3xSsbGxuuuuu3TmzBklJCTI3d3dbGPhwoUKDg5WWFiYevfurU6dOmnevHkO/VgsFs2fP998PXPmTPXp00f9+vVTly5d5Ofnp+XLl5v7K1eurPj4eFWuXFmhoaF6+OGHNXToUE2dOtWsExQUpC+//FKJiYlq3bq13nzzTf3zn/9UREREaZwqAAAAAACAW4rFMAyjrAdRmtLT03X77bfrhx9+UJMmTcp6OA7sdrs8PT2VnZ39p19fymIp6xHgSk75ZDPx5Y8TJt4yhXkvb4xJpT/vUyxTSr0PXLtJxqTS72QRn/lyZ7ATvutLvQdcq1v6jzYAt5yS5h3ldk2pm2X16tWKjY0td4EUAAAAAABARVama0o5Q1xcXFkPAQAAAAAAAFe45a+UAgAAAAAAQPlDKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUgAAAAAAAHA6QikAAAAAAAA4HaEUAAAAAAAAnI5QCgAAAAAAAE5HKAUAAAAAAACnI5QCAAAAAACA0xFKAQAAAAAAwOkIpQAAAAAAAOB0hFIAAAAAAABwOkIpAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAAAApyOUAgAAAAAAgNMRSgEAAAAAAMDpCKUAAAAAAADgdIRSAAAAAAAAcDpCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATleuQ6nJkyfLYrE4bMHBweb+8+fPKy4uTrVq1ZKHh4f69eunjIyMq7ZpGIYmTpwof39/Va1aVeHh4Tp48KBDnczMTEVHR8tqtcrLy0sxMTE6c+aMQ509e/aoc+fOcnd3V7169TR9+vSb98YBAAAAAABuceU6lJKk5s2b6/jx4+b29ddfm/uefvpprVq1SkuXLtWWLVt07Ngx9e3b96rtTZ8+Xe+8847mzp2rbdu2qXr16oqIiND58+fNOtHR0UpNTVViYqLi4+OVlJSk2NhYc7/dblePHj0UGBiolJQUzZgxQ5MnT9a8efNu/gkAAAAAAAC4BbmU9QD+iIuLi/z8/AqVZ2dn61//+pcWLVqkbt26SZI++ugjNWvWTN9++606dOhQ6BjDMDRr1ixNmDBBDzzwgCTp448/lq+vr1asWKGBAwdq//79SkhI0Pbt29WuXTtJ0rvvvqvevXvrjTfeUEBAgBYuXKiLFy/qww8/lKurq5o3b65du3bprbfecgivAAAAAAAAULRyf6XUwYMHFRAQoIYNGyo6OlpHjx6VJKWkpCg3N1fh4eFm3eDgYNWvX1/JyclFtpWeni6bzeZwjKenp9q3b28ek5ycLC8vLzOQkqTw8HBVqlRJ27ZtM+t06dJFrq6uZp2IiAilpaXpt99+K/a9XLhwQXa73WEDAAAAAACoiMp1KNW+fXvNnz9fCQkJmjNnjtLT09W5c2edPn1aNptNrq6u8vLycjjG19dXNputyPYKyn19fYs9xmazycfHx2G/i4uLvL29HeoU1cblfRRl2rRp8vT0NLd69er9wRkAAAAAAAC4NZXr2/d69epl/nerVq3Uvn17BQYG6tNPP1XVqlXLcGTXZ/z48RozZoz52m63E0wBAAAAAIAKqVxfKXUlLy8v3X777Tp06JD8/Px08eJFZWVlOdTJyMgocg0qSWb5lU/ou/wYPz8/nThxwmF/Xl6eMjMzHeoU1cblfRTFzc1NVqvVYQMAAAAAAKiI/lSh1JkzZ3T48GH5+/urbdu2qlKlijZs2GDuT0tL09GjRxUaGlrk8UFBQfLz83M4xm63a9u2beYxoaGhysrKUkpKilln48aNys/PV/v27c06SUlJys3NNeskJiaqadOmqlmz5k19zwAAAAAAALeich1KPfvss9qyZYuOHDmirVu36v/+7/9UuXJlDRo0SJ6enoqJidGYMWO0adMmpaSk6JFHHlFoaGiRT96TJIvFotGjR+uVV17RypUrtXfvXg0dOlQBAQGKioqSJDVr1kw9e/bUiBEj9N133+mbb77RqFGjNHDgQAUEBEiSBg8eLFdXV8XExCg1NVVLlizR22+/7XBrHgAAAAAAAIpXrteU+uWXXzRo0CCdOnVKderUUadOnfTtt9+qTp06kqSZM2eqUqVK6tevny5cuKCIiAi9//77Dm00aNBAw4cP1+TJkyVJzz33nHJychQbG6usrCx16tRJCQkJcnd3N49ZuHChRo0apbCwMLP9d955x9zv6empdevWKS4uTm3btlXt2rU1ceJExcbGlv5JAQAAAAAAuAVYDMMwynoQpeXs2bOqVauW1qxZo65du5b1cAqx2+3y9PRUdnb2n359KYulrEeAKznlk83Elz9OmHjLFOa9vDEmlf68T7FMKfU+cO0mGZNKv5NFfObLncFO+K4v9R5wrW7ZP9oA3JJKmneU69v3btSmTZvUrVu3chlIAQAAAAAAVGS3dCgVGRmpL7/8sqyHAQAAAAAAgCvc0qEUAAAAAAAAyidCKQAAAAAAADgdoRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAABOl5SUpPvuu08BAQGyWCxasWKFw/6MjAwNHz5cAQEBqlatmnr27KmDBw9etc2uXbvKYrEU2iIjI806hmFo4sSJ8vf3V9WqVRUeHl6o3e+//17du3eXl5eXatWqpdjYWJ05c+amvXcAvyOUAgAAAAA4XU5Ojlq3bq3Zs2cX2mcYhqKiovTjjz/qiy++0M6dOxUYGKjw8HDl5OQU2+by5ct1/Phxc9u3b58qV66shx56yKwzffp0vfPOO5o7d662bdum6tWrKyIiQufPn5ckHTt2TOHh4WrcuLG2bdumhIQEpaamavjw4Tf9HAAVnUtZDwAAAAAAUPH06tVLvXr1KnLfwYMH9e2332rfvn1q3ry5JGnOnDny8/PTf/7zHz366KNFHuft7e3wevHixapWrZoZShmGoVmzZmnChAl64IEHJEkff/yxfH19tWLFCg0cOFDx8fGqUqWKZs+erUqVfr+OY+7cuWrVqpUOHTqkxo0b35T3D4ArpQAAAAAA5cyFCxckSe7u7mZZpUqV5Obmpq+//rrE7fzrX//SwIEDVb16dUlSenq6bDabwsPDzTqenp5q3769kpOTzb5dXV3NQEqSqlatKknX1DeAP0YoBQAAAAAoV4KDg1W/fn2NHz9ev/32my5evKjXX39dv/zyi44fP16iNr777jvt27fP4aoqm80mSfL19XWo6+vra+7r1q2bbDabZsyYoYsXL+q3337T888/L0kl7htAyRBKAQAAAADKlSpVqmj58uX673//K29vb1WrVk2bNm1Sr169HK5gupp//etfatmypf7yl79cU9/NmzfXggUL9Oabb6patWry8/NTUFCQfH19S9w3gJLhEwUAAAAAKHfatm2rXbt2KSsrS8ePH1dCQoJOnTqlhg0b/uGxOTk5Wrx4sWJiYhzK/fz8JP3+ZL/LZWRkmPskafDgwbLZbPr111916tQpTZ48WSdPnixR3wBKjlAKAAAAAFBueXp6qk6dOjp48KB27NhhLlB+NUuXLtWFCxf08MMPO5QHBQXJz89PGzZsMMvsdru2bdum0NDQQu34+vrKw8NDS5Yskbu7u7p3737jbwiAiafvAQAAAACc7syZMzp06JD5Oj09Xbt27ZK3t7fq16+vpUuXqk6dOqpfv7727t2rp556SlFRUerRo8cftv2vf/1LUVFRqlWrlkO5xWLR6NGj9corr6hJkyYKCgrSSy+9pICAAEVFRZn13nvvPXXs2FEeHh5KTEzU2LFj9dprr8nLy+tmvX0AIpQCAAAAAJSBHTt26N577zVfjxkzRpI0bNgwzZ8/X8ePH9eYMWOUkZEhf39/DR06VC+99JJDG8OHD9eRI0e0efNmsywtLU1ff/211q1bV2S/zz33nHJychQbG6usrCx16tRJCQkJDk/6++677zRp0iSdOXNGwcHB+uCDDzRkyJCb+O4BSNy+BwAAAAAoA127dpVhGIW2+fPnS5L+9re/6eeff9bFixf1008/6eWXX5arq6tDG+np6eratatDWdOmTWUYRrG32lksFk2dOlU2m03nz5/X+vXrdfvttzvU+fjjj3Xq1ClduHBBu3fvJpC6yZKSknTfffcpICBAFotFK1ascNhvGIYmTpwof39/Va1aVeHh4Tp48OBV25w2bZruuusu1ahRQz4+PoqKilJaWppDna5du8pisThsI0eOdKhz9OhRRUZGqlq1avLx8dHYsWOVl5d3U943CiOUAgAAAAD86WRnZ+vw4cN69tlny3oouEY5OTlq3bq1Zs+eXeT+6dOn65133tHcuXO1bds2Va9eXRERETp//nyxbW7ZskVxcXH69ttvlZiYqNzcXPXo0UM5OTkO9UaMGKHjx4+b2/Tp0819ly5dUmRkpC5evKitW7dqwYIFmj9/viZOnHhz3jgK4fY9AAAAAMCfjqenp3755ZeyHgauQ69evdSrV68i9xmGoVmzZmnChAnmovYff/yxfH19tWLFCg0cOLDI4xISEhxez58/Xz4+PkpJSVGXLl3M8mrVqjk8afFy69at0w8//KD169fL19dXbdq00csvv6xx48Zp8uTJha7Uw43jSikAAAAAAFAupKeny2azKTw83Czz9PRU+/btlZycXOJ2srOzJUne3t4O5QsXLlTt2rXVokULjR8/XmfPnjX3JScnq2XLlvL19TXLIiIiZLfblZqaer1vCVfBlVIAAAAAAKBcsNlskuQQDBW8Ltj3R/Lz8zV69GjdfffdatGihVk+ePBgBQYGKiAgQHv27NG4ceOUlpam5cuXm30X1e/l48LNRSgFAAAAAABuGXFxcdq3b5++/vprh/LY2Fjzv1u2bCl/f3+FhYXp8OHDatSokbOHCXH7HgAAAAAAKCcK1nvKyMhwKM/IyCh2LajLjRo1SvHx8dq0aZPq1q171brt27eXJB06dMjsu6h+Lx8Xbi5CKQAAAACAZGErd1sFFBQUJD8/P23YsMEss9vt2rZtm0JDQ4s9zjAMjRo1Sp9//rk2btyooKCgP+xr165dkiR/f39JUmhoqPbu3asTJ06YdRITE2W1WhUSEnKd7whXw+17AAAAAADAac6cOWNenST9vrj5rl275O3trfr162v06NF65ZVX1KRJEwUFBemll15SQECAoqKiim0zLi5OixYt0hdffKEaNWqYa0B5enqqatWqOnz4sBYtWqTevXurVq1a2rNnj55++ml16dJFrVq1kiT16NFDISEhGjJkiKZPny6bzaYJEyYoLi5Obm5upXpOKipCKQAAAAAA4DQ7duzQvffea74eM2aMJGnYsGGaP3++nnvuOeXk5Cg2NlZZWVnq1KmTEhIS5O7ubh7TtWtXNWjQQPPnz5ckzZkzxyy/3EcffaThw4fL1dVV69ev16xZs5STk6N69eqpX79+mjBhglm3cuXKio+P1+OPP67Q0FBVr15dw4YN09SpU0vpTIBQCgAAAAAAOE3Xrl1lGEax+y0Wi6ZOnXrVMCg9PV3Dhw83X1+tPUmqV6+etmzZ8odjCwwM1OrVq/+wHm4O1pQCAAAAAAB/GqmpqfL09NTQoUPLeii4QVwpBQAAAAAA/jSaN2+uPXv2lPUwcBNwpRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTsdA5AAAAAAAVmqWsB4BCjLIegFNwpRQAAAAAAACcjlAKAAAAAAAATkcoBQAAAAAAAKcjlAIAAAAAAIDTEUoBAAAAAADA6QilAAAAAAAA4HSEUjfB7Nmz1aBBA7m7u6t9+/b67rvvynpIAAAAAAAA5Rqh1A1asmSJxowZo0mTJun7779X69atFRERoRMnTpT10AAAAAAAAMotQqkb9NZbb2nEiBF65JFHFBISorlz56patWr68MMPy3poAAAAAAAA5ZZLWQ/gz+zixYtKSUnR+PHjzbJKlSopPDxcycnJhepfuHBBFy5cMF9nZ2dLkux2e+kPFhUOP1YVlDMm/nzpd4Fr44x/R84z8eWSU36HOFv6XeAa8Y98hcSsV1BMfAX25578gt9RDMO4aj1CqRvwv//9T5cuXZKvr69Dua+vrw4cOFCo/rRp0zRlypRC5fXq1Su1MaLi8vQs6xGgTDDxFZLna8x7RfWa52tlPQSUhRF85isiZr2CYuIrsFtj8k+fPi3Pq/yNQijlROPHj9eYMWPM1/n5+crMzFStWrVksVjKcGSQfk9y69Wrp59//llWq7WshwMnYd4rLua+YmLeKybmveJi7ism5r1iYt7LF8MwdPr0aQUEBFy1HqHUDahdu7YqV66sjIwMh/KMjAz5+fkVqu/m5iY3NzeHMi8vr9IcIq6D1WrlS6wCYt4rLua+YmLeKybmveJi7ism5r1iYt7Lj6tdIVWAhc5vgKurq9q2basNGzaYZfn5+dqwYYNCQ0PLcGQAAAAAAADlG1dK3aAxY8Zo2LBhateunf7yl79o1qxZysnJ0SOPPFLWQwMAAAAAACi3CKVu0IABA3Ty5ElNnDhRNptNbdq0UUJCQqHFz1H+ubm5adKkSYVuscStjXmvuJj7iol5r5iY94qLua+YmPeKiXn/c7IYf/R8PgAAAAAAAOAmY00pAAAAAAAAOB2hFAAAAAAAAJyOUAoAAAAAAABORygFAAAAAPhTYElk4NZCKIVbGv9oAQAAAH9+69evlyRZLBZ+xwduIYRSuKWlpqaW9RAAAKXs/PnzZT0ElBH+MAUqhp07/7/27jyspr39H/h7N0kqmpQpdZIhx1QoKiSEZJ7nKWNIhwqROTNlqpzjmEKkKGPiRCfzUBFN50glVFJJadr37w/f1k+P5/l+n0Pa9na/rst16bPWzr2vZa+113t9hofo06cP5s+fD4CDKcZkCYdSTGYdPXoUU6ZMQUFBAcRisaTLYTUoMzMTV65cwcuXLyVdCqthmZmZuHHjhqTLYDUoJSUFy5cvx++//843KD8gkUgEACgpKZFwJYyxb8nAwAC7d+9GYGAgFixYAICDqR8NH2vZxaEUk1kmJiY4deoU1NXVkZOTI+lyWA2Jj49H//79sX//fiQlJUm6HFaDPnz4gHHjxmHFihWIioqSdDmsBjx69Ai2trbIyspC3bp1hYCCyb5PHzYFBQWhT58+ePfunQQrYpLEN6uyjYigoaGBmTNnwsvLC4GBgfDw8ADAwdSP4D8dX+50IDs4lGIyq3379tDX10dcXBy6deuGU6dOSbok9o3Fx8fD0tISffr0gbu7O7p37y7pklgNUlZWxurVq1FQUIAdO3bg2rVrki6JfUPJycmwtbXF2LFj4ePjg6FDh362D9+oyCaxWAw5uY9fYcPDwxEREYE///wTM2fO5GDqB1D5uc7NzRUeOnIgLdsqj3l0dDQSExOhpqaG9evXw93dHQAHU7KMiCASiXDt2jW4urpizpw52LhxIwBATk6Oj7uM4FCKybyysjK0a9cOq1evRmhoqKTLYd/I27dvMWfOHMycORObNm1CmzZthG3v379HXl6e8DNfwGRPRUUFAMDa2hre3t549uwZfHx8OJiSURUVFfD394e9vT28vLygrq4OAHjz5g1iYmJw/PhxZGdn842qjKoMpFxcXLB48WLUqlUL3bt3x/Xr1zF+/HgUFBRIuEL2LYlEIpw+fRrdunVDt27dMGjQIGRmZkq6LPYNycnJISwsDL1794aGhgYWLFiA8ePHY+/evVi4cCEADqZklUgkQnBwMBwcHJCfnw9FRUXs2bMHNjY2EIvFfJ2XEQqSLoCxb83MzAyLFy/Grl27sGTJEgDAwIEDJVwVq27v379Hfn4+evXqJbRFR0cjKioK+/fvh56eHkaOHAknJye+gMmQ1NRUFBQUoHHjxtDU1AQAdOnSBd7e3pg/fz527NgBANxrTsbIy8sjLS0N8vLyAD5+aQ0JCcHp06cRHByMWrVqQUFBAefOnYOZmZnwpJXJjsjISAQEBCA4OBiWlpYAAF9fX+zfvx+TJk3CoUOHoKamJuEqWXWq/Bw/ePAAjo6OcHJyQv369bFr1y707dsXR44cQdu2bSVdJvsGSkpKcPjwYcyYMUPoHZWTk4OOHTvCw8MDysrK8PLyEoIpPt/LjoyMDHh4eGD9+vVwcnLCs2fPcPz4cRgbGwsPKADwcZdy3FOKyZTKJyTp6elITExEcnIyAKBjx46YPXs2OnXqhCVLlnCPKRmUnZ2N58+f4/3796ioqMDevXvh7OyM8PBw9OzZE82bN8eyZcsQFhYm6VJZNXnx4gV++ukntG/fHoMHD8a0adNw+vRpvHz5EtbW1ggICEBqaip2796NK1euSLpcVk2ICOXl5dDT00NWVhb27NkDV1dXzJs3D7Vq1cL+/fvx+PFjtGvXDrNnzwbAQ3tk0du3byEWi2FgYCC0TZ48GcOHD0d4eDgcHR15KJ+MEYlEiI2NRXp6OpycnODp6YnZs2fjzp07UFRUxNixY/Ho0SNJl8m+AQUFBaSnp1fp9a6trY1x48bBzs4OGzdurDL5OZMdubm5ICI4OTkhIyMD3bp1w5AhQ+Dv7w8AiIiIAMDHXdpxKMVkRmVCfubMGQwaNAg9e/bE1KlT4ezsDAAwNzcXgqnly5fj5MmTki2YVasOHTpg5MiRGDp0KFq1agVnZ2eMHDkSPj4+8PX1xYoVK6Cnp8eTn8sQZWVldOvWDQBgaWmJ5ORkeHp6omXLlhg3bhweP34MFxcXpKSk4PDhw7h69aqEK2bVRUFBAS4uLgCAX3/9FSdPnsTWrVuxcuVKjBgxAnp6eujSpQsUFBRQXl4u4WrZ1/p0SE7l3xs3bgwdHR3cu3dP2KasrIypU6dCT08PsbGxmDFjBoqLi2u8XvZtFBcXw8HBAUOGDEF6errQXqdOHVy/fh21atXCxIkT8fDhQwlWyb4FeXl5DBw4EGlpaVWOr5aWFszMzNCqVSuEh4fj1atXEqySVafKc72Ghga0tbURFhYGS0tL2NvbY9euXQCAhIQEHDx4sMp1gEknHr7HZIZIJMKFCxcwfvx4eHl5oXfv3jhz5gzc3d2Rn5+P33//Hebm5hCJRNi4cSO2bduGfv36oU6dOpyuywg/Pz/07NkTZWVlsLKyqvIEXU1NDTo6OtDW1pZcgaxaaWlpISgoCEOGDMHVq1dx9OhRaGpq4tSpU3j06BFmzZoFU1NTxMTEICYmBqWlpejSpQtq164t6dLZF6h88FA5PKNp06YIDg4GEUFeXh6qqqpV9s/MzISxsTGvziPlPp3UvKKiAhUVFVBSUkKLFi2gpaWFHTt2oHHjxjAzMwMAFBUVwdTUFGZmZjh+/Diio6OrDOtm0qt27dqIiIjAmDFjcOfOHaSnp6NJkyYgIiGYatOmDebOnYvIyEgoKSlJumT2BSrP9ZmZmSgsLES9evVQv3599O/fHwEBAfD394ejoyNMTU0BAFlZWRg1ahQWLlzIQ3alXOWxv3XrFnJzc9G5c2eoqamBiDB06FCMGTMGvr6+wv6//fYbnj17Bn19fQlWzaqDiHhGOCYjsrOzMX78ePTr1w/Ozs7Izs6GmZkZWrRogbi4ONjZ2eHQoUMAgPv376NBgwZo2LChhKtmX6rywvX8+XN8+PABYrEYrVq1qrLtUx4eHggMDMSVK1f44iXF3rx5g9TUVKioqAjH+82bN+jTpw8+fPiAM2fOoFmzZgCAV69eITU1FadPn0ZcXBy2bt0qvIZJl8rPdHR0NKKjo5Gbm4tevXrB2toatWrVqrJvQUEBNm7cCD8/P0RFRfExlxEbN25EdHQ0KioqMGfOHNjb2+PVq1fo1q0bdHV1YWdnh7Zt28Lb2xsaGho4cuQImjRpgvnz52P58uWSLp99gcrPPRGBiIRwMjk5Gb169YKRkRGOHTsGXV1dYd+ioiK8fv0ahoaGEq6efYnK43j69GksWbIEYrEYRARbW1usWrUK9+/fh7u7O1RVVaGjowMlJSVcunQJd+7cQYsWLSRdPvsKlcf+1KlTwpxxEydORLNmzXDv3j3Y2tqiT58+GDlyJOrXr4/g4GAcPHgQ169f57nkZAExJsXEYjERESUnJxMR0c6dOyk+Pp5evXpFJiYmNGvWLCosLCRnZ2cSiUQ0ZMgQSZbLqknlcT916hS1bNmSGjRoQEZGRuTg4ECFhYVV9r1x4wa5uLiQlpYWPXz4UALVsury5MkTsrGxob59+9KUKVOqbHvz5g116tSJWrRoQYmJiZ+9tri4uKbKZN9IUFAQqaqqUvfu3cnc3JxEIhEtWrSI/v77b2GfPXv20NSpU0lfX58ePHggwWrZ16qoqBD+vnbtWtLR0aF58+aRg4MDiUQi2rlzJxERvXr1iiZNmkTt27cnY2Nj6tWrFxUVFRERkbW1NR08eFAi9bOvU3mdDw8Pp/nz51Pfvn3J39+f7t69S0REiYmJ1KRJE7KxsaHXr19XeQ2TblevXiVVVVXy9vamsrIyWr9+PSkoKAif5Rs3bpCPjw/169ePHB0dKS4uTsIVs+py8+ZN0tDQoP379wvn8UrXrl0jKysratiwIZmYmJC1tTXFxMRIqFJW3TiUYlLv9OnT1Lx5c3r8+LHQ5u3tTf369aOsrCwiItq9ezd17NiRzMzMKD09XVKlsmoUGRlJtWvXpr1799Iff/xBwcHB1KxZM7KwsBACiMDAQGrbti3Z2NjQo0ePJFwx+xpxcXGkpaVFy5YtqxJCxMXFCZ/zymCqVatWlJSURER8kyIrUlJSSF9fn/bt2ycc02PHjpG2tja5ublReXk5ZWVl0dSpU2nevHn/Nphk0unvv/+mjRs30h9//EFERCUlJeTl5UVycnLk4+NDRESlpaX07t07yszMFF63bNky0tPTq3K+YNIlJCSElJWVacqUKWRvb0/t2rUjKysrOn/+PBERJSUlkZGREXXo0EG4DjDpVXlunz9/Ps2cOZOIiF68eEGGhoY0e/ZsYb+SkhJh//Ly8povlFW7ymO/efNm6tmzJxUXFwttnx7jwsJCSk9PpxcvXlBBQYFEamXfBodSTOpUVFQIJ6oXL16Qvb09+fr6Vtln1qxZ1KFDB+HnRYsW0cqVKz/rRcOk15o1az7r+fbs2TP66aefaMSIEULbzZs3haeoTDplZGRQq1atyMXFpUr7hg0bSFFRkdauXUtv374loo/BVJcuXUhPT49SUlIkUC37FuLi4sjAwIBiYmKqBI0BAQEkJydHUVFRRERUVFT02dNVJj3c3Nzo3bt3ws8XL14kkUhEDRs2pOvXrwvtFRUVtGHDBpKXl6c9e/ZU+R2PHj0iBwcHatSoEfeWk2KvXr2ijh070vbt24W2a9eu0cSJE6v0kHj69Cm1bduWUlNTJVQpq27Tp0+nffv2UW5uLjVs2JBmzJghnPdDQkLozJkzVFZWJuEqWXWoPK5Pnz4lIiJHR0eytLQUtn/aY/bRo0eUk5NTswWyGsOr7zGp8eeff6K8vBxycnIQiUS4fv06VqxYgbKyMvTp0wfAx0lQAaB///7Iy8vD4MGDMXHiRPj7+2P06NGoU6eOJN8Cqwb0P9Pg/f3330hNTRXay8vLYWBgAE9PT8THxwsr81hYWKB+/fqSKJVVk1u3bkFVVRWzZ88WJq3euHEj1q5diylTpsDT0xN79uxBXl4eNDU1ERoaitatW0u4avalioqKkJOTg8jISLx48QIFBQVQUVFBeno6ioqKIBKJUFJSAgAYO3YsTExMcPv2bQAfJ0LmieylU2pqKu7fvw9lZWWhrVOnTnB1dUVWVhaePXsGAMLcQq6urvDy8sLcuXNx+vRp4TU///wzhg8fjqtXr6JDhw41/TZYNRGLxXj58iX09PSEtm7dumHq1KnIycnB06dPAQAtW7bEvXv30LRpU0mVyr5C5Xe6t2/fCm0qKirYvHkz2rdvj2HDhmH37t3Cef/kyZO4e/dulRU5mfSqXDW9Xbt2SE5Ohq2tLeLj43Hx4kUAEOaRKygowK+//oqYmBgJVsu+JQ6lmFQ4fPgwPD09kZ+fL7RlZWXh+PHjiIyMRFJSEoCPS8YCQJcuXbB06VIUFxfj3bt3iIqK4gkQpVRZWRkKCwvx9OlTvH37VpjAfNSoUcjPz8fRo0cBfFwiHgA0NTWFG1cmG65du4aCggI0a9YMcnJyKCsrg6amJoKDg+Hn54fdu3fDw8MDO3bswIcPH6CtrY3w8HAYGRlJunT2DyUlJWH27NmwtrZGv3790Lp1a8yePRuFhYWYM2cOpk6dipSUFGFy89LSUtSqVQvq6uoSrpx9jV69euHPP//E5cuXoaCggBMnTiA/Px+amppwc3PD7NmzMW3aNJw7d06Y+FokEmHRokU4dOgQBgwYUOX3TZw4Ec2bN5fQu2FfojJkKC8vBwAoKiqiQYMGePXqFYhIeCDRvXt3aGtr49y5c8JrFRUVa75g9tUqP8cXLlzAtGnTEB4eDgBYsWIF9PT0UFRUhK1bt0JBQQHl5eVYvXo1oqKiMHHiRD7mMiIjIwMXL16Et7c3jI2NYWZmBhsbG2zcuFH4jBcUFGDbtm04ceIEfvrpJwlXzL4ZyXXSYuz/Vtlts6CggF68eEFERKmpqVRaWkpERJcuXaKGDRvSqFGj/uOcQTyUQ3olJyfTnDlzqE2bNqSpqUl6enq0fv16Sk5OptzcXBo+fDj169ePDh8+TEQf5xVxd3enjh07Um5uroSrZ9VBLBbTkiVLqFWrVpSbmyvMLfCvc0WNGTOGevToIZwbmPSJjY2lBg0a0KxZs+jAgQP09OlTcnNzIyMjI2rZsiVt2LCBJk6cSMbGxhQREUHXrl2jZcuWkba2Nv3111+SLp99oUmTJlUZbv/69WuSl5engQMHCnOG5OXl0dy5c0lRUZHOnTtHRJ+fA3g4j/T6dFLzlStX0vPnz4mIyNnZmTQ0NCgyMrLK8XZwcKCVK1dKpFZWvYKCgqh27dq0ceNGYbhtWVkZXbp0iQwNDalp06bUr18/6t+/P+no6PCQXBny4MEDsre3p44dO1aZsPzq1as0YcIEUldXpzZt2lDHjh1JV1eXj72M41CKfbcqA6mUlBQ6e/YsEX1cfcvMzIy2bNki3HyGhIRQkyZNyNHRkeLj44XX8+SH0i02Npb09fVp8uTJtH37dgoKCqLJkyeTgoICDRs2jNLT0yklJYVGjhxJBgYGZGxsTDY2NqShocEXLin3/PlzunDhgnCTGRQURCKRiI4ePUpEH29gKm9QKioqqKSkhGbMmEHu7u58YyqlYmNjSUVFhZYsWfLZMTx27Bh17tyZzM3N6eDBgzRlyhSqXbs2NW/enFq3bs2fdylWVlZGQ4cOpcWLFxMR0a+//kr37t2jO3fukK6uLg0dOpTy8/OJ6GMw5eTkRMrKyhQUFCTJstk3cOrUKVJTU6Nffvmlyne5kSNHUr169WjNmjXk6+tLCxcuJHV1dXry5IkEq2XVISEhgQwMDMjf3/+zdiKirKwsWrZsGTk7O9PmzZt5nkgZc/LkSTI3N6fatWvT5cuXq2zLyMigy5cvk4eHB/3666/84OkHwKEU+669ePGCtLW1ycTEhAIDA6mkpIRGjx5NXbt2JR8fHyGYCg4OpiZNmtCsWbMoNjZWwlWzr1V5g7p06VJhJb1KO3bsIFVVVZo0aRIREaWnp1N0dDS5urrS7t27hVXXmHQSi8U0cOBAat68OZ05c4ZKS0uppKSEBg8eTIqKihQWFlZl/4qKClq6dCk1atSIj72USktLI21t7SoLFIjF4irhlK+vL2lpaQk3L48fP6bnz59TdnZ2jdfLqk9xcTHNmjWLevToQQMGDCB1dXXKyMggIqI7d+6QlpbWZ8HUuHHjqFu3bpIsm1Wz+Ph4aty4Me3bt+/fbnd3d6du3bpR8+bNqWfPnvTw4cOaLZB9E9evXycjIyN6//49lZSU0O7du6l79+5Up04dsre3l3R5rAacPXuWzM3NqWvXrnTr1i2hnVdO/vGIiHimOPb9ioyMhK2tLczMzFC/fn3MnDkTdnZ2mDVrFuLj4zF+/HjMmjULioqKOH36NMaNGwdHR0ds2rQJSkpKki6ffYGUlBR06NABY8eOhZ+fH4CP8w5UVFQI80Zt2LABS5cuxbVr12BtbS3Jclk1EovFkJOTQ35+PoYNG4bCwkIsW7YMDg4OePjwIVxcXBAdHY0FCxaga9euyM7Oxp9//omwsDCe1FiKpaamYuTIkWjQoAEWL14MKysrYRv9z5wjAGBtbQ0dHR0EBwcL/1eYbGjcuDHy8vLg6emJxYsXC+13795Fv3790KNHD/z+++9QU1PD+/fvUbt2bT7+MuTq1atwcXHBhQsXUL9+fcjLy3/2GS8sLER5eTnk5eWhpqYmwWpZdUlOTsaQIUOgq6uL169fo1mzZmjevDmGDRuGLl26wN/fH9OnTwdQ9VrApE/l8UtJSUFRURGKiopgYWEBADh79iy8vb1Rq1YteHp6olOnThKulkkCX9HZd61Hjx6YPHkyysrKoKysjC1btuDy5cvw9fVF69atceTIEfj6+qKsrAyDBw9GYGAg5s6dy4GUFEtMTERxcTE0NDSQnJwM4OPqHAoKCsJEp4sXL4axsTHCwsIAgFdhkQEpKSk4cuQIsrOzUbduXQQHB0NZWRlr1qzB+fPn0aFDB/j7+2PBggXw8/PDhAkTsG3bNhQXFyM6OpoDKSlmYGCAgIAAlJaWYu3atfjzzz//7X4KCgpQUVEBAA4kZERpaSnu3r2LzMxMtG7dGhcvXsSJEyeE7Z06dcLFixcRFRWFgQMHoqioCHXq1IGcnJxwPWDSLyMjAwkJCVBXV4e8vDwqKiqEz/j9+/eRlpYGVVVV1KtXjwMpKVX5PY2IhMnsDQwM4OXlBSMjIwwbNgxbt27Fxo0bYW5ujp49e0JLS0t4PQdS0qsykDp16hT69OkDe3t7DBkyBD179kRqaioGDBgAJycn4TvAjRs3JF0ykwD+Vse+G//6BbNyye9hw4ahffv2mDFjBrS1tbF+/XpERETA19cXP//8M44fP44dO3agrKwMAwYMgLGxsSTKZ9XE3t4eBw4cwOHDh7Fz504hmAL+/5cSeXl5lJeXo6Kioko7k1779+/H5MmTcebMGbx58wbq6uoIDQ2FiooKPD09ce7cORgZGWHz5s14/PgxHjx4gJs3b+LQoUMwMTGRdPnsKxkbG8PHxwcikQhr165FdHQ0gI+fbbFYjIyMDNSuXRu9e/cGwEG0NPv0Wq+kpIROnTqhtLQUERERAIA9e/YgKChI2Kdjx44ICQlB7dq1oaysLLRzMCk7unfvDkNDQ6xevRr5+flCMAUAu3btwvHjxzmElGKVocTly5cxY8YM2NnZwcfHB/n5+XBwcIC/vz9WrVoFIyMjiMVieHp6IiEhgR82yQiRSITo6GhMmjQJHh4eCAkJwenTp/H69Ws4ODggIyMDgwYNwqxZs/Dq1St4e3vjw4cPki6b1TTJjBpkrKrKSc3T0tIoODi4yrasrCxq2bIl7dq1i7Kysmjo0KFkZWVF586do5KSEhoxYgTZ2tryamtS7P3795SdnU0RERHCfCJhYWHUoEEDmjdvHiUnJwv7lpeXU0JCAvXo0YPOnz9PRDz2XFYsXLiQtLW1yc/Pj3JycoiIKD8/n7p3706dO3emkJAQnshcxiUlJVHfvn3Jzs6OoqKihHY3Nzdq164dpaenS7A69rUqr/VEH+cOjIiIoNevXwuf9/T0dOrZsyd1796dTp48+X/+DiZdKq/Vd+/epYMHD9LOnTvpzp07RES0fPlyMjc3J2dnZ8rOzqaEhARatmwZ6ejo8KTmMiAkJITU1dVpypQptGLFClJXV6fp06fTvXv3hH3Onj1LkyZN4pXWZEBmZia9fPlS+Hn79u1ka2tbZRGq4uJiatmyJdnZ2QltZ8+eFVbfZD8WDqXYdyMtLY20tLRIJBJR//79KTAwkBITE4mIKDQ0lKytrSkrK4uePHlCQ4cOpR49elBwcDCVlpZSZmamhKtnXyoxMZEmTpxILVu2JGVlZVJTU6OxY8dSRkYGhYeHk56eHs2bN6/KJNZubm7UuXNnPu4y4tOgad68ef8xmLK0tKQTJ07wypoy7tNg6sGDB7Rx40ZSVVWtsmQ0kz6fPjxwc3MjAwMD0tTUJH19fRo7dqxwfNPT06lXr17Us2dPOnTokKTKZd9IUFAQaWpq0qBBg6hDhw7UoUMHWrt2LZWXl5OnpyeZmZmRnJwctW7dmn766ScOJ2RAbGwsGRkZkZ+fn9BWr149qlu3Lo0YMUJYoCgoKIh++eUXevr0qaRKZdXgwYMHJCcnRxcvXhTanJ2dycTERPi5chGjy5cvU5MmTSguLq7G62TfFw6l2HcjNTWVOnbsSF26dCFTU1OaPn06NW3alPz8/CgwMJAGDBgg9IyJj4+nXr16Ub9+/aiwsFDClbMvFRsbSw0aNKBZs2bRgQMH6OnTp+Tm5kaGhobUokUL+vvvv+nixYtCj6nMzExas2YNqamp8SqLUi4hIYE8PDwoLi6OXrx4UWXbvHnzSFNTk/z8/ITV1fLz86l9+/bUq1cvevfunSRKZjUoKSmJBgwYQPXr1ydFRcUqT9OZdNu1axdpaWlReHg4ZWRkkK+vL/Xt25dsbW3p8ePHRPTxKXv79u1p7ty5Eq6WVae4uDhq2LAh+fr6EtHHm1dlZWVyd3cnoo+94PLz8yk0NJTu3LnDD55kRHR0NK1YsYLEYjGlpaWRgYEBOTs705UrV0hOTo4mTpwohNIfPnyQcLXsa8TExJCamhq5urpWab916xbp6OjQ7t27q7RfvXqVDA0N6a+//qrJMtl3iEMp9l1JSkqioUOH0uDBgyk4OJhCQkKoR48eNHjwYBKJRGRubk4lJSVE9PGmlodySK/Y2FhSUVGhJUuWfDYkKzAwkNq1a0edO3emwsJCOnHiBBkYGFCrVq1IRUWFb1ClXH5+PhkaGpJIJKJOnTqRvr4+/fLLL1Weoq5atYrq169P/v7+lJWVRUREBQUFlJqaKqmyWQ1LSEiggQMHCkEFk25isZjKyspo9OjR9Msvv1TZFhYWRpaWluTp6Sn0qMrJyeGhejImKCiILCwsiIjo77//pqZNm9KMGTOE7Y8ePZJUaayafdozMicnhxISEqisrIyGDx9OkydPpvfv3xMRUefOnUlOTo5mzJjBgZSUi4uLIxUVFfL09KzSnpqaShUVFTRv3jzq2rUr7dy5k4g+Tt3h4eFBbdq0ER5Ash8XzxLJvivGxsZYv349SkpK4OvrCxMTE5w9exZubm6wt7eHk5MTlJSUQERo0aIFGjduLOmS2RdIT0+Hra0t7O3tsX79eigoKFRZkWXkyJGYO3cu4uPjcfToUYwYMQLLly/Hhw8fcPPmTZiZmUn4HbCvUadOHbi5uUFbWxs6OjrYunUr4uPj4enpiebNm6N///6wsrKCgYEBvL29cezYMbx58wZqampo2rSppMtnNaRFixYICgpC69atJV0KqwaVq6gSETIyMqpsGzBgADp06ICgoCCIxWIQEbS0tCAnJydMeM2kS3p6On777Tfs27cPUVFRAABFRUXo6uoiPT0d3bp1g52dHfbs2QMAiIqKQmBgIF6+fCnJstlXKCsrExahKCwsBPBxYQMtLS20aNECpaWlyMjIQOfOnaGiooLy8nKYmppi3759cHV1Ra1atSRZPvsKubm5GDduHJo2bYqVK1cK7V5eXhg8eDDEYjFmz56Nzp07Y/Xq1TA0NISNjQ327t2LgwcPQltbW3LFs+8Ch1Lsu9OiRQt4e3sDAObNm4eYmBhYWFggLCwM48ePB8CrrUm7iooKGBoaoqSkRFj+/dMbFgBwdHSEmZkZzp8/DwCYOnUq4uLi0LZtW4nVzb5OUlISzp07Bzk5OUyYMAHr16/HxYsXkZubiwsXLiA5ORlubm7Q1dWFi4sL8vLy8OTJE/j5+UFeXl7S5TMJUFRUlHQJ7Av9p9XSjI2NcevWLcTGxlZp79ixIzQ0NFBcXFzlGs+ffekTFxcHa2tr+Pv7Y8mSJZgyZQpCQ0PRtm1bnD9/Hs2aNcPQoUOrnNtPnDiBmJgYqKioSLh69k+FhYVBLBZDUVERIpEIYWFh6NevH7p164ZBgwYhPj4eRITCwkK8efMGCQkJuHbtGlatWoWLFy9i6NChMDIykvTbYF9BLBZjwIABUFRUxNKlSwEA27Ztw+bNm7FhwwYoKCigVatWWL58Of744w9Mnz4dc+bMwe3bt3mVRfaRBHtpMfa/+k+rMDHZ8J+O76ddvnv06EFjx46VRHmsmsXExJBIJCIfHx+hraSkhHbv3k1ycnKfdfd+/vw5PXjwgBYvXsyTnjImZT4ddnf37l26d+8e3b59W2jr0qULtWzZkqKioujVq1dUUFBANjY2NGzYMEmUy6pR5dB8d3d3ev/+PV2+fJkaNmxI/fr1IyKiX3/9lRQVFWnTpk30/PlzSklJocWLF5OGhgYP1ZVCDx48IAMDA+G72qNHj0heXp7c3Nxo2bJl1Lt3b1JTUxNW0zx+/DhpaGhQs2bNqEmTJnT//n1Jls+q0evXr2nt2rXUunVrsrS0JG1tbYqMjJR0WUxKiIj+p1sCY9+h5ORkuLi4ICcnB9u3b4eFhYWkS2LVKDk5GfPnzwcRYfny5bC0tATw8YlLZmYmZsyYgVGjRmHSpEkgIu4hJ6ViYmJgaWkJZ2dnrFu3rsq2kpIS/P7773BycoKnpyeWL18OACgvL4eCgoIkymWMfYVPz9Vubm44efIkPnz4gJKSEtjb22PPnj1QUFCAnZ0d0tLSUFZWBl1dXZSXl+PevXtQVFTk872USk9Ph6mpKWxsbHDixAmhvXPnzsjLy8Pdu3ehoKCAwMBAzJ07F7q6ulBRUYFIJMKRI0e4x4QUev/+PQ4ePIj9+/fDxMQEXbt2RVZWFlasWCHsM3v2bBw+fBj37t1Dy5Yt8fTpU2FYn56engSrZ9Xh0/N1ZmYmfv/9d/j5+cHCwkI4D1RUVHCvV/a/4lCKffcSEhKwfPlybN26Ffr6+pIuh1WzT4MpDw8PWFlZAQDc3d1x8eJFnD17lucOk2KPHj1Cly5dsHDhQqxZs0ZoDwwMRK9evaClpYXS0lLs378fTk5OWL16tdD1mzEmvXx8fLB69WqEhoZCWVkZOTk5GDt2LDp37iwMyw4NDUVOTg6UlJQwZswYyMvLcyAtxVJTUzFy5Eg0aNAArq6usLS0hJeXF5YtW4aOHTuiQYMG0NLSwoABA1CvXj0UFxejadOm0NHRga6urqTLZ/9QZRhRVFSEgwcP4vDhw0hOTsbMmTOxdu1alJWVCUOwbWxsoKOjg8DAQA6cZUTl8c/OzoZIJIK8vDw0NDTw9u1b7NmzBwEBARg8eDDWr18PgIMp9r/jUIpJhdLSUigpKUm6DPaNfBpMeXl54fLly1izZg3+/PNPtGvXTtLlsS/04sULNGnSBGPGjEFAQIDQvnHjRixZsgR3794VJq0vLS3FgQMHMGvWLGzatAmLFi2SVNmMsWowefJkqKurw8fHR2hLSkqCqakp5syZg02bNn32Gr5pkX6V13MlJSXUr18fZ86cwZ49e9C5c2fcv38fjx8/xs6dO1GnTh2Ympri1KlTki6ZfYXKYOL9+/c4dOgQtmzZAm1tbdy+fRsAhGDKyckJqampOHv2rIQrZtWh8riHhoZi9erVKC0tRW5uLhYvXowJEyYAAPbu3YuAgAAMGzasykNJxv4dnuicSQUOpGSbsbExfHx8oKioiL59+8LDwwORkZEcSEm5Ro0a4eeff0ZMTAyio6MBAJs2bcKWLVtw6dIlmJmZCRPbKykpwdHREfv27YO9vb0ky2aMfQX6n5VUk5OT8fbtW6G9tLQUzZs3F87veXl5n62sx4GU9DM2Noa3tzeKi4tx5MgRuLq6Yvjw4dDX18eQIUOwfPlyPH36VJgAmUk3kUgEIkKdOnUwadIkuLu7IycnB6NGjQLw/xerKCgogEgkQklJCbg/hPQTiUQIDw/HmDFjMH78eISHh2PcuHFYuHAh7t69C01NTTg6OmLChAnYt28fh1Ls/8Q9pRhj343ExES4urpi/fr1vAy8FCMilJWVCWGyubk53r17hx49euDEiRM4ceIEevbsWeU1t2/fhomJCdTU1CRRMmPsC4nFYsjJff6M08/PD6tXr4a/v3+VoHnHjh0IDAxEZGQkLwEvw/766y/MmTMH8vLyWLp0qTA0/9MhXUw2/GsPx3379mHDhg2oW7cuunTpglq1amHv3r24ffs2r6AsA4gIRIRp06ZBQ0MD27ZtQ3p6Onr16oUePXrAz89P2PfVq1fCMD5eYZH9b7inFGPsu9GiRQsEBQVxICXFkpKSMH/+fIwePRpeXl4APgZO2tra8PX1hYeHx2eBVOWS4R8+fJBEyYyxL/RpIHXv3j1ERETg9evXKC4uxqBBg2BlZYVNmzYhNDQUAPDmzRuEh4ejadOm3ANaxhkZGWHXrl0gIqxdu1boLcuBlGwpLy+HvLw8nj9/jkGDBiElJQXjx4+Hu7s7SkpKEBAQADMzMzx58oQDKSlXXl4u/F1OTg7Pnj1Djx49UFxcDAsLiyqB1MGDBxEbGws9PT04OztzIMX+TxxKMca+K/yFVXrFxsbCysoKGRkZqFWrFjw9PYVg6vr16+jatSt27dqFqKgoiMViAMCKFSuwY8cOHDx4EDo6OpIsnzH2D1UGUosXL0b//v0xYsQIWFhYYPbs2SAirF69Gvr6+hgzZgyaN2+Obt26ITMzE4cPHxaG/TDZ9enQ/EWLFuHWrVuSLol9oX/3Wa2oqICCggL++usvWFlZoWHDhjA0NETt2rUxfvx4TJs2DRYWFrCxsYGhoaEEqmbVITs7G2VlZVBQUMCVK1fw8OFDAICJiQm2bt2KFi1aYMiQIdi1axcA4MOHDwgNDcW5c+d4nkD2X+Phe4wxxr5aXFwcLCwssHDhQqxbtw5isRgLFiyAgoICVq1aBXV1dQAfV+BJTU1FcHAwQkJCsGnTJkRHRwsTnjPGvn+fLgF+9uxZuLi4YO/evWjZsiVCQkJw+vRpKCgo4ODBg1BXV0dMTAzu3LkDXV1djBgxglfZ+8HwKsrSrbI3lEgkQmpqKsrLy1GnTh00aNAAANCmTRu0a9euSthcuSpfSUkJNDQ0JPwO2JfKzs7GuHHjYG5ujtatW2Ps2LE4c+YMHBwccPnyZbi5uaGkpAT379+HsrIyiAjLli3DsWPHEBERwT2k2H+NQynGGGNfJT09HaamprCxscGJEyeE9tGjRyMxMREfPnxAo0aNsGDBAjg4OKB79+6IioqCqqoqIiMjYWpqKsHqGWP/RElJiTAX1P79+5GWlobS0lJh2W8AQuDcv39/eHh4fLYEPD89//HwKsrSZ+vWrejatSu6dOkCAAgODsbcuXNRq1YtZGVlYe7cuVi4cCFUVVWFB0+VPg2umfQqKCjApk2bcOLECTx//hx79+7F1KlTAXycH87b21tYXblTp07IyspCVFQUIiIi0KFDB0mWzqQMD99jjDH2VSoqKmBoaIiSkhJh3pANGzYgLCwMw4YNw6JFi5CZmYn58+cjLS0N165dw9ChQ3H9+nUOpBiTIuHh4fDx8RGGYW3ZsgWrV6/G48ePhSG5ADBkyBC0b98eJ0+erNJeiQOpHw8HUtKlqKgIERERsLW1xYMHD/DmzRvMnDkTS5cuxcmTJ7Fr1y6EhoZi8eLFSE1N/ez1HEhJP7FYDHV1dfTt2xcvX75EgwYNkJ6ejrKyMgAfp9uYP38+Nm/ejC5duiA3NxcmJia4ceMGB1LsH+OeUowxxr5acnIy5s+fDyUlJdSvXx+hoaE4fPgw+vTpAwBIS0uDgYEBfHx84OTkJOFqGWP/1O+//47ly5dj4MCBmDRpEszNzQEA/fr1Q3R0tLCqZmX4EBAQgO3btyM8PByampqSLJ0x9gVev36NhQsX4vz58/D29sa9e/ewc+dOYfv58+eFhU3Wrl37H1fiZNKroKAAAHD37l1cv34dFy9eRM+ePbFmzRoefs2qFZ85GGOMfTVjY2N4e3ujuLgYAQEBcHV1RZ8+fUBEKCsrg7y8PNq2bQs9PT0A/37SVMbY9+n48eNwcnLCtm3bsGHDBpibm6OiogIAcOHCBbRv3x6Ojo4ICQnBy5cvkZWVhX379kFHR4fnk2FMSunq6mL79u3o378/pkyZgps3b+LDhw8gIhAR+vfvDxcXF+zcuRM5OTkcSMmY2NhYtG3bFrGxsbC1tYWzszNsbGxw9epVrFy5UrgG/Pbbb8Lk5/zdjn0pjjgZY4xVi+bNm2Pv3r2YM2cOrly5gs6dO8Pa2hqKiorw8/NDQUGB0LuCu/YzJh2ys7Ph5+eHTZs2YeTIkUJ7cXExYmNjoa2tjevXr2PgwIEYM2YMjIyMYGZmBpFIhDNnzlSZ+JgxJl10dXWxZcsWqKmp4eDBg4iKikLv3r2F7c2bN4eurq4wpIvJjvLycrRr1w7Tp0+Hn58fevToAXd3d4hEIly5cgVJSUlo2rQptm7dioSEBAD83Y59OY60GWOMVRsjIyPs2rULRIR169bh4cOH2LRpEzZv3oxTp06hSZMmki6RMfYPZWVloVGjRsLPe/fuxZQpU2BtbQ1ra2sMGjQIoaGhGDZsGJ4/f47x48cjPDwcSkpKKCsr4xsVxqRAZQ8oAMjPz8erV69QXl6Ohg0bYuvWrRg4cCCGDh2KS5cuIS8vD2KxGJcuXQIRCYsfMOn1r72czMzMsHLlSpiammLq1KmIjIxEvXr14O7ujhEjRqCoqAg3b97Ew4cP0bx5cwlVzWQFzynFGGOs2iUnJ8PFxQV37tzB27dvcfPmTZiZmUm6LMbYP5SdnQ1TU1P07dsXY8aMwZ49e5CUlAQrKysMGTIE+fn5cHFxgaurK5ycnNCxY0fk5+fj0KFDMDMz4wmuGZMSlT0az5w5gx07diA5ORmdOnVCu3btsHLlSuTl5WHOnDkICgqCkZERbG1tERISgrNnz/LE1jLi1q1bUFVVxc8//yy03b9/H1u3bsWtW7dw6NAhWFlZobS0FAoKCigqKoKqqqoEK2aygntKMcYYq3bGxsbYsmULLCws8PDhQw6kGJNSOjo6OHDgAE6ePAlHR0ekpKRgx44dWLNmDXr37g1bW1toaWkhMzMTAHDv3j3o6enB3t5emGeEMfb9qVwZs6SkBMDHoVcXLlzAmDFj4ODggLNnz6Jx48ZYv349zp8/j3r16mHbtm2YMWMGEhMT0atXL8TFxXEgJeUq+6e8ePECXl5eGD16NJ48eSJsNzMzw/z586GmpoZp06bh2rVrUFJSgpycHAdSrNpwTynGGGPfTFlZGRQVFSVdBmPsK2VnZ6OwsBCGhoZV2t++fYtBgwZh/PjxmDp1qrAiU+/evbF37140a9ZMEuUyxv4LGRkZsLOzw4ULF6Cvr49Ro0ahdevWWLFiBd6+fYs2bdpg6NCh8PHxEV6TlZWFpUuXYvHixWjRooUEq2fV5dy5c8jMzISamhqOHTuG169f47fffkPr1q2FfUaPHo2LFy/C0NAQ0dHRqF27Ng/NZtWGe0oxxhj7ZjiQYkw26OjofBZIZWdnY8KECSgtLcW0adOgoKAgTHh8+fJlDqQY+84RET58+IAVK1agvLwc79+/R+vWrZGRkYE2bdrA3t5eCKTOnDmD69evo379+vD39+dASspV9kuJjY3FkCFDULduXYwePRpz5syBpqYmHB0dkZiYKOyvp6eHzZs3Izw8HCoqKhxIsWrFoRRjjDHGGPuv5eTkYMOGDZgyZQqysrIQFRUFeXl5VFRUcBDN2HfsXwfINGzYEDNnzsT9+/dx5swZyMvL49KlS+jRowf69esHX19fAMCbN28QFBSEp0+fQiwWQ06ObyGlnUgkwv3795GSkoJffvlFWF3Vzs4OCxYsgIaGBuzs7LBu3To4OjoiODgYdnZ20NHRkXDlTBbxGYUxxhhjjP3XMjIyEB0djWbNmuHGjRtQVFREeXk55OXlJV0aY+w/EIvFEIlEePv2rdAmLy+PmTNnQiQSISwsDEuXLsXRo0ehpqaGffv2Cb1htm3bhps3b6J3794cSEkxIhLmEistLcWYMWMwYsQIJCUlVQks7ezssGrVKjg4OCAgIAB//fUXQkNDoa+vL6nSmYzjOaUYY4wxxtg/kpeXh7p160IkEqGiooIDKcakwF9//QULCwtYWlrC398fqqqqUFFRwe3bt2FlZYXNmzejUaNGGDVqFEaMGAEVFRVUVFQgNDQUf/zxB09qLsWSkpKwc+dOvHjxAl27dsWiRYuQlpaGcePGIT09HefPn4eJiclnr8vNzUWtWrVQp04dCVTNfhQcdTPGGGOMsX+kXr16EIlEICIOpBiTEmKxGOXl5QgNDcWECROwb98+PH78GObm5pg3bx6OHj0KAwMDXLt2TehVpauri1u3bnEgJcViY2NhZWWFjIwM1KpVC0uWLMHmzZuhr6+PY8eOQUVFBZMmTUJ6evpnr9XU1ORAin1z3FOKMcYYY4wxxmRQ5RxQ5eXlUFBQgI+PD1JTU6GiooI3b97g/v37WL16NTQ1NTFp0iSMGjUKK1euRHFxMWrXrs1zSEm5uLg4WFhYYOHChVi3bh3EYjEWLFgAeXl5rF+/HioqKkhPT8egQYMgJyeH06dPo3HjxpIum/1g+AzDGGOMMcYYYzKkst9BUVERAEBBQQEA0K5dOzx9+hSWlpbYtm0bJk6ciDFjxiA6OhpNmzbFjh07EBcXh9q1awMAr7ImxdLT02Fra4sBAwZg3bp1AAA5OTlkZ2cjMjISpqam6Nu3L27cuIEzZ85ALBajZ8+eePHihYQrZz8aDqUYY4wxxhhjTIaIRCK8evUKJiYmWLZsGdLS0gAA3bt3h6WlJSZOnIjc3Fw4OTkhLCwMjx8/hoKCAgoKCuDh4YGKigrh9zDpVFFRAUNDQ5SUlCA6OhoAsGHDBoSFhWH48OFYvHgxnj9/Dg8PD7x//x4hISGoV68eysrKJFw5+9Hw8D3GGGOMMcYYkzF5eXnw8fHBtm3bYGZmBgcHBzg7OwMAJk+eDADw9vZG3bp18fr1azx58gRbt26Fl5cX2rRpI7nCWbVJTk7G/PnzoaSkhPr16yM0NBSHDx9Gnz59AABpaWkwMDDAnj17MGvWLGGYJ2M1iXtKMcYYY4wxxpiMqVevHlasWIEbN25AU1MTu3fvho2NDRITE2Fvbw8AuHv3LgBAV1cXNjY2CAsL40BKhhgbG8Pb2xvFxcUICAiAq6sr+vTpAyJCWVkZ5OXl0aZNG2hrawMAB1JMIjiUYowxxhhjjDEZZWJiAj8/P+zYsQP5+fno378/Hjx4gMePH+PkyZNV9uXherKnefPm2Lt3L6ytrXHlyhVERUVBJBJBUVERfn5+ePfuHczNzSVdJvuB8fA9xhhjjDHGGPtBLFy4EAkJCXj06BEyMzPh7++P6dOnS7os9o1VDuUjInh5eeHy5cvw9PTEjRs30KFDB0mXx35gHEoxxhhjjDHGmIwjIqEnVGRkJC5evIg9e/bgzp07aNmypYSrYzUhOTkZLi4uuHPnDt6+fYubN2/CzMxM0mWxHxyHUowxxhhjjDH2A/g0mAKAgoICqKurS7AiVtMSExPh6uqK9evXo3Xr1pIuhzEOpRhjjDHGGGOMsR9FWVkZFBUVJV0GYwA4lGKMMcYYY4wxxhhjEsCr7zHGGGOMMcYYY4yxGsehFGOMMcYYY4wxxhircRxKMcYYY4wxxhhjjLEax6EUY4wxxhhjjDHGGKtxHEoxxhhjjDHGGGOMsRrHoRRjjDHGGGOMMcYYq3EcSjHGGGOMMcYYY4yxGsehFGOMMcaYjDlw4ADq1av31b9HJBLh9OnTX/17GGOMMcb+HQ6lGGOMMca+Q5MnT8bgwYMlXQZjjDHG2DfDoRRjjDHGGGOMMcYYq3EcSjHGGGOMSZlt27ahTZs2qFOnDpo0aYI5c+agsLDws/1Onz4NY2NjKCsrw87ODunp6VW2nzlzBqamplBWVsZPP/2EVatWoby8/N/+m6WlpXByckKDBg2grKyMpk2bwsvL65u8P8YYY4z9GDiUYowxxhiTMnJycvDx8UF8fDwOHjyIq1evwtXVtco+RUVFWLduHQ4dOoTo6Gjk5eVh9OjRwvaoqChMnDgRCxYswJMnT+Dn54cDBw5g3bp1//bf9PHxQWhoKE6cOIHExEQEBATAwMDgW75NxhhjjMk4ERGRpItgjDHGGGNVTZ48GXl5ef/VRONBQUGYNWsWcnJyAHyc6HzKlCm4desWzM3NAQAJCQlo1aoVbt++jc6dO6NXr16wtbXFkiVLhN9z5MgRuLq6IjMzE8DHic5DQkIwePBgzJ8/H/Hx8YiIiIBIJKr+N8wYY4yxHw73lGKMMcYYkzIRERGwtbVFo0aNoKamhgkTJuDNmzcoKioS9lFQUECnTp2En1u2bIl69erh6dOnAIDY2FisXr0aqqqqwh9HR0e8fPmyyu+pNHnyZMTExKBFixaYP38+wsPDv/0bZYwxxphM41CKMcYYY0yKpKamYsCAAWjbti1OnTqF+/fvY/fu3QA+zvv03yosLMSqVasQExMj/Hn06BGSk5OhrKz82f6mpqZ49uwZ1qxZg+LiYowcORLDhw+vtvfFGGOMsR+PgqQLYIwxxhhj/7379+9DLBZj69atkJP7+HzxxIkTn+1XXl6Oe/fuoXPnzgCAxMRE5OXloVWrVgA+hkyJiYlo1qzZf/1vq6urY9SoURg1ahSGDx+Ovn37Ijc3F5qamtXwzhhjjDH2o+FQijHGGGPsO5Wfn4+YmJgqbdra2igrK8POnTvh4OCA6Oho+Pr6fvZaRUVFzJs3Dz4+PlBQUICTkxMsLCyEkGrFihUYMGAA9PX1MXz4cMjJySE2NhaPHz/G2rVrP/t927ZtQ4MGDdChQwfIycnh5MmT0NPTQ7169b7FW2eMMcbYD4CH7zHGGGOMfaciIyPRoUOHKn8OHz6Mbdu2YePGjfj5558REBAALy+vz16roqICNzc3jB07FpaWllBVVUVgYKCw3c7ODmfPnkV4eDg6deoECwsLbN++HU2bNv23taipqWHTpk3o2LEjOnXqhNTUVJw/f17orcUYY4wx9k/x6nuMMcYYY4wxxhhjrMbxoy3GGGOMMcYYY4wxVuM4lGKMMcYYY4wxxhhjNY5DKcYYY4wxxhhjjDFW4ziUYowxxhhjjDHGGGM1jkMpxhhjjDHGGGOMMVbjOJRijDHGGGOMMcYYYzWOQynGGGOMMcYYY4wxVuM4lGKMMcYYY4wxxhhjNY5DKcYYY4wxxhhjjDFW4ziUYowxxhhjjDHGGGM1jkMpxhhjjDHGGGOMMVbjOJRijDHGGGOMMcYYYzXu/wG5NO3c32VygQAAAABJRU5ErkJggg==\n"},"metadata":{}},{"name":"stdout","text":"üìå Nh√£n Mirai: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Nh√£n DDoS: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Oversampling nh√£n Spoofing: T·ª´ 383,520 l√™n 400,000 d√≤ng\nüìå Nh√£n BENIGN: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Nh√£n DoS: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Oversampling nh√£n Recon: T·ª´ 280,094 l√™n 400,000 d√≤ng\nüìå Oversampling nh√£n BruteForce: T·ª´ 10,250 l√™n 400,000 d√≤ng\nüìå Oversampling nh√£n Web-based: T·ª´ 19,709 l√™n 400,000 d√≤ng\n\nüìã Ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng b·∫±ng oversampling:\nlabel\nDDoS          400000\nBruteForce    400000\nMirai         400000\nWeb-based     400000\nDoS           400000\nRecon         400000\nSpoofing      400000\nBENIGN        400000\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# **√ÅNH X·∫† NH√ÉN**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer\nimport pickle\nimport os\nimport matplotlib.pyplot as plt\n\n# ƒê∆∞·ªùng d·∫´n l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Gi·∫£ ƒë·ªãnh df_full l√† DataFrame t·ª´ cell ƒë·ªçc d·ªØ li·ªáu tr∆∞·ªõc ƒë√≥ (cuDF)\n# Chuy·ªÉn t·ª´ cuDF sang Pandas\ndf_original = df_full.to_pandas()\n\n# Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o\nif df_original.empty or 'label' not in df_original.columns:\n    raise ValueError(\"‚ùå D·ªØ li·ªáu ƒë·∫ßu v√†o r·ªóng ho·∫∑c thi·∫øu c·ªôt 'label'!\")\n\n# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu cho c·ªôt s·ªë\nnumeric_columns = df_original.select_dtypes(include=[np.number]).columns\ndf_original[numeric_columns] = df_original[numeric_columns].fillna(df_original[numeric_columns].mean())\n\n# T√°ch ƒë·∫∑c tr∆∞ng v√† nh√£n\nX = df_original.drop(columns=['label']).select_dtypes(include=[np.number])\ny = df_original['label']\n\n# Ki·ªÉm tra nh√£n duy nh·∫•t\nprint(\"üìã Nh√£n duy nh·∫•t trong d·ªØ li·ªáu:\", y.unique().tolist())\n\n# Danh s√°ch 46 ƒë·∫∑c tr∆∞ng (gi·∫£ ƒë·ªãnh ch·ªçn 46 c·ªôt s·ªë ƒë·∫ßu ti√™n ho·∫∑c t·ª´ b√†i to√°n 34 nh√£n)\n# N·∫øu b·∫°n c√≥ danh s√°ch c·ª• th·ªÉ, thay v√†o ƒë√¢y\nall_numeric_columns = X.columns.tolist()\nif len(all_numeric_columns) < 46:\n    raise ValueError(f\"‚ùå D·ªØ li·ªáu ch·ªâ c√≥ {len(all_numeric_columns)} c·ªôt s·ªë, kh√¥ng ƒë·ªß 46 ƒë·∫∑c tr∆∞ng!\")\nselected_features = all_numeric_columns[:46]  # Ch·ªçn 46 c·ªôt ƒë·∫ßu ti√™n\n# V√≠ d·ª•: N·∫øu b·∫°n c√≥ danh s√°ch 46 ƒë·∫∑c tr∆∞ng t·ª´ b√†i to√°n 34 nh√£n, thay b·∫±ng:\n# selected_features = [\n#     'IAT', 'Tot size', 'Max', 'Tot sum', 'Magnitue', 'AVG', 'Min', 'Header_Length',\n#     'Protocol Type', 'rst_count', 'Weight', 'Number', 'Variance', 'Std', 'Radius',\n#     'Covariance', 'Duration', 'urg_count', 'flow_duration', 'Rate', 'Srate', 'TCP',\n#     'ack_flag_number', 'syn_count', 'HTTPS', 'ack_count', 'syn_flag_number', 'ICMP',\n#     'fin_count', 'UDP', 'SSH', 'DNS', 'Drate', 'fin_flag_number', 'psh_flag_number',\n#     'LLC', 'ece_flag_number', 'cwr_flag_number', 'Telnet', 'SMTP', 'ARP', 'DHCP',\n#     'Length', 'Correlation', 'Entropy', 'Skewness'\n# ]\n\n# Ki·ªÉm tra xem c√°c ƒë·∫∑c tr∆∞ng c√≥ t·ªìn t·∫°i trong d·ªØ li·ªáu kh√¥ng\nmissing_features = [f for f in selected_features if f not in X.columns]\nif missing_features:\n    raise ValueError(f\"‚ùå C√°c ƒë·∫∑c tr∆∞ng sau kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu: {missing_features}\")\n\n# L·∫•y ch·ªâ s·ªë c·ªßa c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn\nfeature_indices = [list(X.columns).index(f) for f in selected_features]\n\n# √Åp d·ª•ng c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn tr∆∞·ªõc khi chia d·ªØ li·ªáu\nX = X[selected_features]\n\n# Chia d·ªØ li·ªáu th√†nh t·∫≠p train, val, test\nX_temp, X_test, Y_temp, Y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\nX_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.1875, stratify=Y_temp, random_state=42)\n\n# M√£ h√≥a nh√£n (8 nh√£n: DDoS, DoS, Recon, Spoofing, BruteForce, Web-based, Mirai, BENIGN)\nlabel_encoder = LabelEncoder()\nY_train_encoded = label_encoder.fit_transform(Y_train)\nY_val_encoded = label_encoder.transform(Y_val)\nY_test_encoded = label_encoder.transform(Y_test)\nlabel_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\nprint(\"üìä √Ånh x·∫° nh√£n (8 nh√£n):\", label_mapping)\n\n# Ki·ªÉm tra ph√¢n b·ªë nh√£n\nprint(\"\\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p hu·∫•n luy·ªán:\")\nprint(pd.Series(Y_train_encoded).value_counts().rename(label_mapping))\nprint(\"\\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p validation:\")\nprint(pd.Series(Y_val_encoded).value_counts().rename(label_mapping))\nprint(\"\\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p ki·ªÉm tra:\")\nprint(pd.Series(Y_test_encoded).value_counts().rename(label_mapping))\n\n# X·ª≠ l√Ω NaN v√† outlier b·∫±ng KNNImputer\nimputer = KNNImputer(n_neighbors=5)\nX_train_imputed = imputer.fit_transform(X_train)\nX_val_imputed = imputer.transform(X_val)\nX_test_imputed = imputer.transform(X_test)\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng RobustScaler\nscaler = RobustScaler()\nX_train_scaled = scaler.fit_transform(X_train_imputed)\nX_val_scaled = scaler.transform(X_val_imputed)\nX_test_scaled = scaler.transform(X_test_imputed)\n\n# Ki·ªÉm tra gi√° tr·ªã sau khi ch·ªçn ƒë·∫∑c tr∆∞ng\nprint(\"üîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_train_scaled:\")\nprint(pd.DataFrame(X_train_scaled, columns=selected_features).describe().loc[['min', 'max']])\nprint(\"üîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_val_scaled:\")\nprint(pd.DataFrame(X_val_scaled, columns=selected_features).describe().loc[['min', 'max']])\nprint(\"üîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_test_scaled:\")\nprint(pd.DataFrame(X_test_scaled, columns=selected_features).describe().loc[['min', 'max']])\n\n# L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\nnp.save(f\"{output_dir}/X_train_scaled_8labels_46features.npy\", X_train_scaled)\nnp.save(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\", Y_train_encoded)\nnp.save(f\"{output_dir}/X_val_scaled_8labels_46features.npy\", X_val_scaled)\nnp.save(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\", Y_val_encoded)\nnp.save(f\"{output_dir}/X_test_scaled_8labels_46features.npy\", X_test_scaled)\nnp.save(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\", Y_test_encoded)\n\n# L∆∞u c√°c ƒë·ªëi t∆∞·ª£ng x·ª≠ l√Ω\nwith open(f\"{output_dir}/label_encoder_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\nwith open(f\"{output_dir}/scaler_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(scaler, f)\nwith open(f\"{output_dir}/imputer_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(imputer, f)\nwith open(f\"{output_dir}/selected_features_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(selected_features, f)\n\n# In th√¥ng tin chi ti·∫øt\nprint(f\"‚úÖ D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√† l∆∞u trong '{output_dir}'!\")\nprint(f\"üìå S·ªë ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: {len(selected_features)}\")\nprint(f\"üìã C√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: {selected_features}\")\n\n# V·∫Ω bi·ªÉu ƒë·ªì danh s√°ch ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn\nplt.figure(figsize=(14, 6))\nplt.bar(selected_features, [1] * len(selected_features), color='skyblue')\nplt.title('Selected Features for Classification (46 Features, 8 Labels)', fontsize=12, fontweight='bold')\nplt.xlabel('Features', fontsize=10)\nplt.ylabel('Selected', fontsize=10)\nplt.xticks(rotation=45, ha='right', fontsize=8)\nplt.tight_layout()\nplt.savefig(f\"{output_dir}/selected_features_8labels_46features.png\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:52:05.069616Z","iopub.execute_input":"2025-05-01T15:52:05.070332Z","iopub.status.idle":"2025-05-01T15:52:33.632071Z","shell.execute_reply.started":"2025-05-01T15:52:05.070301Z","shell.execute_reply":"2025-05-01T15:52:33.631428Z"}},"outputs":[{"name":"stdout","text":"üìã Nh√£n duy nh·∫•t trong d·ªØ li·ªáu: ['Mirai', 'DDoS', 'Spoofing', 'BENIGN', 'DoS', 'Recon', 'BruteForce', 'Web-based']\nüìä √Ånh x·∫° nh√£n (8 nh√£n): {'BENIGN': 0, 'BruteForce': 1, 'DDoS': 2, 'DoS': 3, 'Mirai': 4, 'Recon': 5, 'Spoofing': 6, 'Web-based': 7}\n\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p hu·∫•n luy·ªán:\n0    260000\n4    260000\n6    260000\n7    260000\n3    260000\n1    260000\n5    260000\n2    260000\nName: count, dtype: int64\n\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p validation:\n7    60000\n5    60000\n4    60000\n1    60000\n6    60000\n2    60000\n3    60000\n0    60000\nName: count, dtype: int64\n\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p ki·ªÉm tra:\n7    80000\n1    80000\n4    80000\n3    80000\n6    80000\n2    80000\n0    80000\n5    80000\nName: count, dtype: int64\nüîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_train_scaled:\n     flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\nmin      -0.082931      -0.078134      -0.922078 -1.855932     -0.270129   \nmax    2057.701837      69.911050       5.181818  5.347458  75807.264431   \n\n            Srate     Drate  fin_flag_number  syn_flag_number  \\\nmin     -0.270129  0.000000              0.0              0.0   \nmax  75807.264431  0.044042              1.0              1.0   \n\n     rst_flag_number  ...        AVG        Std   Tot size       IAT  Number  \\\nmin              0.0  ...  -0.165225  -0.212743  -0.157720 -0.499342 -1.0625   \nmax              1.0  ...  23.125590  66.669532  19.897472  0.507392  0.6875   \n\n     Magnitue     Radius   Covariance  Variance    Weight  \nmin -0.286227  -0.212623    -0.048615      -0.8 -0.681951  \nmax  5.754030  67.040168  2945.545825       0.2  0.500000  \n\n[2 rows x 46 columns]\nüîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_val_scaled:\n     flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\nmin      -0.082931      -0.078134      -0.922078 -1.855932     -0.270129   \nmax    3853.881044      69.465697       5.181818  5.347458  55149.712197   \n\n            Srate      Drate  fin_flag_number  syn_flag_number  \\\nmin     -0.270129   0.000000              0.0              0.0   \nmax  55149.712197  29.715225              1.0              1.0   \n\n     rst_flag_number  ...        AVG        Std   Tot size       IAT  Number  \\\nmin              0.0  ...  -0.165225  -0.212743  -0.157720 -0.499342 -1.0625   \nmax              1.0  ...  17.272997  66.669532  14.386343  0.507392  0.6875   \n\n     Magnitue     Radius   Covariance  Variance    Weight  \nmin -0.286227  -0.212623    -0.048615      -0.8 -0.681951  \nmax  5.047480  67.040168  2945.545825       0.2  0.500000  \n\n[2 rows x 46 columns]\nüîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_test_scaled:\n     flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\nmin      -0.082931      -0.078134      -0.922078 -1.855932     -0.270129   \nmax    2057.701837      69.911050       5.181818  5.347458  66331.322611   \n\n            Srate     Drate  fin_flag_number  syn_flag_number  \\\nmin     -0.270129  0.000000              0.0              0.0   \nmax  66331.322611  0.019357              1.0              1.0   \n\n     rst_flag_number  ...        AVG        Std   Tot size       IAT  Number  \\\nmin              0.0  ...  -0.165225  -0.212743  -0.157720 -0.499342 -1.0625   \nmax              1.0  ...  21.974971  58.822572  19.897472  0.507392  0.6875   \n\n     Magnitue     Radius   Covariance  Variance    Weight  \nmin -0.286227  -0.212623    -0.048615      -0.8 -0.681951  \nmax  5.667244  59.028323  2729.536881       0.2  0.500000  \n\n[2 rows x 46 columns]\n‚úÖ D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√† l∆∞u trong 'processed_data'!\nüìå S·ªë ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: 46\nüìã C√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: ['flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius', 'Covariance', 'Variance', 'Weight']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# **CHUY·ªÇN ƒê·ªîI ƒê·∫∂C TR∆ØNG FUZZY**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport joblib\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (46 ƒë·∫∑c tr∆∞ng)\nX_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels_46features.npy\")\nY_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\nX_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels_46features.npy\")\nY_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\nX_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels_46features.npy\")\nY_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n\n# Ki·ªÉm tra shape\nprint(f\"üìå Shape d·ªØ li·ªáu ƒë·∫ßu v√†o:\")\nprint(f\"  - X_train_scaled: {X_train_scaled.shape}\")\nprint(f\"  - X_val_scaled: {X_val_scaled.shape}\")\nprint(f\"  - X_test_scaled: {X_test_scaled.shape}\")\n\n# Chia 46 ƒë·∫∑c tr∆∞ng th√†nh 8 nh√≥m (7 nh√≥m 6 ƒë·∫∑c tr∆∞ng, 1 nh√≥m 4 ƒë·∫∑c tr∆∞ng)\nn_groups = 8\ngroup_sizes = [6] * 7 + [4]  # [6, 6, 6, 6, 6, 6, 6, 4]\nX_train_grouped = []\nX_val_grouped = []\nX_test_grouped = []\n\nprint(\"üîÑ T·∫°o ƒë·∫∑c tr∆∞ng x√°c su·∫•t nh√≥m b·∫±ng XGBoost...\")\nfor i in range(n_groups):\n    start_idx = sum(group_sizes[:i])\n    end_idx = start_idx + group_sizes[i]\n    X_train_group = X_train_scaled[:, start_idx:end_idx]\n    X_val_group = X_val_scaled[:, start_idx:end_idx]\n    X_test_group = X_test_scaled[:, start_idx:end_idx]\n\n    print(f\"  - Nh√≥m {i+1}: ƒê·∫∑c tr∆∞ng t·ª´ {start_idx} ƒë·∫øn {end_idx-1} (k√≠ch th∆∞·ªõc: {group_sizes[i]})\")\n\n    # Hu·∫•n luy·ªán XGBoost tr√™n nh√≥m ƒë·∫∑c tr∆∞ng\n    xgb = XGBClassifier(\n        n_estimators=50,\n        max_depth=8,\n        min_child_weight=10,\n        tree_method=\"hist\",\n        device=\"cuda\",\n        random_state=42,\n        objective=\"multi:softprob\"\n    )\n    xgb.fit(X_train_group, Y_train_encoded)\n\n    # T·∫°o x√°c su·∫•t d·ª± ƒëo√°n\n    train_probs = xgb.predict_proba(X_train_group)  # Shape: [n_samples, 8]\n    val_probs = xgb.predict_proba(X_val_group)\n    test_probs = xgb.predict_proba(X_test_group)\n\n    X_train_grouped.append(train_probs)\n    X_val_grouped.append(val_probs)\n    X_test_grouped.append(test_probs)\n\n    # L∆∞u m√¥ h√¨nh XGBoost\n    joblib.dump(xgb, f\"{output_dir}/xgb_group_{i}_8labels_46features.joblib\")\n    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m {i+1}/{n_groups}\")\n\n# G·ªôp ƒë·∫∑c tr∆∞ng x√°c su·∫•t\nX_train_grouped = np.concatenate(X_train_grouped, axis=1)  # Shape: [n_samples, 8*8 = 64]\nX_val_grouped = np.concatenate(X_val_grouped, axis=1)\nX_test_grouped = np.concatenate(X_test_grouped, axis=1)\n\n# (T√πy ch·ªçn) K·∫øt h·ª£p v·ªõi top-k ƒë·∫∑c tr∆∞ng g·ªëc\nk = 10  # Ch·ªçn 10 ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t\nxgb_full = XGBClassifier(\n    n_estimators=100,\n    max_depth=10,\n    tree_method=\"hist\",\n    device=\"cuda\",\n    random_state=42\n)\nxgb_full.fit(X_train_scaled, Y_train_encoded)\nfeature_importance = xgb_full.feature_importances_\nsorted_idx = np.argsort(feature_importance)[::-1][:k]\n\n# K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng x√°c su·∫•t v√† ƒë·∫∑c tr∆∞ng g·ªëc\nX_train_combined = np.concatenate([X_train_grouped, X_train_scaled[:, sorted_idx]], axis=1)  # Shape: [n_samples, 64+10 = 74]\nX_val_combined = np.concatenate([X_val_grouped, X_val_scaled[:, sorted_idx]], axis=1)\nX_test_combined = np.concatenate([X_test_grouped, X_test_scaled[:, sorted_idx]], axis=1)\n\n# Chu·∫©n h√≥a l·∫°i d·ªØ li·ªáu\nscaler = StandardScaler()\nX_train_combined = scaler.fit_transform(X_train_combined)\nX_val_combined = scaler.transform(X_val_combined)\nX_test_combined = scaler.transform(X_test_combined)\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{output_dir}/X_train_combined_8labels_46features.npy\", X_train_combined)\nnp.save(f\"{output_dir}/X_val_combined_8labels_46features.npy\", X_val_combined)\nnp.save(f\"{output_dir}/X_test_combined_8labels_46features.npy\", X_test_combined)\nnp.save(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\", Y_train_encoded)\nnp.save(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\", Y_val_encoded)\nnp.save(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\", Y_test_encoded)\njoblib.dump(scaler, f\"{output_dir}/scaler_combined_8labels_46features.joblib\")\n\n# In th√¥ng tin\nprint(f\"‚úÖ ƒê√£ t·∫°o ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p!\")\nprint(f\"üìå Shape: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\nprint(f\"üìå S·ªë ƒë·∫∑c tr∆∞ng: {X_train_combined.shape[1]} (64 x√°c su·∫•t + 10 g·ªëc)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T15:53:19.190307Z","iopub.execute_input":"2025-05-01T15:53:19.191020Z","iopub.status.idle":"2025-05-01T15:55:12.925735Z","shell.execute_reply.started":"2025-05-01T15:53:19.190995Z","shell.execute_reply":"2025-05-01T15:55:12.924877Z"}},"outputs":[{"name":"stdout","text":"üìå Shape d·ªØ li·ªáu ƒë·∫ßu v√†o:\n  - X_train_scaled: (2080000, 46)\n  - X_val_scaled: (480000, 46)\n  - X_test_scaled: (640000, 46)\nüîÑ T·∫°o ƒë·∫∑c tr∆∞ng x√°c su·∫•t nh√≥m b·∫±ng XGBoost...\n  - Nh√≥m 1: ƒê·∫∑c tr∆∞ng t·ª´ 0 ƒë·∫øn 5 (k√≠ch th∆∞·ªõc: 6)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:53:29] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 1/8\n  - Nh√≥m 2: ƒê·∫∑c tr∆∞ng t·ª´ 6 ƒë·∫øn 11 (k√≠ch th∆∞·ªõc: 6)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 2/8\n  - Nh√≥m 3: ƒê·∫∑c tr∆∞ng t·ª´ 12 ƒë·∫øn 17 (k√≠ch th∆∞·ªõc: 6)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 3/8\n  - Nh√≥m 4: ƒê·∫∑c tr∆∞ng t·ª´ 18 ƒë·∫øn 23 (k√≠ch th∆∞·ªõc: 6)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 4/8\n  - Nh√≥m 5: ƒê·∫∑c tr∆∞ng t·ª´ 24 ƒë·∫øn 29 (k√≠ch th∆∞·ªõc: 6)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 5/8\n  - Nh√≥m 6: ƒê·∫∑c tr∆∞ng t·ª´ 30 ƒë·∫øn 35 (k√≠ch th∆∞·ªõc: 6)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 6/8\n  - Nh√≥m 7: ƒê·∫∑c tr∆∞ng t·ª´ 36 ƒë·∫øn 41 (k√≠ch th∆∞·ªõc: 6)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 7/8\n  - Nh√≥m 8: ƒê·∫∑c tr∆∞ng t·ª´ 42 ƒë·∫øn 45 (k√≠ch th∆∞·ªõc: 4)\n‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m 8/8\n‚úÖ ƒê√£ t·∫°o ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p!\nüìå Shape: train (2080000, 74), val (480000, 74), test (640000, 74)\nüìå S·ªë ƒë·∫∑c tr∆∞ng: 74 (64 x√°c su·∫•t + 10 g·ªëc)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# **M√î H√åNH TABNET**","metadata":{}},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 88.53 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\nTrain Loss trung b√¨nh: 0.1004\nVal Loss trung b√¨nh: 0.1024\nTrain Accuracy trung b√¨nh: 96.27%\nVal Accuracy trung b√¨nh: 96.24%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(results_dir, exist_ok=True)\n\n# Contrastive Loss\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_positive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2))\n        loss_negative = torch.mean(label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return (loss_positive + loss_negative) / 2\n\n# Entmax\ndef entmax15(x, dim=-1):\n    x = F.softmax(x * 1.5, dim=dim)\n    return x\n\n# Ghost Batch Normalization\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# TabNet thu·∫ßn t√∫y\nclass TabNet(nn.Module):\n    def __init__(self, input_dim, num_classes, n_d=64, n_a=64, n_steps=5, gamma=1.3, lambda_sparse=1e-8):\n        super(TabNet, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.lambda_sparse = lambda_sparse\n\n        # BatchNorm ƒë·∫ßu v√†o\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # L·ªõp FC ban ƒë·∫ßu\n        self.initial_fc = nn.Linear(input_dim, n_d + n_a)\n        nn.init.xavier_normal_(self.initial_fc.weight)\n        nn.init.zeros_(self.initial_fc.bias)\n\n        # C√°c l·ªõp ch√∫ √Ω (attention) v√† quy·∫øt ƒë·ªãnh (decision) cho t·ª´ng b∆∞·ªõc\n        self.attention_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(n_a, input_dim),\n                nn.BatchNorm1d(input_dim),\n                nn.ReLU()\n            ) for _ in range(n_steps)\n        ])\n        self.decision_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, n_d),\n                nn.BatchNorm1d(n_d),\n                nn.ReLU(),\n                nn.Dropout(0.2)\n            ) for _ in range(n_steps)\n        ])\n\n        # L·ªõp cu·ªëi ƒë·ªÉ t·∫°o embedding (Stage 1) ho·∫∑c logits (Stage 2)\n        self.fc_embed = nn.Linear(n_d * n_steps, n_d)  # D√πng trong Stage 1\n        self.fc_output = nn.Linear(n_d * n_steps, num_classes)  # D√πng trong Stage 2\n        nn.init.xavier_normal_(self.fc_embed.weight)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_embed.bias)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x, stage='classification'):\n        x = torch.clamp(self.bn(x), -50, 50)\n        prior = torch.ones_like(x)\n        outputs = []\n        sparsity_loss = 0\n        masks = []\n\n        for step in range(self.n_steps):\n            # T·∫°o ƒë·∫∑c tr∆∞ng ch√∫ √Ω v√† quy·∫øt ƒë·ªãnh\n            att = self.initial_fc(x)\n            att_d, att_a = att[:, :self.n_d], att[:, self.n_d:]\n            mask = self.attention_layers[step](att_a)\n            mask = entmax15(mask, dim=1)\n            \n            # T√≠nh sparsity loss\n            entropy = -torch.sum(mask * torch.log(mask + 1e-8), dim=1)\n            sparsity_loss += torch.mean(entropy) / self.n_steps / self.input_dim\n            masks.append(mask)\n\n            # C·∫≠p nh·∫≠t prior v√† √°p d·ª•ng mask\n            prior = prior * (self.gamma - mask)\n            masked_x = x * mask\n\n            # T·∫°o ƒë·∫ßu ra quy·∫øt ƒë·ªãnh\n            out = self.decision_layers[step](masked_x)\n            outputs.append(out)\n\n        # K·∫øt h·ª£p ƒë·∫ßu ra t·ª´ t·∫•t c·∫£ c√°c b∆∞·ªõc\n        combined = torch.cat(outputs, dim=1)  # [batch_size, n_d * n_steps]\n\n        # T·∫°o embedding (Stage 1) ho·∫∑c logits (Stage 2)\n        if stage == 'feature_learning':\n            output = self.fc_embed(combined)\n        else:  # stage == 'classification'\n            output = self.fc_output(combined)\n\n        return output, sparsity_loss, masks\n\n# T·∫£i d·ªØ li·ªáu (8 nh√£n, 30 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels.npy\")\n    X_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels.npy\")\n    X_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu scaled v√† nh√£n\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# T·∫£i soft labels t·ª´ XGBoost (8 nh√£n)\ntry:\n    soft_labels_train = np.load(f\"{results_dir}/soft_labels_train_8labels.npy\")\n    soft_labels_val = np.load(f\"{results_dir}/soft_labels_val_8labels.npy\")\n    soft_labels_test = np.load(f\"{results_dir}/soft_labels_test_8labels.npy\")\n    tqdm.write(f\"‚úÖ ƒê√£ t·∫£i soft labels t·ª´ {results_dir}\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i soft labels: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra k√≠ch th∆∞·ªõc soft labels\nif soft_labels_train.shape[0] != X_train_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_train ({soft_labels_train.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_train_scaled ({X_train_scaled.shape[0]})\")\nif soft_labels_val.shape[0] != X_val_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_val ({soft_labels_val.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_val_scaled ({X_val_scaled.shape[0]})\")\nif soft_labels_test.shape[0] != X_test_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_test ({soft_labels_test.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_test_scaled ({X_test_scaled.shape[0]})\")\n\n# N·ªëi soft labels v√†o ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o\nX_train_aug = np.concatenate([X_train_scaled, soft_labels_train], axis=1)  # Shape: (n_train, 38)\nX_val_aug = np.concatenate([X_val_scaled, soft_labels_val], axis=1)        # Shape: (n_val, 38)\nX_test_aug = np.concatenate([X_test_scaled, soft_labels_test], axis=1)      # Shape: (n_test, 38)\ntqdm.write(f\"‚úÖ ƒê√£ n·ªëi soft labels v√†o ƒë·∫∑c tr∆∞ng, shape: train {X_train_aug.shape}, val {X_val_aug.shape}, test {X_test_aug.shape}\")\n\n# Chuy·ªÉn th√†nh tensor\nX_train_tensor = torch.tensor(X_train_aug, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nsoft_labels_train_tensor = torch.tensor(soft_labels_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val_aug, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nsoft_labels_val_tensor = torch.tensor(soft_labels_val, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_aug, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 512\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor, soft_labels_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor, soft_labels_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntqdm.write(f\"üì° Thi·∫øt b·ªã: {device}\")\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_aug.shape[1]  # 38 ƒë·∫∑c tr∆∞ng (30 + 8 soft labels)\nmodel = TabNet(input_dim=input_dim, num_classes=8, n_d=64, n_a=64, n_steps=5).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_ce = nn.CrossEntropyLoss()  # D√πng cho ph√¢n lo·∫°i ƒëa l·ªõp\ncriterion_contrast = ContrastiveLoss(margin=1.0)\n\n# Danh s√°ch l∆∞u d·ªØ li·ªáu\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nepoch_times = []\n\n# Two-Stage Training\nnum_epochs_stage1 = 5\nnum_epochs_stage2 = 100\ndistillation_weight = 0.1  # Gi·ªØ nguy√™n t·ª´ m√£ tr∆∞·ªõc\ntemperature = 5.0  # Gi·ªØ nguy√™n t·ª´ m√£ tr∆∞·ªõc\n\n# Stage 1: Feature Learning\ntqdm.write(\"Stage 1: Feature Learning with Contrastive Loss\")\nfor epoch in range(num_epochs_stage1):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage1})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, _ in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            idx = torch.randperm(X_batch.size(0))\n            X_batch_2 = X_batch[idx]\n            Y_batch_2 = Y_batch[idx]\n            label = (Y_batch == Y_batch_2).float()\n            features, _, _ = model(X_batch, stage='feature_learning')\n            features_2, _, _ = model(X_batch_2, stage='feature_learning')\n            loss = criterion_contrast(features, features_2, label)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item() * X_batch.size(0)\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n    train_losses.append(running_loss / len(train_loader.dataset))\n    train_accuracies.append(0.0)  # Kh√¥ng t√≠nh accuracy trong Stage 1\n    val_losses.append(0.0)\n    val_accuracies.append(0.0)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage1}, Train Loss: {train_losses[-1]:.4f}, Time: {epoch_time:.2f}s\")\n\n# Stage 2: Classification with CE + KL + Sparsity Loss\ntqdm.write(\"Stage 2: Classification with CE + KL + Sparsity Loss\")\nbest_f1 = 0\nfor epoch in range(num_epochs_stage2):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage2})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, soft_labels in pbar:\n            X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n            optimizer.zero_grad()\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            ce_loss = criterion_ce(outputs, Y_batch)  # CrossEntropyLoss cho ƒëa l·ªõp\n            kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels, reduction='batchmean'), min=0.0)\n            loss = ce_loss + distillation_weight * kl_loss + model.lambda_sparse * sparsity_loss\n            loss.backward()\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch, soft_labels in pbar_val:\n                X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n                outputs, sparsity_loss, _ = model(X_batch, stage='classification')\n                ce_loss = criterion_ce(outputs, Y_batch)\n                kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels, reduction='batchmean'), min=0.0)\n                loss = ce_loss + distillation_weight * kl_loss + model.lambda_sparse * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)  # 8 nh√£n\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage2}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n    # L∆∞u m√¥ h√¨nh t·ªët nh·∫•t d·ª±a tr√™n F1\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_with_soft_label_input.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_with_soft_label_input_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/tabnet_8labels_with_soft_label_input_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{results_dir}/train_losses_8labels_with_soft_label_input.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_with_soft_label_input.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/epoch_times_8labels_with_soft_label_input.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\nnp.save(f\"{results_dir}/total_time_8labels_with_soft_label_input.npy\", np.array([total_time]))\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/tabnet_8labels_with_soft_label_input.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            probs = torch.softmax(outputs, dim=1)\n            test_probs.extend(probs.cpu().numpy())\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())  # L∆∞u logits\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)  # 8 nh√£n\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_with_soft_label_input.npy\", np.array(test_probs))\nnp.save(f\"{results_dir}/test_labels_8labels_with_soft_label_input.npy\", np.array(test_labels))\nnp.save(f\"{results_dir}/test_features_8labels_with_soft_label_input.npy\", np.array(test_features))\nnp.save(f\"{results_dir}/feature_importance_8labels_with_soft_label_input.npy\", avg_mask)\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T14:50:54.13372Z","iopub.execute_input":"2025-04-21T14:50:54.13444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**V·∫º C√ÅC S∆† ƒê·ªí TABNET**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\nresults_dir = \"results\"\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_with_soft_label_input.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_with_soft_label_input.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_with_soft_label_input.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_with_soft_label_input.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_with_soft_label_input.npy\")\n    test_features = np.load(f\"{results_dir}/test_features_8labels_with_soft_label_input.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input.npy\")\n    print(\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho TabNet (8 nh√£n, v·ªõi soft label input)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nexpected_epochs = 105  # 5 epoch Stage 1 + 100 epoch Stage 2\nif train_losses.shape != (expected_epochs,) or val_losses.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (expected_epochs,) or val_accuracies.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\nif test_features.shape[0] != test_labels.shape[0]:\n    raise ValueError(f\"Shape c·ªßa test_features v√† test_labels kh√¥ng kh·ªõp: {test_features.shape}, {test_labels.shape}\")\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'BENIGN',\n    1: 'BruteForce',\n    2: 'DDoS',\n    3: 'DoS',\n    4: 'Mirai',\n    5: 'Recon',\n    6: 'Spoofing',\n    7: 'Web-based'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Lo·∫°i b·ªè Stage 1 (5 epoch ƒë·∫ßu), ch·ªâ v·∫Ω Stage 2 (epoch 5 ƒë·∫øn 105)\nstage1_epochs = 5\nstart_epoch = stage1_epochs  # B·∫Øt ƒë·∫ßu t·ª´ epoch 5\nepochs = np.arange(len(train_losses))\n# L·∫•y d·ªØ li·ªáu t·ª´ epoch 5 tr·ªü ƒëi (Stage 2)\ntrain_accuracies_plot = train_accuracies[start_epoch:]\nval_accuracies_plot = val_accuracies[start_epoch:]\ntrain_losses_plot = train_losses[start_epoch:]\nval_losses_plot = val_losses[start_epoch:]\n# √Ånh x·∫° epochs t·ª´ 5-105 th√†nh 0-100 tr√™n tr·ª•c X\nepochs_mapped = (epochs[start_epoch:] - start_epoch)  # √Ånh x·∫°: epoch 5 ‚Üí 0, epoch 105 ‚Üí 100\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ d·ªÖ ƒë·ªçc\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.legend(loc=\"upper right\", fontsize=10)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, 100)\nax1.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nax1.set_ylim(loss_min - 0.005, loss_max + 0.005)  # Th√™m padding nh·ªè ƒë·ªÉ d·ªÖ nh√¨n\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.legend(loc=\"lower right\", fontsize=10)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, 100)\nax2.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nax2.set_ylim(acc_min - 0.5, acc_max + 0.5)  # Th√™m padding nh·ªè ƒë·ªÉ d·ªÖ nh√¨n\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(\"TabNet: Learning Curves (8 Labels, With Soft Label Input)\\nStage 2 (Epoch 5 to 105, Mapped to 0-100)\", \n             fontsize=14, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{results_dir}/learning_curves_tabnet_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(10, 8))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(\"TabNet: Confusion Matrix (Test, 8 Labels)\")\nplt.grid(False)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/confusion_matrix_tabnet_8labels_with_soft_label_input.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(10, 8))  # TƒÉng k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì\nroc_auc_scores = []\nfor i in range(8):\n    # T√≠nh ROC cho t·ª´ng nh√£n (one-vs-rest)\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    roc_auc_scores.append(roc_auc)\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\n\n# T√≠nh ROC-AUC trung b√¨nh (macro-average)\nroc_auc_macro = np.mean(roc_auc_scores)\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"TabNet: ROC Curves (8 Labels, Macro AUC = {roc_auc_macro:.4f})\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\n# Thu h·∫πp tr·ª•c X t·ª´ 0 ƒë·∫øn 0.2\nplt.xlim(0, 0.2)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/roc_curve_tabnet_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\nprint(f\"üìà ROC-AUC Scores (One-vs-Rest):\")\nfor i, score in enumerate(roc_auc_scores):\n    print(f\"{class_names[i]}: {score:.4f}\")\nprint(f\"üìà Macro-average ROC-AUC: {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of test_features: {test_features.shape}\")\nn_samples, n_features = test_features.shape\n\n# Ki·ªÉm tra s·ªë m·∫´u\nif n_samples < 3:\n    print(f\"Warning: Only {n_samples} samples available. Skipping PCA 3D.\")\nelse:\n    # Apply PCA v·ªõi n_components=3\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(test_features)\n        \n        # 3D Plot\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels):\n            idx = test_labels == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\")\n        ax.set_ylabel(\"PC2\")\n        ax.set_zlabel(\"PC3\")\n        ax.set_title(\"TabNet: PCA 3D Visualization (8 Labels)\")\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{results_dir}/pca_3d_tabnet_8labels_with_soft_label_input.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 7Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy ·ªü Stage 2\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(\"\\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T17:31:02.265099Z","iopub.execute_input":"2025-04-21T17:31:02.265396Z","iopub.status.idle":"2025-04-21T17:31:52.223007Z","shell.execute_reply.started":"2025-04-21T17:31:02.265376Z","shell.execute_reply":"2025-04-21T17:31:52.222177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH AUTOINT**","metadata":{}},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 71.91 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\nTrain Loss trung b√¨nh: 0.0019\nVal Loss trung b√¨nh: 0.0019\nTrain Accuracy trung b√¨nh: 93.85%\nVal Accuracy trung b√¨nh: 94.28%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# Focal Loss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.05):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# Contrastive Loss\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_positive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2))\n        loss_negative = torch.mean(label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return (loss_positive + loss_negative) / 2\n\n# Ghost Batch Normalization\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# AutoInt (Automatic Feature Interaction Learning)\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, n_layers=3, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        # Ghost Batch Normalization\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # Embedding layer\n        self.embedding = nn.Linear(input_dim, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight)\n\n        # Multi-Head Self-Attention layers\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        # Feature importance\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight)\n\n        # Fully connected layers\n        self.fc_embed = nn.Linear(embed_dim, embed_dim)  # D√πng trong Stage 1\n        self.fc_output = nn.Linear(embed_dim, num_classes)  # D√πng trong Stage 2\n        nn.init.xavier_normal_(self.fc_embed.weight)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_embed.bias)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x, stage='classification'):\n        # Ghost Batch Normalization\n        x = torch.clamp(self.bn(x), -50, 50)  # [batch_size, input_dim]\n\n        # Feature importance\n        importance = torch.sigmoid(self.importance_layer(x))  # [batch_size, input_dim]\n        sparsity_loss = torch.mean(-importance * torch.log(importance + 1e-8))\n        masks = [importance]\n\n        # Embedding\n        x_embed = self.embedding(x).unsqueeze(1)  # [batch_size, 1, embed_dim]\n\n        # Multi-Head Self-Attention\n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)  # [batch_size, 1, embed_dim]\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))  # Residual + LayerNorm\n\n        embeddings = x_embed.squeeze(1)  # [batch_size, embed_dim]\n\n        # T·∫°o embedding (Stage 1) ho·∫∑c logits (Stage 2)\n        if stage == 'feature_learning':\n            output = self.fc_embed(embeddings)\n        else:  # stage == 'classification'\n            output = self.fc_output(embeddings)\n\n        return output, sparsity_loss, masks\n\n# T·∫£i d·ªØ li·ªáu (8 nh√£n)\ntry:\n    X_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels.npy\")\n    X_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels.npy\")\n    X_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu scaled v√† nh√£n (8 nh√£n)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# T·∫£i soft labels (8 nh√£n)\ntry:\n    soft_labels_train = np.load(f\"{results_dir}/soft_labels_train_8labels.npy\")\n    soft_labels_val = np.load(f\"{results_dir}/soft_labels_val_8labels.npy\")\n    soft_labels_test = np.load(f\"{results_dir}/soft_labels_test_8labels.npy\")\n    tqdm.write(f\"‚úÖ ƒê√£ t·∫£i soft labels t·ª´ {results_dir} (8 nh√£n)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i soft labels: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra k√≠ch th∆∞·ªõc soft labels\nif soft_labels_train.shape[0] != X_train_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_train ({soft_labels_train.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_train_scaled ({X_train_scaled.shape[0]})\")\nif soft_labels_val.shape[0] != X_val_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_val ({soft_labels_val.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_val_scaled ({X_val_scaled.shape[0]})\")\nif soft_labels_test.shape[0] != X_test_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_test ({soft_labels_test.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_test_scaled ({X_test_scaled.shape[0]})\")\nif soft_labels_train.shape[1] != 8:\n    raise ValueError(f\"Soft labels ph·∫£i c√≥ 8 c·ªôt (cho 8 nh√£n), nh∆∞ng c√≥ {soft_labels_train.shape[1]} c·ªôt\")\n\n# N·ªëi soft labels v√†o ƒë·∫ßu v√†o\nX_train_aug = np.concatenate([X_train_scaled, soft_labels_train], axis=1)  # Shape: (n_train, 30 + 8)\nX_val_aug = np.concatenate([X_val_scaled, soft_labels_val], axis=1)\nX_test_aug = np.concatenate([X_test_scaled, soft_labels_test], axis=1)\ntqdm.write(f\"‚úÖ Input shape (sau khi n·ªëi soft labels): train {X_train_aug.shape}, val {X_val_aug.shape}, test {X_test_aug.shape}\")\n\n# Chuy·ªÉn th√†nh tensor\nX_train_tensor = torch.tensor(X_train_aug, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nsoft_labels_train_tensor = torch.tensor(soft_labels_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val_aug, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nsoft_labels_val_tensor = torch.tensor(soft_labels_val, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_aug, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 512\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor, soft_labels_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor, soft_labels_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntqdm.write(f\"üì° Thi·∫øt b·ªã: {device}\")\n\n# T√≠nh alpha cho Focal Loss (cho 8 nh√£n)\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_aug.shape[1]  # 30 ƒë·∫∑c tr∆∞ng + 8 soft labels = 38\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=192, n_layers=3, n_heads=4, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=5e-7)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.05)\ncriterion_contrast = ContrastiveLoss(margin=1.0)\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs_stage1 = 5\nnum_epochs_stage2 = 100\ndistillation_weight = 0.001\ntemperature = 2.0\n\n# Danh s√°ch l∆∞u d·ªØ li·ªáu\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nepoch_times = []\n\n# Stage 1: Feature Learning\ntqdm.write(\"Stage 1: Feature Learning with Contrastive Loss\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs_stage1):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage1})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, _ in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            idx = torch.randperm(X_batch.size(0))\n            X_batch_2 = X_batch[idx]\n            Y_batch_2 = Y_batch[idx]\n            label = (Y_batch == Y_batch_2).float()\n            features, _, _ = model(X_batch, stage='feature_learning')\n            features_2, _, _ = model(X_batch_2, stage='feature_learning')\n            loss = criterion_contrast(features, features_2, label)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item() * X_batch.size(0)\n\n            # T√≠nh accuracy trong Stage 1\n            with torch.no_grad():\n                outputs, _, _ = model(X_batch, stage='classification')\n                preds = torch.argmax(outputs, dim=1)\n                train_preds.extend(preds.cpu().numpy())\n                train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n\n    train_loss = running_loss / len(train_loader.dataset)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    # Validation trong Stage 1\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch, _ in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                outputs, _, _ = model(X_batch, stage='classification')\n                preds = torch.argmax(outputs, dim=1)\n                val_preds.extend(preds.cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                # T√≠nh contrastive loss ƒë·ªÉ b√°o c√°o (kh√¥ng d√πng ƒë·ªÉ t·ªëi ∆∞u)\n                idx_val = torch.randperm(X_batch.size(0))\n                X_batch_2 = X_batch[idx_val]\n                Y_batch_2 = Y_batch[idx_val]\n                label = (Y_batch == Y_batch_2).float()\n                features, _, _ = model(X_batch, stage='feature_learning')\n                features_2, _, _ = model(X_batch_2, stage='feature_learning')\n                loss = criterion_contrast(features, features_2, label)\n                running_val_loss += loss.item() * X_batch.size(0)\n\n    val_loss = running_val_loss / len(val_loader.dataset)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, Time: {epoch_time:.2f}s\")\n\n# Stage 2: Classification with Focal + KL + Sparsity Loss\ntqdm.write(\"Stage 2: Classification with Focal + KL + Sparsity Loss (Reduced Soft Label Influence)\")\nbest_f1 = 0\nfor epoch in range(num_epochs_stage2):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage2})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, soft_labels in pbar:\n            X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n            optimizer.zero_grad()\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            focal_loss = criterion_focal(outputs, Y_batch)\n            kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels / temperature, reduction='batchmean', log_target=False), min=0.0)\n            loss = focal_loss + distillation_weight * kl_loss + 1e-8 * sparsity_loss\n            loss.backward()\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean()\n                ce_loss = F.cross_entropy(outputs, Y_batch, reduction='none', label_smoothing=0.05).mean()\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Sparsity Loss: {sparsity_loss.item():.4f}, Focal Loss: {focal_loss.item():.4f}, \"\n                          f\"CE Loss: {ce_loss.item():.4f}, KL Loss: {kl_loss.item():.4f}, Grad Norm: {grad_norm:.4f}, \"\n                          f\"Running Loss: {running_loss:.4f}, \"\n                          f\"Mask max/min: {masks[-1].max():.4f}/{masks[-1].min():.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch, soft_labels in pbar_val:\n                X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n                outputs, sparsity_loss, _ = model(X_batch, stage='classification')\n                focal_loss = criterion_focal(outputs, Y_batch)\n                kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels / temperature, reduction='batchmean', log_target=False), min=0.0)\n                loss = focal_loss + distillation_weight * kl_loss + 1e-8 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)  # 8 nh√£n\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage2}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_with_soft_label_input.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_with_soft_label_input_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/autoint_8labels_with_soft_label_input_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{results_dir}/train_losses_8labels_with_soft_label_input_autoint.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input_autoint.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_with_soft_label_input_autoint.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input_autoint.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/epoch_times_8labels_with_soft_label_input_autoint.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_with_soft_label_input_autoint.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_with_soft_label_input_autoint.npy\", np.array([avg_epoch_time]))\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\ntqdm.write(f\"üìä Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/autoint_8labels_with_soft_label_input.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            embed_features, _, _ = model(X_batch, stage='feature_learning')  # L·∫•y embedding t·ª´ Stage 1\n            probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(embed_features.detach().cpu().numpy())  # L∆∞u embedding thay v√¨ logits\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)  # 8 nh√£n\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\n# Ki·ªÉm tra k√≠ch th∆∞·ªõc Confusion Matrix\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input_autoint.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_with_soft_label_input_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_with_soft_label_input_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_with_soft_label_input_autoint.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_with_soft_label_input_autoint.npy\", avg_mask)\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:46:53.733435Z","iopub.execute_input":"2025-04-26T12:46:53.733964Z","iopub.status.idle":"2025-04-26T12:49:45.346851Z","shell.execute_reply.started":"2025-04-26T12:46:53.733938Z","shell.execute_reply":"2025-04-26T12:49:45.345542Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**¬∑V·∫º C√ÅC S∆† ƒê·ªí AUTOINT**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\nresults_dir = \"results\"\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_with_soft_label_input_autoint.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_with_soft_label_input_autoint.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input_autoint.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input_autoint.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_with_soft_label_input_autoint.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_with_soft_label_input_autoint.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_with_soft_label_input_autoint.npy\")\n    test_features = np.load(f\"{results_dir}/test_features_8labels_with_soft_label_input_autoint.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input_autoint.npy\")\n    print(\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho AutoInt (8 nh√£n, v·ªõi soft label input)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nexpected_epochs = 105  # 5 epoch Stage 1 + 100 epoch Stage 2\nif train_losses.shape != (expected_epochs,) or val_losses.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (expected_epochs,) or val_accuracies.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\nif test_features.shape[0] != test_labels.shape[0]:\n    raise ValueError(f\"Shape c·ªßa test_features v√† test_labels kh√¥ng kh·ªõp: {test_features.shape}, {test_labels.shape}\")\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'BENIGN',\n    1: 'BruteForce',\n    2: 'DDoS',\n    3: 'DoS',\n    4: 'Mirai',\n    5: 'Recon',\n    6: 'Spoofing',\n    7: 'Web-based'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Lo·∫°i b·ªè Stage 1 (5 epoch ƒë·∫ßu), ch·ªâ v·∫Ω Stage 2 (epoch 5 ƒë·∫øn 105)\nstage1_epochs = 5\nstart_epoch = stage1_epochs  # B·∫Øt ƒë·∫ßu t·ª´ epoch 5\nepochs = np.arange(len(train_losses))\n# L·∫•y d·ªØ li·ªáu t·ª´ epoch 5 tr·ªü ƒëi (Stage 2)\ntrain_accuracies_plot = train_accuracies[start_epoch:]\nval_accuracies_plot = val_accuracies[start_epoch:]\ntrain_losses_plot = train_losses[start_epoch:]\nval_losses_plot = val_losses[start_epoch:]\n# √Ånh x·∫° epochs t·ª´ 5-105 th√†nh 0-100 tr√™n tr·ª•c X\nepochs_mapped = (epochs[start_epoch:] - start_epoch)  # √Ånh x·∫°: epoch 5 ‚Üí 0, epoch 105 ‚Üí 100\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ d·ªÖ ƒë·ªçc\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.legend(loc=\"upper right\", fontsize=10)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, 100)\nax1.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y theo y√™u c·∫ßu: t·ª´ 0.00 ƒë·∫øn 0.004\nax1.set_ylim(0.0016, 0.0026)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.legend(loc=\"lower right\", fontsize=10)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, 100)\nax2.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nax2.set_ylim(acc_min - 0.5, acc_max + 0.5)  # Th√™m padding nh·ªè ƒë·ªÉ d·ªÖ nh√¨n\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(\"AutoInt: Learning Curves (8 Labels, With Soft Label Input)\\nStage 2 (Epoch 5 to 105, Mapped to 0-100)\", \n             fontsize=14, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{results_dir}/learning_curves_autoint_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(10, 8))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(\"AutoInt: Confusion Matrix (Test, 8 Labels)\")\nplt.grid(False)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/confusion_matrix_autoint_8labels_with_soft_label_input.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(10, 8))  # TƒÉng k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì\nroc_auc_scores = []\nfor i in range(8):\n    # T√≠nh ROC cho t·ª´ng nh√£n (one-vs-rest)\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    roc_auc_scores.append(roc_auc)\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\n\n# T√≠nh ROC-AUC trung b√¨nh (macro-average)\nroc_auc_macro = np.mean(roc_auc_scores)\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"AutoInt: ROC Curves (8 Labels, Macro AUC = {roc_auc_macro:.4f})\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\n# ƒêi·ªÅu ch·ªânh tr·ª•c X theo y√™u c·∫ßu: t·ª´ 0 ƒë·∫øn 1\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/roc_curve_autoint_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\nprint(f\"üìà ROC-AUC Scores (One-vs-Rest):\")\nfor i, score in enumerate(roc_auc_scores):\n    print(f\"{class_names[i]}: {score:.4f}\")\nprint(f\"üìà Macro-average ROC-AUC: {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of test_features: {test_features.shape}\")\nn_samples, n_features = test_features.shape\n\n# Ki·ªÉm tra s·ªë m·∫´u\nif n_samples < 3:\n    print(f\"Warning: Only {n_samples} samples available. Skipping PCA 3D.\")\nelse:\n    # Apply PCA v·ªõi n_components=3\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(test_features)\n        \n        # 3D Plot\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels):\n            idx = test_labels == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\")\n        ax.set_ylabel(\"PC2\")\n        ax.set_zlabel(\"PC3\")\n        ax.set_title(\"AutoInt: PCA 3D Visualization (8 Labels)\")\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{results_dir}/pca_3d_autoint_8labels_with_soft_label_input.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 7Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy ·ªü Stage 2\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(\"\\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T16:18:45.374379Z","iopub.execute_input":"2025-04-22T16:18:45.374988Z","iopub.status.idle":"2025-04-22T16:19:37.366773Z","shell.execute_reply.started":"2025-04-22T16:18:45.374961Z","shell.execute_reply":"2025-04-22T16:19:37.365867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH AUTOINT FUZZY**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.amp import GradScaler, autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, AutoInt\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.embedding = nn.Linear(input_dim, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight, gain=0.1)\n\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        x_embed = self.embedding(x).unsqueeze(1)\n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))\n\n        embeddings = x_embed.squeeze(1)\n        output = self.fc_output(embeddings)\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu cho 8 nh√£n, 74 ƒë·∫∑c tr∆∞ng (t∆∞∆°ng t·ª± DCN-V2)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"‚ùå Shape c·ªßa X_train_combined kh√¥ng ƒë√∫ng: {X_train_combined.shape[1]}, k·ª≥ v·ªçng 74 ƒë·∫∑c tr∆∞ng\")\ntqdm.write(f\"üìå Shape d·ªØ li·ªáu: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf trong d·ªØ li·ªáu\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\nX_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\nX_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\nX_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long).to(device)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32).to(device)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long).to(device)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long).to(device)\n\n# DataLoader\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T√≠nh alpha cho Focal Loss cho 8 nh√£n\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v·ªõi num_classes=8, input_dim=74\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler('cuda')\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150  # ƒê·ªìng b·ªô v·ªõi DCN-V2\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n cho 8 nh√£n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training AutoInt with Focal + Sparsity Loss (No Early Stopping, 8 Labels, 74 Features)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            \n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            if torch.isnan(total_loss):\n                tqdm.write(f\"NaN detected in total_loss at batch {pbar.n+1}\")\n                continue\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean()\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                with autocast('cuda'):\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top c·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    # L∆∞u m√¥ h√¨nh n·∫øu F1 t·ªët h∆°n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_74features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_74features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/autoint_8labels_74features_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/autoint_8labels_74features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n tr√™n t·∫≠p test\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"C·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_74features_autoint.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_74features_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_74features_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_74features_autoint.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_74features_autoint.npy\", avg_mask)\n\n# T√≠nh gi√° tr·ªã trung b√¨nh\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\n\n# L∆∞u k·∫øt qu·∫£ v√†o file .txt\nwith open(f\"{results_dir}/AutoInt_8labels_74features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán AutoInt (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/AutoInt_8labels_74features.txt\")\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_74features_autoint.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_74features_autoint.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_74features_autoint.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_74features_autoint.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_74features_autoint.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_74features_autoint.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_74features_autoint.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_74features_autoint.npy\", np.array(epoch_times))\nnp.save(f\"{results_dir}/total_time_8labels_74features_autoint.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_74features_autoint.npy\", np.array([avg_epoch_time]))\ntqdm.write(f\"üì¶ ƒê√£ l∆∞u d·ªØ li·ªáu ƒë√°nh gi√° v√†o c√°c file .npy trong {results_dir}\")\n\n# In th√¥ng tin shape\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T03:59:51.000712Z","iopub.execute_input":"2025-05-01T03:59:51.001374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH AUTOINT FUZZY**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"autoint_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_74features_autoint.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_74features_autoint.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_74features_autoint.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_74features_autoint.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_74features_autoint.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_74features_autoint.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_74features_autoint.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_74features_autoint.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_74features_autoint.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho AutoInt (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ ch·ª©a 150 epoch\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05\nax2.set_ylim(acc_min - padding, acc_max + padding)\nax2.set_yticks(np.linspace(acc_min - padding, acc_max + padding, 8))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"AutoInt: Learning Curves (8 Labels, 74 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_autoint_8labels_74features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"AutoInt: Confusion Matrix (Test, 8 Labels, 74 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_autoint_8labels_74features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"AutoInt: ROC Curves (8 Labels, 74 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_autoint_8labels_74features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"AutoInt: PCA 3D Visualization (8 Labels, 74 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_autoint_8labels_74features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 74\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]\n\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (74,) or (n_samples, 74).\")\n\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"AutoInt: Feature Importance (8 Labels, 74 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_autoint_8labels_74features_150epochs.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:57:03.328067Z","iopub.execute_input":"2025-05-01T05:57:03.328364Z","iopub.status.idle":"2025-05-01T05:57:12.377207Z","shell.execute_reply.started":"2025-05-01T05:57:03.328342Z","shell.execute_reply":"2025-05-01T05:57:12.376565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 37.30 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh (100 epoch):\nTrain Loss trung b√¨nh: 0.0205\nVal Loss trung b√¨nh: 0.0199\nTrain Accuracy trung b√¨nh: 88.35%\nVal Accuracy trung b√¨nh: 88.68%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.cuda.amp import GradScaler, autocast\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# FocalLoss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# GhostBN1d\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# AutoInt\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=32, n_layers=2, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.embedding = nn.Linear(1, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight, gain=0.1)\n\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        x_embed = torch.stack([self.embedding(x[:, i:i+1]) for i in range(self.input_dim)], dim=1)\n        \n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))\n\n        embeddings = x_embed.mean(dim=1)\n        output = self.fc_output(embeddings)\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu combined (74 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} ch·ª©a gi√° tr·ªã NaN ho·∫∑c Inf\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape c·ªßa d·ªØ li·ªáu\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\naccumulation_steps = 8\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\ntorch.cuda.empty_cache()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=32, n_layers=2, n_heads=4, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler()\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# H√†m ki·ªÉm tra b·ªô nh·ªõ GPU\ndef print_gpu_memory():\n    if torch.cuda.is_available():\n        allocated = torch.cuda.memory_allocated() / 1024**3  # GB\n        reserved = torch.cuda.memory_reserved() / 1024**3    # GB\n        tqdm.write(f\"GPU Memory - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Hu·∫•n luy·ªán AutoInt v·ªõi Focal + Sparsity Loss (8 Nh√£n, 46 ƒê·∫∑c tr∆∞ng)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Batch Hu·∫•n luy·ªán (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for batch_idx, (X_batch, Y_batch) in enumerate(pbar):\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            \n            with autocast():  # ƒê√£ s·ª≠a: B·ªè 'cuda', ch·ªâ d√πng autocast() ƒë·ªÉ t·ª± ƒë·ªông √°p d·ª•ng AMP tr√™n thi·∫øt b·ªã hi·ªán t·∫°i\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n                loss = total_loss / accumulation_steps\n            \n            if torch.isnan(loss) or torch.isinf(loss):\n                tqdm.write(f\"Ph√°t hi·ªán NaN ho·∫∑c Inf trong total_loss t·∫°i batch {batch_idx+1}\")\n                continue\n            \n            scaler.scale(loss).backward()\n            \n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=False)\n            \n            if (batch_idx + 1) % accumulation_steps == 0:\n                scaler.unscale_(optimizer)\n                scaler.step(optimizer)\n                scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if batch_idx < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {batch_idx+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n                print_gpu_memory()\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, total_loss, focal_loss, loss\n            torch.cuda.empty_cache()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # ƒê√°nh gi√°\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"ƒê√°nh gi√° (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n                with autocast():  # ƒê√£ s·ª≠a: B·ªè 'cuda'\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n                \n                del X_batch, Y_batch, outputs, sparsity_loss, focal_loss, loss\n                torch.cuda.empty_cache()\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (ƒê√°nh gi√°): {pred_counts}\")\n    tqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\n    tqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n h√†ng ƒë·∫ßu: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n    print_gpu_memory()\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_46features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_46features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/autoint_8labels_46features_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_46features_autoint.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_autoint.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_autoint.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_autoint.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_autoint.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_autoint.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_autoint.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_autoint.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_autoint.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_autoint.npy\", np.array([avg_epoch_time]))\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\ntqdm.write(f\"üìä Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\")\n\n# Ki·ªÉm tra tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/autoint_8labels_46features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Ki·ªÉm tra\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            with autocast():  # ƒê√£ s·ª≠a: B·ªè 'cuda'\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(X_batch.cpu().numpy())  # L∆∞u input features\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, probs\n            torch.cuda.empty_cache()\n\n    print_gpu_memory()\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\ntqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"C·∫£nh b√°o: K√≠ch th∆∞·ªõc mask kh√¥ng ƒë·ªìng nh·∫•t: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_autoint.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_autoint.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_autoint.npy\", avg_mask)\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/AutoInt_8labels_46features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán AutoInt (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/AutoInt_8labels_46features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"T·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T14:57:19.403284Z","iopub.execute_input":"2025-04-30T14:57:19.403942Z","iopub.status.idle":"2025-04-30T15:01:38.439705Z","shell.execute_reply.started":"2025-04-30T14:57:19.403919Z","shell.execute_reply":"2025-04-30T15:01:38.438676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom xgboost import XGBClassifier\nimport joblib\nimport pickle\nimport os\nfrom tqdm import tqdm\nimport time\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, AutoInt\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.embedding = nn.Linear(input_dim, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight)\n\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight)\n\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        x_embed = self.embedding(x).unsqueeze(1)\n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))\n\n        embeddings = x_embed.squeeze(1)\n        output = self.fc_output(embeddings)\n        return output, sparsity_loss, masks\n\n# H√†m √°nh x·∫° nh√£n\ndef change_label(df):\n    mapping = {\n        'DDoS-ICMP_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS',\n        'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-RSTFINFlood': 'DDoS',\n        'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n        'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n        'DDoS-HTTP_Flood': 'DDoS', 'DDoS-SlowLoris': 'DDoS',\n        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n        'DictionaryBruteForce': 'BruteForce',\n        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n        'BenignTraffic': 'BENIGN'\n    }\n    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n    return df\n\n# Danh s√°ch 30 ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn\nselected_features = [\n    'IAT', 'Tot size', 'Max', 'Tot sum', 'Magnitue', 'AVG', 'Min', 'Header_Length', \n    'Protocol Type', 'rst_count', 'Weight', 'Number', 'Variance', 'Std', 'Radius', \n    'Covariance', 'Duration', 'urg_count', 'flow_duration', 'Rate', 'Srate', 'TCP', \n    'ack_flag_number', 'syn_count', 'HTTPS', 'ack_count', 'syn_flag_number', 'ICMP', \n    'fin_count', 'UDP'\n]\n\n# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu t·ª´ file CSV\ntest_file = \"/kaggle/input/cic-iot-2023/part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\nprint(\"‚úÖ ƒêang t·∫£i d·ªØ li·ªáu t·ª´:\", test_file)\ndf_test = pd.read_csv(test_file)\n\n# Ki·ªÉm tra v√† √°nh x·∫° nh√£n\nunique_labels_before = df_test['label'].unique()\ndf_test = change_label(df_test)\nunique_labels_after = df_test['label'].unique()\nvalid_labels = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\nif not all(label in valid_labels for label in unique_labels_after):\n    raise ValueError(f\"‚ùå Nh√£n kh√¥ng ƒë∆∞·ª£c √°nh x·∫° ƒë√∫ng: {unique_labels_after}\")\nprint(f\"Nh√£n tr∆∞·ªõc √°nh x·∫°: {unique_labels_before}\")\nprint(f\"Nh√£n sau √°nh x·∫°: {unique_labels_after}\")\n\n# Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i\nmissing_features = [f for f in selected_features if f not in df_test.columns]\nif missing_features:\n    raise ValueError(f\"‚ùå C√°c ƒë·∫∑c tr∆∞ng sau kh√¥ng c√≥ trong d·ªØ li·ªáu: {missing_features}\")\n\n# Ch·ªçn 30 ƒë·∫∑c tr∆∞ng\nX_test = df_test[selected_features].values\nY_test = df_test['label'].values\n\n# T·∫£i label encoder\ntry:\n    with open(f\"{output_dir}/label_encoder_8labels.pkl\", 'rb') as f:\n        label_encoder = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i label encoder t·ª´:\", f\"{output_dir}/label_encoder_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i label encoder: {str(e)}\")\n\n# M√£ h√≥a nh√£n\nY_test_encoded = label_encoder.transform(Y_test)\nlabel_names = label_encoder.classes_\nexpected_label_map = {'BENIGN': 0, 'BruteForce': 1, 'DDoS': 2, 'DoS': 3, 'Mirai': 4, 'Recon': 5, 'Spoofing': 6, 'Web-based': 7}\nif not all(label_names[i] == label for label, i in expected_label_map.items()):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: √Ånh x·∫° nh√£n kh√¥ng kh·ªõp v·ªõi k·ª≥ v·ªçng: {label_names}\")\nprint(\"‚úÖ Nh√£n ƒë√£ m√£ h√≥a:\", label_names)\n\n# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu b·∫±ng KNNImputer\ntry:\n    with open(f\"{output_dir}/imputer_8labels.pkl\", 'rb') as f:\n        imputer = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i imputer t·ª´:\", f\"{output_dir}/imputer_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i imputer: {str(e)}\")\nX_test_imputed = imputer.transform(X_test)\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng RobustScaler\ntry:\n    with open(f\"{output_dir}/scaler_8labels.pkl\", 'rb') as f:\n        scaler = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i scaler t·ª´:\", f\"{output_dir}/scaler_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i scaler: {str(e)}\")\nX_test_scaled = scaler.transform(X_test_imputed)\nprint(\"‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu test\")\n\n# H√†m t·∫°o ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost\ndef convert_to_fuzzy_features_xgb(X_test, n_features=30, n_labels=8):\n    X_test_fuzzy = []\n    \n    # L·∫∑p qua t·ª´ng ƒë·∫∑c tr∆∞ng\n    for i in tqdm(range(n_features), desc=\"Processing features for fuzzy features\"):\n        X_test_feature = X_test[:, i].reshape(-1, 1)\n        \n        # T·∫£i m√¥ h√¨nh XGBoost ƒë√£ l∆∞u\n        try:\n            xgb = joblib.load(f\"{output_dir}/xgb_feature_{i}.joblib\")\n        except Exception as e:\n            print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh XGBoost cho ƒë·∫∑c tr∆∞ng {i}: {str(e)}\")\n            raise\n        \n        # D·ª± ƒëo√°n x√°c su·∫•t\n        test_probs = xgb.predict_proba(X_test_feature)\n        \n        # ƒê·∫£m b·∫£o ƒë·ªß 8 nh√£n\n        if test_probs.shape[1] < n_labels:\n            missing_labels = n_labels - test_probs.shape[1]\n            test_probs = np.pad(test_probs, ((0, 0), (0, missing_labels)), mode='constant')\n        \n        X_test_fuzzy.append(test_probs)\n    \n    # Chuy·ªÉn th√†nh ma tr·∫≠n [n_samples, n_features * n_labels]\n    X_test_fuzzy = np.concatenate(X_test_fuzzy, axis=1)\n    return X_test_fuzzy\n\n# T√≠nh ƒë·∫∑c tr∆∞ng fuzzy\nprint(\"üîÑ T√≠nh ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost...\")\nstart_time = time.time()\nX_test_fuzzy = convert_to_fuzzy_features_xgb(X_test_scaled, n_features=30, n_labels=8)\nprint(f\"‚úÖ Shape c·ªßa X_test_fuzzy: {X_test_fuzzy.shape}\")\nprint(f\"‚è± Th·ªùi gian t√≠nh fuzzy: {time.time() - start_time:.2f}s\")\n\n# Ki·ªÉm tra gi√° tr·ªã nan/inf\nprint(f\"X_test_fuzzy nan: {np.any(np.isnan(X_test_fuzzy))}\")\nprint(f\"X_test_fuzzy inf: {np.any(np.isinf(X_test_fuzzy))}\")\n\n# Ki·ªÉm tra x√°c su·∫•t fuzzy\nprint(\"M·∫´u x√°c su·∫•t fuzzy (5 m·∫´u ƒë·∫ßu ti√™n, ƒë·∫∑c tr∆∞ng 0):\")\nprint(X_test_fuzzy[:5, :8])\nprint(\"T·ªïng x√°c su·∫•t m·ªói m·∫´u:\", X_test_fuzzy[:5, :8].sum(axis=1))\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_test_tensor = torch.tensor(X_test_fuzzy, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T·∫£i m√¥ h√¨nh AutoInt ƒë√£ hu·∫•n luy·ªán\ninput_dim = X_test_fuzzy.shape[1]  # 240 (30 features * 8 labels)\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1).to(device)\nmodel_path = f\"{results_dir}/autoint_8labels_fuzzy_xgb.pth\"\ntry:\n    model.load_state_dict(torch.load(model_path, weights_only=True))\n    print(f\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ {model_path}\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}\")\n    raise\n\n# Test m√¥ h√¨nh\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_probs = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            outputs, _, _ = model(X_batch)\n            probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_probs = np.array(test_probs)\n\n# T√≠nh ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ v√† theo t·ª´ng nh√£n\noverall_accuracy = accuracy_score(test_labels, test_preds) * 100\nclassification_rep = classification_report(test_labels, test_preds, target_names=label_names, digits=4)\n\n# T√≠nh confusion matrix\ncm = confusion_matrix(test_labels, test_preds)\nprint(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\n# In k·∫øt qu·∫£\nprint(\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\nprint(f\"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ: {overall_accuracy:.2f}%\")\nprint(\"\\nB√°o c√°o ph√¢n lo·∫°i theo t·ª´ng nh√£n:\")\nprint(classification_rep)\nprint(f\"Confusion Matrix:\\n{cm}\")\n\n# L∆∞u k·∫øt qu·∫£\nnp.save(f\"{results_dir}/test_preds_8labels_fuzzy_xgb_autoint.npy\", test_preds)\nnp.save(f\"{results_dir}/test_labels_8labels_fuzzy_xgb_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_probs_8labels_fuzzy_xgb_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_fuzzy_xgb_autoint.npy\", cm)\nprint(f\"üì¶ ƒê√£ l∆∞u d·ª± ƒëo√°n, nh√£n th·ª±c t·∫ø, x√°c su·∫•t v√† confusion matrix t·∫°i {results_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T07:17:14.051475Z","iopub.execute_input":"2025-04-24T07:17:14.05176Z","iopub.status.idle":"2025-04-24T07:17:20.598918Z","shell.execute_reply.started":"2025-04-24T07:17:14.051739Z","shell.execute_reply":"2025-04-24T07:17:20.598197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH TABNET FUZZY**","metadata":{}},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 39.49 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh (100 epoch):\nTrain Loss trung b√¨nh: 0.0102\nVal Loss trung b√¨nh: 0.0099\nTrain Accuracy trung b√¨nh: 94.88%\nVal Accuracy trung b√¨nh: 95.05%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.cuda.amp import GradScaler, autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, TabNet\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\ndef entmax15(x, dim=-1):\n    x = F.softmax(x * 1.5, dim=dim)\n    return x\n\nclass TabNet(nn.Module):\n    def __init__(self, input_dim, num_classes, n_d=64, n_a=64, n_steps=5, gamma=1.3, lambda_sparse=5e-4):\n        super(TabNet, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.lambda_sparse = lambda_sparse\n\n        # BatchNorm ƒë·∫ßu v√†o\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # L·ªõp FC ban ƒë·∫ßu\n        self.initial_fc = nn.Linear(input_dim, n_d + n_a)\n        nn.init.xavier_normal_(self.initial_fc.weight)\n        nn.init.zeros_(self.initial_fc.bias)\n\n        # C√°c l·ªõp ch√∫ √Ω v√† quy·∫øt ƒë·ªãnh\n        self.attention_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(n_a, input_dim),\n                nn.BatchNorm1d(input_dim),\n                nn.ReLU()\n            ) for _ in range(n_steps)\n        ])\n        self.decision_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, n_d),\n                nn.BatchNorm1d(n_d),\n                nn.ReLU(),\n                nn.Dropout(0.1)\n            ) for _ in range(n_steps)\n        ])\n\n        # L·ªõp ƒë·∫ßu ra\n        self.fc_output = nn.Linear(n_d * n_steps, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        prior = torch.ones_like(x)\n        outputs = []\n        sparsity_loss = 0\n        masks = []\n\n        for step in range(self.n_steps):\n            att = self.initial_fc(x)\n            att_d, att_a = att[:, :self.n_d], att[:, self.n_d:]\n            mask = self.attention_layers[step](att_a)\n            mask = entmax15(mask, dim=1)\n            \n            entropy = -torch.sum(mask * torch.log(mask + 1e-8), dim=1)\n            sparsity_loss += torch.mean(entropy) / self.n_steps / self.input_dim\n            masks.append(mask)\n\n            prior = prior * (self.gamma - mask)\n            masked_x = x * mask\n            out = self.decision_layers[step](masked_x)\n            outputs.append(out)\n\n        combined = torch.cat(outputs, dim=1)\n        output = self.fc_output(combined)\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p (74 ƒë·∫∑c tr∆∞ng: 64 x√°c su·∫•t + 10 g·ªëc)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p (74 ƒë·∫∑c tr∆∞ng, 8 nh√£n)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"‚ùå Shape c·ªßa X_train_combined kh√¥ng ƒë√∫ng: {X_train_combined.shape[1]}, k·ª≥ v·ªçng 74 ƒë·∫∑c tr∆∞ng\")\ntqdm.write(f\"üìå Shape d·ªØ li·ªáu: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long).to(device)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32).to(device)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long).to(device)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long).to(device)\n\n# DataLoader\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = 74  # C·∫≠p nh·∫≠t cho 74 ƒë·∫∑c tr∆∞ng\nmodel = TabNet(input_dim=input_dim, num_classes=8, n_d=64, n_a=64, n_steps=5, lambda_sparse=5e-4).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler()\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training TabNet with Focal + Sparsity Loss (No Early Stopping)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            \n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean()\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                with autocast():\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    # Ph√¢n t√≠ch nh·∫ßm l·∫´n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    # L∆∞u m√¥ h√¨nh n·∫øu F1 t·ªët h∆°n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_46features_tabnet.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_46features_tabnet_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/tabnet_8labels_46features_tabnet_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/tabnet_8labels_46features_tabnet.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n tr√™n t·∫≠p test\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_tabnet.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_tabnet.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_tabnet.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_tabnet.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_tabnet.npy\", avg_mask)\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_46features_tabnet.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_tabnet.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_tabnet.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_tabnet.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_tabnet.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_tabnet.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_tabnet.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_tabnet.npy\", np.array(epoch_times))\n\n# T√≠nh v√† l∆∞u th·ªùi gian hu·∫•n luy·ªán\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_tabnet.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_tabnet.npy\", np.array([avg_epoch_time]))\n\n# L∆∞u k·∫øt qu·∫£ v√†o file\nwith open(f\"{results_dir}/TabNet_8labels_46features_tabnet.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán TabNet (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {np.mean(train_losses):.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {np.mean(val_losses):.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {np.mean(train_accuracies):.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {np.mean(val_accuracies):.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"Th·ªùi gian trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {np.mean(val_f1_scores):.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {np.mean(val_precisions):.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {np.mean(val_recalls):.4f}\\n\")\n\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/TabNet_8labels_46features_tabnet.txt\")\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\ntqdm.write(f\"üìä Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T11:59:38.588595Z","iopub.execute_input":"2025-04-30T11:59:38.588953Z","iopub.status.idle":"2025-04-30T13:50:03.885751Z","shell.execute_reply.started":"2025-04-30T11:59:38.588924Z","shell.execute_reply":"2025-04-30T13:50:03.885087Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CODE V·∫º C√ÅC S∆† ƒê·ªí TABNET**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"tabnet_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_46features_tabnet.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_46features_tabnet.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_46features_tabnet.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_46features_tabnet.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_46features_tabnet.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_46features_tabnet.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_46features_tabnet.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_46features_tabnet.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_46features_tabnet.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho TabNet (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ ch·ª©a 150 epoch\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i) - GI·ªÆ NGUY√äN\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss (gi·ªØ nguy√™n nh∆∞ ban ƒë·∫ßu)\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i) - THAY ƒê·ªîI\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\n# Thu h·∫πp kho·∫£ng Y ƒë·ªÉ l√†m r√µ s·ª± bi·∫øn thi√™n, nh∆∞ng v·∫´n bao qu√°t to√†n b·ªô d·ªØ li·ªáu\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05  # Gi·∫£m padding ƒë·ªÉ thu h·∫πp kho·∫£ng Y\n# Ch·ªçn kho·∫£ng Y sao cho t·∫≠p trung v√†o v√πng dao ƒë·ªông ch√≠nh (88% ƒë·∫øn 94.5%) nh∆∞ng v·∫´n hi·ªÉn th·ªã to√†n b·ªô d·ªØ li·ªáu\nax2.set_ylim(86, acc_max + padding)  # C·ªë ƒë·ªãnh gi·ªõi h·∫°n d∆∞·ªõi ·ªü 86% ƒë·ªÉ t·∫≠p trung v√†o v√πng dao ƒë·ªông ch√≠nh\nax2.set_yticks(np.linspace(86, acc_max + padding, 8))  # TƒÉng s·ªë l∆∞·ª£ng nh√£n Y ƒë·ªÉ th·∫•y r√µ bi·∫øn thi√™n\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"TabNet: Learning Curves (8 Labels, 46 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_tabnet_8labels_46features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"TabNet: Confusion Matrix (Test, 8 Labels, 46 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_tabnet_8labels_46features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"TabNet: ROC Curves (8 Labels, 46 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_tabnet_8labels_46features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"TabNet: PCA 3D Visualization (8 Labels, 46 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_tabnet_8labels_46features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 74\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]\n\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (74,) or (n_samples, 74).\")\n\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"TabNet: Feature Importance (8 Labels, 46 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_tabnet_8labels_46features_150epochs.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T14:05:18.244344Z","iopub.execute_input":"2025-04-30T14:05:18.244661Z","iopub.status.idle":"2025-04-30T14:05:27.588729Z","shell.execute_reply.started":"2025-04-30T14:05:18.24464Z","shell.execute_reply":"2025-04-30T14:05:27.588056Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CODE TEST TABNET_FUZZY**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom xgboost import XGBClassifier\nimport joblib\nimport pickle\nimport os\nfrom tqdm import tqdm\nimport time\nfrom torch.cuda.amp import autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, TabNet\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\ndef entmax15(x, dim=-1):\n    x = F.softmax(x * 1.5, dim=dim)\n    return x\n\nclass TabNet(nn.Module):\n    def __init__(self, input_dim, num_classes, n_d=64, n_a=64, n_steps=5, gamma=1.3, lambda_sparse=5e-4):\n        super(TabNet, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.lambda_sparse = lambda_sparse\n\n        # BatchNorm ƒë·∫ßu v√†o\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # L·ªõp FC ban ƒë·∫ßu\n        self.initial_fc = nn.Linear(input_dim, n_d + n_a)\n        nn.init.xavier_normal_(self.initial_fc.weight)\n        nn.init.zeros_(self.initial_fc.bias)\n\n        # C√°c l·ªõp ch√∫ √Ω v√† quy·∫øt ƒë·ªãnh\n        self.attention_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(n_a, input_dim),\n                nn.BatchNorm1d(input_dim),\n                nn.ReLU()\n            ) for _ in range(n_steps)\n        ])\n        self.decision_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, n_d),\n                nn.BatchNorm1d(n_d),\n                nn.ReLU(),\n                nn.Dropout(0.1)  # ƒê·ªìng b·ªô v·ªõi dropout c·ªßa AutoInt\n            ) for _ in range(n_steps)\n        ])\n\n        # L·ªõp ƒë·∫ßu ra\n        self.fc_output = nn.Linear(n_d * n_steps, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        prior = torch.ones_like(x)\n        outputs = []\n        sparsity_loss = 0\n        masks = []\n\n        for step in range(self.n_steps):\n            att = self.initial_fc(x)\n            att_d, att_a = att[:, :self.n_d], att[:, self.n_d:]\n            mask = self.attention_layers[step](att_a)\n            mask = entmax15(mask, dim=1)\n            \n            entropy = -torch.sum(mask * torch.log(mask + 1e-8), dim=1)\n            sparsity_loss += torch.mean(entropy) / self.n_steps / self.input_dim\n            masks.append(mask)\n\n            prior = prior * (self.gamma - mask)\n            masked_x = x * mask\n            out = self.decision_layers[step](masked_x)\n            outputs.append(out)\n\n        combined = torch.cat(outputs, dim=1)\n        output = self.fc_output(combined)\n        return output, sparsity_loss, masks\n\n# H√†m √°nh x·∫° nh√£n\ndef change_label(df):\n    mapping = {\n        'DDoS-ICMP_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS',\n        'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-RSTFINFlood': 'DDoS',\n        'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n        'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n        'DDoS-HTTP_Flood': 'DDoS', 'DDoS-SlowLoris': 'DDoS',\n        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n        'DictionaryBruteForce': 'BruteForce',\n        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n        'BenignTraffic': 'BENIGN'\n    }\n    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n    return df\n\n# Danh s√°ch 30 ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn\nselected_features = [\n    'IAT', 'Tot size', 'Max', 'Tot sum', 'Magnitue', 'AVG', 'Min', 'Header_Length', \n    'Protocol Type', 'rst_count', 'Weight', 'Number', 'Variance', 'Std', 'Radius', \n    'Covariance', 'Duration', 'urg_count', 'flow_duration', 'Rate', 'Srate', 'TCP', \n    'ack_flag_number', 'syn_count', 'HTTPS', 'ack_count', 'syn_flag_number', 'ICMP', \n    'fin_count', 'UDP'\n]\n\n# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu t·ª´ file CSV\ntest_file = \"/kaggle/input/cic-iot-2023/part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\nprint(\"‚úÖ ƒêang t·∫£i d·ªØ li·ªáu t·ª´:\", test_file)\ndf_test = pd.read_csv(test_file)\n\n# Ki·ªÉm tra v√† √°nh x·∫° nh√£n\nunique_labels_before = df_test['label'].unique()\ndf_test = change_label(df_test)\nunique_labels_after = df_test['label'].unique()\nvalid_labels = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\nif not all(label in valid_labels for label in unique_labels_after):\n    raise ValueError(f\"‚ùå Nh√£n kh√¥ng ƒë∆∞·ª£c √°nh x·∫° ƒë√∫ng: {unique_labels_after}\")\nprint(f\"Nh√£n tr∆∞·ªõc √°nh x·∫°: {unique_labels_before}\")\nprint(f\"Nh√£n sau √°nh x·∫°: {unique_labels_after}\")\n\n# Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i\nmissing_features = [f for f in selected_features if f not in df_test.columns]\nif missing_features:\n    raise ValueError(f\"‚ùå C√°c ƒë·∫∑c tr∆∞ng sau kh√¥ng c√≥ trong d·ªØ li·ªáu: {missing_features}\")\n\n# Ch·ªçn 30 ƒë·∫∑c tr∆∞ng\nX_test = df_test[selected_features].values\nY_test = df_test['label'].values\n\n# T·∫£i label encoder\ntry:\n    with open(f\"{output_dir}/label_encoder_8labels.pkl\", 'rb') as f:\n        label_encoder = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i label encoder t·ª´:\", f\"{output_dir}/label_encoder_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i label encoder: {str(e)}\")\n\n# M√£ h√≥a nh√£n\nY_test_encoded = label_encoder.transform(Y_test)\nlabel_names = label_encoder.classes_\nexpected_label_map = {'BENIGN': 0, 'BruteForce': 1, 'DDoS': 2, 'DoS': 3, 'Mirai': 4, 'Recon': 5, 'Spoofing': 6, 'Web-based': 7}\nif not all(label_names[i] == label for label, i in expected_label_map.items()):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: √Ånh x·∫° nh√£n kh√¥ng kh·ªõp v·ªõi k·ª≥ v·ªçng: {label_names}\")\nprint(\"‚úÖ Nh√£n ƒë√£ m√£ h√≥a:\", label_names)\n\n# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu b·∫±ng KNNImputer\ntry:\n    with open(f\"{output_dir}/imputer_8labels.pkl\", 'rb') as f:\n        imputer = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i imputer t·ª´:\", f\"{output_dir}/imputer_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i imputer: {str(e)}\")\nX_test_imputed = imputer.transform(X_test)\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng RobustScaler\ntry:\n    with open(f\"{output_dir}/scaler_8labels.pkl\", 'rb') as f:\n        scaler = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i scaler t·ª´:\", f\"{output_dir}/scaler_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i scaler: {str(e)}\")\nX_test_scaled = scaler.transform(X_test_imputed)\nprint(\"‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu test\")\n\n# H√†m t·∫°o ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost\ndef convert_to_fuzzy_features_xgb(X_test, n_features=30, n_labels=8):\n    X_test_fuzzy = []\n    \n    # L·∫∑p qua t·ª´ng ƒë·∫∑c tr∆∞ng\n    for i in tqdm(range(n_features), desc=\"Processing features for fuzzy features\"):\n        X_test_feature = X_test[:, i].reshape(-1, 1)\n        \n        # T·∫£i m√¥ h√¨nh XGBoost ƒë√£ l∆∞u\n        try:\n            xgb = joblib.load(f\"{output_dir}/xgb_feature_{i}.joblib\")\n        except Exception as e:\n            print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh XGBoost cho ƒë·∫∑c tr∆∞ng {i}: {str(e)}\")\n            raise\n        \n        # D·ª± ƒëo√°n x√°c su·∫•t\n        test_probs = xgb.predict_proba(X_test_feature)\n        \n        # ƒê·∫£m b·∫£o ƒë·ªß 8 nh√£n\n        if test_probs.shape[1] < n_labels:\n            missing_labels = n_labels - test_probs.shape[1]\n            test_probs = np.pad(test_probs, ((0, 0), (0, missing_labels)), mode='constant')\n        \n        X_test_fuzzy.append(test_probs)\n    \n    # Chuy·ªÉn th√†nh ma tr·∫≠n [n_samples, n_features * n_labels]\n    X_test_fuzzy = np.concatenate(X_test_fuzzy, axis=1)\n    return X_test_fuzzy\n\n# T√≠nh ƒë·∫∑c tr∆∞ng fuzzy\nprint(\"üîÑ T√≠nh ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost...\")\nstart_time = time.time()\nX_test_fuzzy = convert_to_fuzzy_features_xgb(X_test_scaled, n_features=30, n_labels=8)\nprint(f\"‚úÖ Shape c·ªßa X_test_fuzzy: {X_test_fuzzy.shape}\")\nprint(f\"‚è± Th·ªùi gian t√≠nh fuzzy: {time.time() - start_time:.2f}s\")\n\n# Ki·ªÉm tra gi√° tr·ªã nan/inf\nprint(f\"X_test_fuzzy nan: {np.any(np.isnan(X_test_fuzzy))}\")\nprint(f\"X_test_fuzzy inf: {np.any(np.isinf(X_test_fuzzy))}\")\n\n# Ki·ªÉm tra x√°c su·∫•t fuzzy\nprint(\"M·∫´u x√°c su·∫•t fuzzy (5 m·∫´u ƒë·∫ßu ti√™n, ƒë·∫∑c tr∆∞ng 0):\")\nprint(X_test_fuzzy[:5, :8])\nprint(\"T·ªïng x√°c su·∫•t m·ªói m·∫´u:\", X_test_fuzzy[:5, :8].sum(axis=1))\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_test_tensor = torch.tensor(X_test_fuzzy, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T·∫£i m√¥ h√¨nh TabNet ƒë√£ hu·∫•n luy·ªán\ninput_dim = X_test_fuzzy.shape[1]  # 240 (30 features * 8 labels)\nmodel = TabNet(input_dim=input_dim, num_classes=8, n_d=64, n_a=64, n_steps=5, lambda_sparse=5e-4).to(device)\nmodel_path = f\"{results_dir}/tabnet_8labels_fuzzy_xgb.pth\"\ntry:\n    model.load_state_dict(torch.load(model_path, weights_only=True))\n    print(f\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ {model_path}\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}\")\n    raise\n\n# Test m√¥ h√¨nh\nmodel.eval()\ntabnet_test_preds = []\ntabnet_test_labels = []\ntabnet_test_probs = []\ntabnet_test_features = []\ntabnet_test_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing TabNet\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            tabnet_test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            tabnet_test_labels.extend(Y_batch.cpu().numpy())\n            tabnet_test_probs.extend(probs.cpu().numpy())\n            tabnet_test_features.extend(outputs.detach().cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                tabnet_test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntabnet_test_preds = np.array(tabnet_test_preds)\ntabnet_test_labels = np.array(tabnet_test_labels)\ntabnet_test_probs = np.array(tabnet_test_probs)\ntabnet_test_features = np.array(tabnet_test_features)\n\n# T√≠nh ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ v√† theo t·ª´ng nh√£n\ntabnet_overall_accuracy = accuracy_score(tabnet_test_labels, tabnet_test_preds) * 100\ntabnet_classification_rep = classification_report(tabnet_test_labels, tabnet_test_preds, target_names=label_names, digits=4)\n\n# T√≠nh confusion matrix\ntabnet_cm = confusion_matrix(tabnet_test_labels, tabnet_test_preds)\nprint(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {tabnet_cm.shape}\")\nif tabnet_cm.shape != (8, 8):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {tabnet_cm.shape}\")\n\n# In k·∫øt qu·∫£\nprint(\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test (TabNet):\")\nprint(f\"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ: {tabnet_overall_accuracy:.2f}%\")\nprint(\"\\nB√°o c√°o ph√¢n lo·∫°i theo t·ª´ng nh√£n:\")\nprint(tabnet_classification_rep)\nprint(f\"Confusion Matrix:\\n{tabnet_cm}\")\n\n# L∆∞u k·∫øt qu·∫£ v·ªõi t√™n file kh√°c ƒë·ªÉ tr√°nh tr√πng\nnp.save(f\"{results_dir}/tabnet_test_preds_8labels.npy\", tabnet_test_preds)\nnp.save(f\"{results_dir}/tabnet_test_labels_8labels.npy\", tabnet_test_labels)\nnp.save(f\"{results_dir}/tabnet_test_probs_8labels.npy\", tabnet_test_probs)\nnp.save(f\"{results_dir}/tabnet_test_features_8labels.npy\", tabnet_test_features)\nif tabnet_test_masks:\n    shapes = [mask.shape for mask in tabnet_test_masks]\n    if len(set(shapes)) == 1:\n        tabnet_avg_mask = np.mean(np.stack(tabnet_test_masks, axis=0), axis=(0, 1))\n    else:\n        print(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc mask kh√¥ng ƒë·ªìng nh·∫•t: {shapes}\")\n        tabnet_avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    tabnet_avg_mask = np.zeros((batch_size, input_dim))\nnp.save(f\"{results_dir}/tabnet_feature_importance_8labels.npy\", tabnet_avg_mask)\nnp.save(f\"{results_dir}/tabnet_confusion_matrix_8labels.npy\", tabnet_cm)\nprint(f\"üì¶ ƒê√£ l∆∞u d·ª± ƒëo√°n, nh√£n th·ª±c t·∫ø, x√°c su·∫•t, ƒë·∫∑c tr∆∞ng, t·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng v√† confusion matrix t·∫°i {results_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:04:43.409645Z","iopub.execute_input":"2025-04-24T09:04:43.410245Z","iopub.status.idle":"2025-04-24T09:04:53.989525Z","shell.execute_reply.started":"2025-04-24T09:04:43.410215Z","shell.execute_reply":"2025-04-24T09:04:53.988847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH NODE-GAM FUZZY**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.cuda.amp import GradScaler, autocast\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# FocalLoss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# FeatureSelector\nclass FeatureSelector(nn.Module):\n    def __init__(self, input_dim):\n        super(FeatureSelector, self).__init__()\n        self.importance_weights = nn.Parameter(torch.ones(input_dim) * 0.1)\n        \n    def forward(self, x):\n        importance = torch.sigmoid(self.importance_weights)\n        importance = importance / (importance.sum() + 1e-6)\n        mask = importance.unsqueeze(0)\n        return x * mask\n\n# ObliviousDecisionTree\nclass ObliviousDecisionTree(nn.Module):\n    def __init__(self, embed_dim, depth, input_dim):\n        super(ObliviousDecisionTree, self).__init__()\n        self.depth = depth\n        self.num_leaves = 2 ** depth\n        self.input_dim = input_dim\n        \n        self.thresholds = nn.Parameter(torch.randn(depth, input_dim) * 0.1)\n        self.feature_weights = nn.Parameter(torch.randn(depth, input_dim) * 0.1)\n        self.attention = nn.Parameter(torch.randn(input_dim) * 0.1)\n        self.leaf_projection = nn.Linear(embed_dim, self.num_leaves)\n        \n        nn.init.xavier_normal_(self.thresholds, gain=0.1)\n        nn.init.xavier_normal_(self.feature_weights, gain=0.1)\n        nn.init.xavier_normal_(self.leaf_projection.weight, gain=0.1)\n        nn.init.zeros_(self.leaf_projection.bias)\n        nn.init.normal_(self.attention, mean=0.0, std=0.1)\n\n    def forward(self, x, input_features):\n        batch_size = x.size(0)\n        \n        attention_weights = torch.sigmoid(self.attention)\n        attention_weights = attention_weights / (attention_weights.sum() + 1e-6)\n        selected_features = input_features * attention_weights.unsqueeze(0)\n        \n        scores = torch.matmul(selected_features, self.feature_weights.t())\n        scores = scores + self.thresholds.sum(dim=-1).unsqueeze(0)\n        decisions = torch.sigmoid(scores)\n        \n        leaf_indices = torch.zeros(batch_size, device=x.device, dtype=torch.long)\n        for d in range(self.depth):\n            leaf_indices = leaf_indices * 2 + (decisions[:, d] > 0.5).long()\n        \n        leaf_probs = torch.zeros(batch_size, self.num_leaves, device=x.device)\n        leaf_probs.scatter_(1, leaf_indices.unsqueeze(-1), 1.0)\n        \n        out = self.leaf_projection(x)\n        out = F.softmax(out, dim=-1) * leaf_probs\n        return out\n\n# NODEGAM\nclass NODEGAM(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, num_trees=10, depth=6, num_layers=2, dropout=0.1):\n        super(NODEGAM, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.num_trees = num_trees\n        self.depth = depth\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        self.bn = nn.BatchNorm1d(input_dim)\n        self.feature_selector = FeatureSelector(input_dim)\n        self.feature_dim = 16\n        self.feature_nets = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(1, self.feature_dim),\n                nn.ReLU(),\n                nn.Dropout(dropout),\n                nn.Linear(self.feature_dim, self.feature_dim),\n                nn.ReLU(),\n                nn.Dropout(dropout)\n            ) for _ in range(input_dim)\n        ])\n\n        self.concat_dim = self.feature_dim * input_dim\n        self.feature_projection = nn.Linear(self.concat_dim, embed_dim)\n        self.tree_layers = nn.ModuleList([\n            nn.ModuleList([\n                ObliviousDecisionTree(embed_dim, depth, input_dim)\n                for _ in range(num_trees)\n            ]) for _ in range(num_layers)\n        ])\n        self.tree_projections = nn.ModuleList([\n            nn.Linear(2**depth, embed_dim) for _ in range(num_layers)\n        ])\n        self.tree_weights = nn.ParameterList([\n            nn.Parameter(torch.ones(num_trees) / num_trees) for _ in range(num_layers)\n        ])\n        self.layer_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(num_layers)])\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        self.importance_layer = nn.Linear(embed_dim, input_dim)\n\n        for net in self.feature_nets:\n            for layer in net:\n                if isinstance(layer, nn.Linear):\n                    nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n                    if layer.bias is not None:\n                        nn.init.zeros_(layer.bias)\n        nn.init.kaiming_normal_(self.feature_projection.weight, nonlinearity='relu')\n        nn.init.zeros_(self.feature_projection.bias)\n        for proj in self.tree_projections:\n            nn.init.kaiming_normal_(proj.weight, nonlinearity='relu')\n            nn.init.zeros_(proj.bias)\n        nn.init.kaiming_normal_(self.fc_output.weight, nonlinearity='relu')\n        nn.init.zeros_(self.fc_output.bias)\n        nn.init.kaiming_normal_(self.importance_layer.weight, nonlinearity='relu')\n        nn.init.zeros_(self.importance_layer.bias)\n\n    def forward(self, x):\n        input_features = torch.clamp(self.bn(x), -50, 50)\n        input_features = self.feature_selector(input_features)\n        feature_outputs = []\n        for i in range(self.input_dim):\n            feat = input_features[:, i:i+1]\n            feat_out = self.feature_nets[i](feat)\n            if torch.isnan(feat_out).any():\n                tqdm.write(f\"NaN detected in feature_nets[{i}]\")\n            feature_outputs.append(feat_out)\n        x = torch.cat(feature_outputs, dim=1)\n        x = self.feature_projection(x)\n        if torch.isnan(x).any():\n            tqdm.write(\"NaN detected in feature_projection\")\n\n        for layer_idx in range(self.num_layers):\n            tree_outputs = []\n            for tree in self.tree_layers[layer_idx]:\n                tree_out = tree(x, input_features)\n                tree_outputs.append(tree_out)\n            tree_weights = F.softmax(self.tree_weights[layer_idx], dim=0)\n            tree_out = torch.stack(tree_outputs, dim=1)\n            tree_out = torch.einsum('bnt,n->bt', tree_out, tree_weights)\n            tree_out = self.tree_projections[layer_idx](tree_out)\n            x = self.layer_norms[layer_idx](x + tree_out)\n            if torch.isnan(x).any():\n                tqdm.write(f\"NaN detected in tree_layer[{layer_idx}]\")\n\n        output = self.fc_output(x)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu combined (74 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} ch·ª©a gi√° tr·ªã NaN ho·∫∑c Inf\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape c·ªßa d·ªØ li·ªáu\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\naccumulation_steps = 8\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\ntorch.cuda.empty_cache()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = NODEGAM(input_dim=input_dim, num_classes=8, embed_dim=192, num_trees=10, depth=6, num_layers=2, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler()\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Hu·∫•n luy·ªán NODE-GAM v·ªõi Focal + Sparsity Loss (8 Nh√£n, 46 ƒê·∫∑c tr∆∞ng)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Batch Hu·∫•n luy·ªán (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for batch_idx, (X_batch, Y_batch) in enumerate(pbar):\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            \n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n                loss = total_loss / accumulation_steps\n            \n            if torch.isnan(loss) or torch.isinf(loss):\n                tqdm.write(f\"Ph√°t hi·ªán NaN ho·∫∑c Inf trong total_loss t·∫°i batch {batch_idx+1}\")\n                continue\n            \n            scaler.scale(loss).backward()\n            \n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=False)\n            \n            if (batch_idx + 1) % accumulation_steps == 0:\n                scaler.unscale_(optimizer)\n                scaler.step(optimizer)\n                scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if batch_idx < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {batch_idx+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, total_loss, focal_loss, loss\n            torch.cuda.empty_cache()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # ƒê√°nh gi√°\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"ƒê√°nh gi√° (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n                with autocast():\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n                \n                del X_batch, Y_batch, outputs, sparsity_loss, focal_loss, loss\n                torch.cuda.empty_cache()\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (ƒê√°nh gi√°): {pred_counts}\")\n    tqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\n    tqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n h√†ng ƒë·∫ßu: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/nodegam_8labels_46features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/nodegam_8labels_46features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/nodegam_8labels_46features_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_46features_nodegam.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_nodegam.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_nodegam.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_nodegam.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_nodegam.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_nodegam.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_nodegam.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_nodegam.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_nodegam.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_nodegam.npy\", np.array([avg_epoch_time]))\n\n# Ki·ªÉm tra tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/nodegam_8labels_46features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Ki·ªÉm tra\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(X_batch.cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, probs\n            torch.cuda.empty_cache()\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\ntqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"C·∫£nh b√°o: K√≠ch th∆∞·ªõc mask kh√¥ng ƒë·ªìng nh·∫•t: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_nodegam.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_nodegam.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_nodegam.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_nodegam.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_nodegam.npy\", avg_mask)\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/NODE-GAM_8labels_46features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán NODE-GAM (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/NODE-GAM_8labels_46features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"T·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:05:55.8927Z","iopub.execute_input":"2025-04-30T15:05:55.893007Z","iopub.status.idle":"2025-04-30T15:24:01.982701Z","shell.execute_reply.started":"2025-04-30T15:05:55.892985Z","shell.execute_reply":"2025-04-30T15:24:01.981706Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**V·∫º C√ÅC S∆† ƒê·ªí**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"nodegam_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_46features_nodegam.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_46features_nodegam.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_46features_nodegam.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_46features_nodegam.npy\")\n    val_f1_scores = np.load(f\"{results_dir}/val_f1_scores_8labels_46features_nodegam.npy\")\n    val_precisions = np.load(f\"{results_dir}/val_precisions_8labels_46features_nodegam.npy\")\n    val_recalls = np.load(f\"{results_dir}/val_recalls_8labels_46features_nodegam.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_46features_nodegam.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_46features_nodegam.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_46features_nodegam.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_46features_nodegam.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_46features_nodegam.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho NODE-GAM (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\nprint(f\"Val F1 - Min: {val_f1_scores.min():.4f}, Max: {val_f1_scores.max():.4f}, Mean: {val_f1_scores.mean():.4f}\")\nprint(f\"Val Precision - Min: {val_precisions.min():.4f}, Max: {val_precisions.max():.4f}, Mean: {val_precisions.mean():.4f}\")\nprint(f\"Val Recall - Min: {val_recalls.min():.4f}, Max: {val_recalls.max():.4f}, Mean: {val_recalls.mean():.4f}\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2.5)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2.5)\nax1.set_xlabel(\"Epoch\", fontsize=14)\nax1.set_ylabel(\"Loss\", fontsize=14)\nax1.set_title(\"Learning Curve - Loss\", fontsize=16)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, max(1, num_epochs // 5)))\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=10)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=10)\nax1.legend(loc=\"upper right\", fontsize=12)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2.5)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2.5)\nax2.set_xlabel(\"Epoch\", fontsize=14)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=14)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=16)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, max(1, num_epochs // 5)))\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.1\nax2.set_ylim(acc_min - padding, acc_max + padding)\nax2.set_yticks(np.linspace(acc_min - padding, acc_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=10)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=10)\nax2.legend(loc=\"lower right\", fontsize=12)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"NODE-GAM: Learning Curves (8 Labels, 46 Features)\\n{num_epochs} Epochs\", \n             fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_nodegam_8labels_46features.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"NODE-GAM: Confusion Matrix (Test, 8 Labels, 46 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_nodegam_8labels_46features.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"NODE-GAM: ROC Curves (8 Labels, 46 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_nodegam_8labels_46features.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"NODE-GAM: PCA 3D Visualization (8 Labels, 46 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_nodegam_8labels_46features.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 74\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]  # Kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ v·ªÅ ƒë·∫∑c tr∆∞ng\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω shape c·ªßa feature_importance\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (74,) or (n_samples, 74).\")\n\n# Ki·ªÉm tra NaN ho·∫∑c Inf trong feature_importance\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"NODE-GAM: Feature Importance (8 Labels, 46 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_nodegam_8labels_46features.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")\nprint(f\"Val F1 trung b√¨nh: {avg_f1:.4f}\")\nprint(f\"Val Precision trung b√¨nh: {avg_precision:.4f}\")\nprint(f\"Val Recall trung b√¨nh: {avg_recall:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:47:21.982282Z","iopub.execute_input":"2025-04-24T16:47:21.982999Z","iopub.status.idle":"2025-04-24T16:48:07.693472Z","shell.execute_reply.started":"2025-04-24T16:47:21.982972Z","shell.execute_reply":"2025-04-24T16:48:07.692625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nfrom IPython.display import FileLink\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\nprocessed_data_dir = \"/kaggle/working/processed_data\"\nresults_dir = \"/kaggle/working/results\"\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c processed_data\n# processed_zip = \"/kaggle/working/processed_data.zip\"\n# with zipfile.ZipFile(processed_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(processed_data_dir):\n#         for file in files:\n#             file_path = os.path.join(root, file)\n#             # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n#             zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c results\nresults_zip = \"/kaggle/working/results.zip\"\nwith zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(results_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n            zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# Hi·ªÉn th·ªã li√™n k·∫øt t·∫£i xu·ªëng\n# print(\"T·∫£i xu·ªëng processed_data.zip:\")\n# display(FileLink(\"processed_data.zip\"))\n\nprint(\"T·∫£i xu·ªëng results.zip:\")\ndisplay(FileLink(\"results.zip\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:03:36.896997Z","iopub.execute_input":"2025-04-24T09:03:36.897319Z","iopub.status.idle":"2025-04-24T09:03:38.776135Z","shell.execute_reply.started":"2025-04-24T09:03:36.897296Z","shell.execute_reply":"2025-04-24T09:03:38.775464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FT-TRAN**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.amp import GradScaler, autocast\nimport uuid\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d v√† FTTransformerCorrected\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\nclass FTTransformerCorrected(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, num_layers=6, num_heads=4, ff_hidden_dim=768, dropout=0.1):\n        super(FTTransformerCorrected, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.ff_hidden_dim = ff_hidden_dim\n        self.dropout = dropout\n\n        # Feature Tokenizer: Nh√∫ng t·ª´ng ƒë·∫∑c tr∆∞ng ri√™ng l·∫ª\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.feature_embeds = nn.ModuleList([nn.Linear(1, embed_dim) for _ in range(input_dim)])\n        \n        # CLS Token\n        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n        \n        # Transformer Encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_hidden_dim,\n            dropout=dropout, activation='gelu', batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.ln = nn.LayerNorm(embed_dim)\n        \n        # Output Layer\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        \n        # Importance Layer cho Sparsity Loss\n        self.importance_layer = nn.Linear(embed_dim, input_dim)\n\n        # Kh·ªüi t·∫°o tr·ªçng s·ªë\n        for embed in self.feature_embeds:\n            nn.init.xavier_normal_(embed.weight, gain=0.1)\n            nn.init.zeros_(embed.bias)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.fc_output.bias)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n        nn.init.zeros_(self.importance_layer.bias)\n\n    def forward(self, x):\n        # Batch Normalization\n        x = torch.clamp(self.bn(x), -50, 50)\n        \n        # Feature Tokenizer: Nh√∫ng t·ª´ng ƒë·∫∑c tr∆∞ng\n        x = torch.stack([embed(x[:, i:i+1]) for i, embed in enumerate(self.feature_embeds)], dim=1)  # Shape: (batch_size, input_dim, embed_dim)\n        \n        # Th√™m CLS Token\n        batch_size = x.size(0)\n        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # Shape: (batch_size, 1, embed_dim)\n        x = torch.cat([cls_tokens, x], dim=1)  # Shape: (batch_size, input_dim+1, embed_dim)\n        \n        # LayerNorm tr∆∞·ªõc Transformer\n        x = self.ln(x)\n        \n        # Transformer Encoder\n        x = self.transformer(x)  # Shape: (batch_size, input_dim+1, embed_dim)\n        \n        # L·∫•y CLS token cho d·ª± ƒëo√°n\n        embeddings = self.ln(x[:, 0, :])  # Shape: (batch_size, embed_dim)\n        \n        # Output\n        output = self.fc_output(embeddings)\n        \n        # Sparsity Loss (d·ª±a tr√™n nh√∫ng c·ªßa c√°c ƒë·∫∑c tr∆∞ng, kh√¥ng bao g·ªìm CLS token)\n        feature_embeddings = x[:, 1:, :]  # Shape: (batch_size, input_dim, embed_dim)\n        importance = torch.sigmoid(self.importance_layer(feature_embeddings.mean(dim=1)))  # Shape: (batch_size, input_dim)\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n        \n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu combined (74 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    FURTHER = \"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\"\n    tqdm.write(FURTHER)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape c·ªßa d·ªØ li·ªáu\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor (gi·ªØ tr√™n CPU ƒë·ªÉ tr√°nh l·ªói pin_memory)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# Ki·ªÉm tra NaN/Inf trong tensor\nif torch.isnan(X_train_tensor).any() or torch.isinf(X_train_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è X_train_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(Y_train_tensor).any() or torch.isinf(Y_train_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è Y_train_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(X_val_tensor).any() or torch.isinf(X_val_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è X_val_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(Y_val_tensor).any() or torch.isinf(Y_val_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è Y_val_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(X_test_tensor).any() or torch.isinf(X_test_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è X_test_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(Y_test_tensor).any() or torch.isinf(Y_test_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è Y_test_tensor ch·ª©a NaN ho·∫∑c Inf!\")\n\n# DataLoader v·ªõi pin_memory=True\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\ntorch.cuda.empty_cache()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = FTTransformerCorrected(\n    input_dim=input_dim,\n    num_classes=8,\n    embed_dim=192,\n    num_layers=6,\n    num_heads=4,\n    ff_hidden_dim=768,\n    dropout=0.1\n).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler('cuda')\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training FT-Transformer with Focal + Sparsity Loss (8 Labels, 74 Features)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            \n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            if torch.isnan(total_loss) or torch.isinf(total_loss):\n                tqdm.write(f\"NaN or Inf detected in total_loss at batch {pbar.n+1}\")\n                continue\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=False)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n            \n            # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n            del X_batch, Y_batch, outputs, sparsity_loss, masks, total_loss, focal_loss\n            torch.cuda.empty_cache()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n                with autocast('cuda'):\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n                \n                # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n                del X_batch, Y_batch, outputs, sparsity_loss, focal_loss, loss\n                torch.cuda.empty_cache()\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/fttransformer_corrected_8labels_74features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/fttransformer_corrected_8labels_74features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/fttransformer_corrected_8labels_74features_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/fttransformer_corrected_8labels_74features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n            \n            # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n            del X_batch, Y_batch, outputs, sparsity_loss, masks, probs\n            torch.cuda.empty_cache()\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2 partition:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\n# L∆∞u k·∫øt qu·∫£\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_74features_fttransformer_corrected.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_74features_fttransformer_corrected.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_74features_fttransformer_corrected.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_74features_fttransformer_corrected.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_74features_fttransformer_corrected.npy\", avg_mask)\nnp.save(f\"{results_dir}/train_losses_8labels_74features_fttransformer_corrected.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_74features_fttransformer_corrected.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_74features_fttransformer_corrected.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_74features_fttransformer_corrected.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_74features_fttransformer_corrected.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_74features_fttransformer_corrected.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_74features_fttransformer_corrected.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_74features_fttransformer_corrected.npy\", np.array(epoch_times))\n\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_74features_fttransformer_corrected.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_74features_fttransformer_corrected.npy\", np.array([avg_epoch_time]))\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/FTTransformerCorrected_8labels_74features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán FT-Transformer Corrected (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/FTTransformerCorrected_8labels_74features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T16:01:18.219004Z","iopub.execute_input":"2025-05-01T16:01:18.219677Z","iopub.status.idle":"2025-05-01T16:01:26.370959Z","shell.execute_reply.started":"2025-05-01T16:01:18.219653Z","shell.execute_reply":"2025-05-01T16:01:26.369702Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\nTraining FT-Transformer with Focal + Sparsity Loss (8 Labels, 74 Features)\n","output_type":"stream"},{"name":"stderr","text":"                                                                        \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2109407292.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 total_loss, focal_loss, sparsity_loss = combined_loss(\n\u001b[1;32m    289\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_focal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2109407292.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Transformer Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (batch_size, input_dim+1, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# L·∫•y CLS token cho d·ª± ƒëo√°n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             )\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 34.12 MiB is free. Process 2927 has 14.71 GiB memory in use. Of the allocated memory 11.64 GiB is allocated by PyTorch, and 75.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 34.12 MiB is free. Process 2927 has 14.71 GiB memory in use. Of the allocated memory 11.64 GiB is allocated by PyTorch, and 75.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"fttransformer_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_74features_fttransformer.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_74features_fttransformer.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_74features_fttransformer.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_74features_fttransformer.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_74features_fttransformer.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_74features_fttransformer.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_74features_fttransformer.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_74features_fttransformer.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_74features_fttransformer.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho FT-Transformer (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ ch·ª©a 150 epoch\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05\nax2.set_ylim(acc_min - padding, acc_max + padding)\nax2.set_yticks(np.linspace(acc_min - padding, acc_max + padding, 8))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"FT-Transformer: Learning Curves (8 Labels, 74 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_fttransformer_8labels_74features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"FT-Transformer: Confusion Matrix (Test, 8 Labels, 74 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_fttransformer_8labels_74features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"FT-Transformer: ROC Curves (8 Labels, 74 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_fttransformer_8labels_74features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"FT-Transformer: PCA 3D Visualization (8 Labels, 74 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_fttransformer_8labels_74features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 74\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]\n\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (74,) or (n_samples, 74).\")\n\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"FT-Transformer: Feature Importance (8 Labels, 74 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_fttransformer_8labels_74features_150epochs.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T08:56:19.858166Z","iopub.execute_input":"2025-05-01T08:56:19.858551Z","iopub.status.idle":"2025-05-01T08:56:29.010329Z","shell.execute_reply.started":"2025-05-01T08:56:19.858531Z","shell.execute_reply":"2025-05-01T08:56:29.009628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nfrom IPython.display import FileLink\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\nprocessed_data_dir = \"/kaggle/working/processed_data\"\nresults_dir = \"/kaggle/working/results\"\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c processed_data\n# processed_zip = \"/kaggle/working/processed_data.zip\"\n# with zipfile.ZipFile(processed_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(processed_data_dir):\n#         for file in files:\n#             file_path = os.path.join(root, file)\n#             # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n#             zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c results\nresults_zip = \"/kaggle/working/results.zip\"\nwith zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(results_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n            zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# Hi·ªÉn th·ªã li√™n k·∫øt t·∫£i xu·ªëng\n# print(\"T·∫£i xu·ªëng processed_data.zip:\")\n# display(FileLink(\"processed_data.zip\"))\n\nprint(\"T·∫£i xu·ªëng results.zip:\")\ndisplay(FileLink(\"results.zip\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T14:05:35.281988Z","iopub.execute_input":"2025-04-30T14:05:35.282497Z","iopub.status.idle":"2025-04-30T14:05:37.176609Z","shell.execute_reply.started":"2025-04-30T14:05:35.282469Z","shell.execute_reply":"2025-04-30T14:05:37.175995Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FT-TRAN**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.amp import GradScaler, autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss v√† GhostBN1d\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# ƒê·ªãnh nghƒ©a l·ªõp FTTransformer chu·∫©n\nclass FTTransformer(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, num_layers=6, num_heads=4, ff_hidden_dim=768, dropout=0.1, use_cls_token=True):\n        super(FTTransformer, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.ff_hidden_dim = ff_hidden_dim\n        self.dropout = dropout\n        self.use_cls_token = use_cls_token\n\n        # Feature Tokenizer\n        self.feature_tokenizers = nn.ModuleList([\n            nn.Linear(1, embed_dim) for _ in range(input_dim)\n        ])\n\n        # BatchNorm\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # CLS token\n        if self.use_cls_token:\n            self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n\n        # Transformer Encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=ff_hidden_dim,\n            dropout=dropout,\n            activation='gelu',\n            batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n        # LayerNorm\n        self.ln = nn.LayerNorm(embed_dim)\n\n        # Output layer\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n\n        # Importance layer\n        self.importance_layer = nn.Linear(embed_dim, input_dim)\n\n        # Kh·ªüi t·∫°o tr·ªçng s·ªë\n        for tokenizer in self.feature_tokenizers:\n            nn.init.xavier_normal_(tokenizer.weight, gain=0.1)\n            nn.init.zeros_(tokenizer.bias)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.fc_output.bias)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n        nn.init.zeros_(self.importance_layer.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n\n        # Tokenization\n        tokens = []\n        for i in range(self.input_dim):\n            feat = x[:, i:i+1]\n            token = self.feature_tokenizers[i](feat)\n            tokens.append(token)\n        x = torch.stack(tokens, dim=1)\n\n        # Th√™m CLS token\n        if self.use_cls_token:\n            batch_size = x.size(0)\n            cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n            x = torch.cat([cls_tokens, x], dim=1)\n\n        # Transformer\n        x = self.transformer(x)\n        x = self.ln(x)\n\n        # Pooling\n        if self.use_cls_token:\n            embeddings = x[:, 0, :]\n        else:\n            embeddings = x.mean(dim=1)\n\n        # Output\n        output = self.fc_output(embeddings)\n\n        # Importance v√† sparsity loss\n        importance = torch.sigmoid(self.importance_layer(embeddings))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(\n            -importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6)\n        )\n        masks = [importance]\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\nX_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\nX_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\nX_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long).to(device)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32).to(device)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long).to(device)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long).to(device)\n\n# DataLoader\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = FTTransformer(\n    input_dim=input_dim,\n    num_classes=8,\n    embed_dim=192,\n    num_layers=6,\n    num_heads=4,\n    ff_hidden_dim=768,\n    dropout=0.1,\n    use_cls_token=True\n).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler('cuda')\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training FT-Transformer with Focal + Sparsity Loss (8 Labels, 46 Features)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            \n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            if torch.isnan(total_loss):\n                tqdm.write(f\"NaN detected in total_loss at batch {pbar.n+1}\")\n                continue\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                with autocast('cuda'):\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\" COGNITIVE MATRIX:\\n{cm}\")\n    tqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/fttransformer_8labels_46features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/fttransformer_8labels_46features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/fttransformer_8labels_46features_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/fttransformer_8labels_46features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_fttransformer.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_fttransformer.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_fttransformer.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_fttransformer.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_fttransformer.npy\", avg_mask)\nnp.save(f\"{results_dir}/train_losses_8labels_46features_fttransformer.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_fttransformer.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_fttransformer.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_fttransformer.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_fttransformer.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_fttransformer.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_fttransformer.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_fttransformer.npy\", np.array(epoch_times))\n\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_fttransformer.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_fttransformer.npy\", np.array([avg_epoch_time]))\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/FTTransformer_8labels_46features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán FT-Transformer (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/FTTransformer_8labels_46features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nfrom IPython.display import FileLink\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\nprocessed_data_dir = \"/kaggle/working/processed_data\"\nresults_dir = \"/kaggle/working/results\"\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c processed_data\n# processed_zip = \"/kaggle/working/processed_data.zip\"\n# with zipfile.ZipFile(processed_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(processed_data_dir):\n#         for file in files:\n#             file_path = os.path.join(root, file)\n#             # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n#             zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c results\nresults_zip = \"/kaggle/working/results.zip\"\nwith zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(results_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n            zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# Hi·ªÉn th·ªã li√™n k·∫øt t·∫£i xu·ªëng\n# print(\"T·∫£i xu·ªëng processed_data.zip:\")\n# display(FileLink(\"processed_data.zip\"))\n\nprint(\"T·∫£i xu·ªëng results.zip:\")\ndisplay(FileLink(\"results.zip\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T08:57:13.036846Z","iopub.execute_input":"2025-05-01T08:57:13.037135Z","iopub.status.idle":"2025-05-01T08:57:17.771964Z","shell.execute_reply.started":"2025-05-01T08:57:13.037114Z","shell.execute_reply":"2025-05-01T08:57:17.771303Z"}},"outputs":[],"execution_count":null}]}