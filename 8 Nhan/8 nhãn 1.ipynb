{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6126678,"sourceType":"datasetVersion","datasetId":3512311}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn import preprocessing\nfrom sklearn.cluster import DBSCAN\nfrom tabulate import tabulate\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split \nimport seaborn as sns\nimport numpy as np\n# importing required libraries for normalizing data\nfrom sklearn.preprocessing import StandardScaler,LabelBinarizer,MinMaxScaler\nfrom sklearn.neighbors import NearestNeighbors\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\n# representation of model layers\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score , classification_report\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\nimport joblib\nfrom sklearn.svm import SVC\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T07:31:10.440434Z","iopub.execute_input":"2025-05-04T07:31:10.440592Z","iopub.status.idle":"2025-05-04T07:31:27.315715Z","shell.execute_reply.started":"2025-05-04T07:31:10.440576Z","shell.execute_reply":"2025-05-04T07:31:27.315131Z"}},"outputs":[{"name":"stderr","text":"2025-05-04 07:31:14.147437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746343874.385593      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746343874.451518      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **ƒê·ªåC D·ªÆ LI·ªÜU 8 NH√ÉN**","metadata":{}},{"cell_type":"code","source":"\n\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib.pyplot as plt\nimport cudf  # D√πng cuDF ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu nhanh h∆°n tr√™n GPU\nimport numpy as np\nfrom sklearn.utils import resample\n\n# ƒê·ªãnh nghƒ©a th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# H√†m √°nh x·∫° nh√£n th√†nh 8 nh√≥m\ndef change_label(df):\n    mapping = {\n        'DDoS-ICMP_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS',\n        'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-RSTFINFlood': 'DDoS',\n        'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n        'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n        'DDoS-HTTP_Flood': 'DDoS', 'DDoS-SlowLoris': 'DDoS',\n        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n        'DictionaryBruteForce': 'BruteForce',\n        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n        'BenignTraffic': 'BENIGN'\n    }\n    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n    return df\n\n# ƒê·ªçc d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c\ndata_dir = \"/kaggle/input/cic-iot-2023/\"\nfile_list = glob.glob(f\"{data_dir}*.csv\")[:168]  # L·∫•y t·ªëi ƒëa 134 file\n\n# Gi·ªõi h·∫°n t·ªëi ƒëa v√† t·ªëi thi·ªÉu 400,000 d√≤ng cho m·ªói nh√£n\nMAX_ROWS_PER_LABEL = 400_000\nMIN_ROWS_PER_LABEL = 400_000\nlabel_counts = {\n    \"DDoS\": 0, \"DoS\": 0, \"Recon\": 0, \"Spoofing\": 0,\n    \"BruteForce\": 0, \"Web-based\": 0, \"Mirai\": 0, \"BENIGN\": 0\n}  # Theo d√µi s·ªë d√≤ng c·ªßa t·ª´ng nh√£n\n\ndef read_file(filename, index):\n    try:\n        # ƒê·ªçc file CSV b·∫±ng cuDF\n        df = cudf.read_csv(filename)\n        \n        # Ki·ªÉm tra c·ªôt 'label'\n        if 'label' not in df.columns:\n            print(f\"‚ùå File {filename}: Kh√¥ng t√¨m th·∫•y c·ªôt 'label'!\")\n            return None\n        \n        # √Ånh x·∫° nh√£n th√†nh 8 nh√≥m\n        df = change_label(df)\n        \n        # L·ªçc d·ªØ li·ªáu d·ª±a tr√™n gi·ªõi h·∫°n 400K cho m·ªói nh√£n\n        valid_rows = []\n        unique_labels = df['label'].unique().to_pandas().tolist()\n        for label in unique_labels:\n            current_count = label_counts.get(label, 0)\n            remaining_quota = MAX_ROWS_PER_LABEL - current_count\n            \n            if remaining_quota <= 0:\n                print(f\"‚ö† Nh√£n {label} ƒë√£ ƒë·ªß {MAX_ROWS_PER_LABEL:,} d√≤ng, kh√¥ng ƒë·ªçc th√™m!\")\n                continue\n            \n            # L·∫•y c√°c d√≤ng thu·ªôc nh√£n n√†y\n            label_df = df[df['label'] == label]\n            rows_to_take = min(len(label_df), remaining_quota)\n            \n            if rows_to_take > 0:\n                valid_rows.append(label_df[:rows_to_take])\n                label_counts[label] = current_count + rows_to_take\n                print(f\"üìå Nh√£n {label}: Th√™m {rows_to_take:,} d√≤ng, t·ªïng c·ªông {label_counts[label]:,} d√≤ng\")\n        \n        # G·ªôp c√°c d√≤ng h·ª£p l·ªá\n        if valid_rows:\n            df_filtered = cudf.concat(valid_rows, ignore_index=True)\n            print(f\"üìå File {index}: Gi·ªØ {df_filtered.shape[0]:,} d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\")\n            return df_filtered\n        else:\n            print(f\"‚ö† File {index}: Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c gi·ªØ l·∫°i!\")\n            return None\n    except Exception as e:\n        print(f\"‚ùå L·ªói khi ƒë·ªçc file {filename}: {e}\")\n        return None\n\n# ƒê·ªçc tu·∫ßn t·ª± t·ª´ng file\ndfs = []\nfor idx, fname in enumerate(file_list):\n    df = read_file(fname, idx)\n    if df is not None:\n        dfs.append(df)\n\n# N·ªëi d·ªØ li·ªáu v√† x·ª≠ l√Ω c√¢n b·∫±ng\nif dfs:\n    df_full = cudf.concat(dfs, ignore_index=True)\n    print(f\"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi! K√≠ch th∆∞·ªõc: {df_full.shape}\")\n    print(f\"üìã Nh√£n duy nh·∫•t: {df_full['label'].unique().to_pandas().tolist()}\")\n    \n    # Chuy·ªÉn sang pandas ƒë·ªÉ x·ª≠ l√Ω oversampling\n    df_pandas = df_full.to_pandas()\n    \n    # Ki·ªÉm tra ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng\n    print(\"\\nüìã Ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng:\")\n    label_distribution = df_pandas[\"label\"].value_counts()\n    print(label_distribution)\n    \n    # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng\n    fig, ax = plt.subplots(figsize=(12, 6))\n    bars = ax.bar(label_distribution.index, label_distribution.values, color=['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow'])\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of 8 Labels (Before Oversampling)')\n    for bar in bars:\n        height = bar.get_height()\n        ax.annotate(f'{int(height):,}',\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', fontsize=10)\n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/label_distribution_before_oversampling.png')\n    plt.show()\n    \n    # Chu·∫©n b·ªã d·ªØ li·ªáu cho oversampling\n    balanced_dfs = []\n    unique_labels = df_pandas['label'].unique()\n    \n    # √Åp d·ª•ng oversampling th·ªß c√¥ng cho m·ªói nh√£n\n    for label in unique_labels:\n        label_df = df_pandas[df_pandas['label'] == label]\n        current_count = len(label_df)\n        \n        if current_count < MIN_ROWS_PER_LABEL:\n            # Oversampling b·∫±ng resample\n            oversampled_df = resample(\n                label_df,\n                replace=True,  # Cho ph√©p sao ch√©p m·∫´u\n                n_samples=MIN_ROWS_PER_LABEL,  # ƒê·∫°t 400K\n                random_state=42\n            )\n            print(f\"üìå Oversampling nh√£n {label}: T·ª´ {current_count:,} l√™n {MIN_ROWS_PER_LABEL:,} d√≤ng\")\n            balanced_dfs.append(oversampled_df)\n        else:\n            print(f\"üìå Nh√£n {label}: ƒê√£ c√≥ {current_count:,} d√≤ng, gi·ªØ nguy√™n\")\n            balanced_dfs.append(label_df)\n    \n    # G·ªôp d·ªØ li·ªáu ƒë√£ c√¢n b·∫±ng\n    df_balanced = pd.concat(balanced_dfs, ignore_index=True)\n    \n    # Chuy·ªÉn l·∫°i th√†nh cuDF ƒë·ªÉ ƒë·ªìng b·ªô\n    df_full = cudf.from_pandas(df_balanced)\n    \n    # Ki·ªÉm tra ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng\n    print(\"\\nüìã Ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng b·∫±ng oversampling:\")\n    balanced_label_distribution = df_full[\"label\"].value_counts().to_pandas()\n    print(balanced_label_distribution)\n    \n    # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng\n    fig, ax = plt.subplots(figsize=(12, 6))\n    bars = ax.bar(balanced_label_distribution.index, balanced_label_distribution.values, color=['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow'])\n    plt.xticks(rotation=45, ha='right', fontsize=10)\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n    ax.set_xlabel('Labels')\n    ax.set_ylabel('Count')\n    ax.set_title('Distribution of 8 Labels (After Oversampling)')\n    for bar in bars:\n        height = bar.get_height()\n        ax.annotate(f'{int(height):,}',\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', fontsize=10)\n    plt.tight_layout()\n    plt.savefig(f'{output_dir}/label_distribution_after_oversampling.png')\n    plt.show()\n    \n    # # L∆∞u df_full ƒë√£ c√¢n b·∫±ng ƒë·ªÉ ki·ªÉm tra\n    # df_full.to_pandas().to_csv(f'{output_dir}/balanced_data_8labels.csv', index=False)\n    # print(f\"‚úÖ D·ªØ li·ªáu ƒë√£ c√¢n b·∫±ng v√† l∆∞u t·∫°i '{output_dir}/balanced_data_8labels.csv'\")\n    \nelse:\n    print(\"‚ö† Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c ƒë·ªçc th√†nh c√¥ng ho·∫∑c t·∫•t c·∫£ d·ªØ li·ªáu r·ªóng!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T07:32:30.637130Z","iopub.execute_input":"2025-05-04T07:32:30.637471Z","iopub.status.idle":"2025-05-04T07:33:41.228945Z","shell.execute_reply.started":"2025-05-04T07:32:30.637449Z","shell.execute_reply":"2025-05-04T07:33:41.228279Z"}},"outputs":[{"name":"stdout","text":"üìå Nh√£n Mirai: Th√™m 13,351 d√≤ng, t·ªïng c·ªông 13,351 d√≤ng\nüìå Nh√£n DDoS: Th√™m 174,841 d√≤ng, t·ªïng c·ªông 174,841 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,572 d√≤ng, t·ªïng c·ªông 2,572 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,645 d√≤ng, t·ªïng c·ªông 5,645 d√≤ng\nüìå Nh√£n DoS: Th√™m 41,221 d√≤ng, t·ªïng c·ªông 41,221 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,876 d√≤ng, t·ªïng c·ªông 1,876 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 55 d√≤ng\nüìå Nh√£n Web-based: Th√™m 105 d√≤ng, t·ªïng c·ªông 105 d√≤ng\nüìå File 0: Gi·ªØ 239,666 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Recon: Th√™m 1,888 d√≤ng, t·ªïng c·ªông 3,764 d√≤ng\nüìå Nh√£n DoS: Th√™m 41,933 d√≤ng, t·ªïng c·ªông 83,154 d√≤ng\nüìå Nh√£n DDoS: Th√™m 176,390 d√≤ng, t·ªïng c·ªông 351,231 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,615 d√≤ng, t·ªïng c·ªông 26,966 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,544 d√≤ng, t·ªïng c·ªông 5,116 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,778 d√≤ng, t·ªïng c·ªông 11,423 d√≤ng\nüìå Nh√£n Web-based: Th√™m 147 d√≤ng, t·ªïng c·ªông 252 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 125 d√≤ng\nüìå File 1: Gi·ªØ 242,365 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n DoS: Th√™m 40,184 d√≤ng, t·ªïng c·ªông 123,338 d√≤ng\nüìå Nh√£n DDoS: Th√™m 48,769 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,440 d√≤ng, t·ªïng c·ªông 16,863 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,116 d√≤ng, t·ªïng c·ªông 40,082 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,448 d√≤ng, t·ªïng c·ªông 7,564 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,780 d√≤ng, t·ªïng c·ªông 5,544 d√≤ng\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 368 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 194 d√≤ng\nüìå File 2: Gi·ªØ 111,922 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n DoS: Th√™m 38,499 d√≤ng, t·ªïng c·ªông 161,837 d√≤ng\nüìå Nh√£n Mirai: Th√™m 12,555 d√≤ng, t·ªïng c·ªông 52,637 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,416 d√≤ng, t·ªïng c·ªông 22,279 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,340 d√≤ng, t·ªïng c·ªông 9,904 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,621 d√≤ng, t·ªïng c·ªông 7,165 d√≤ng\nüìå Nh√£n Web-based: Th√™m 109 d√≤ng, t·ªïng c·ªông 477 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 256 d√≤ng\nüìå File 3: Gi·ªØ 60,602 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Mirai: Th√™m 12,916 d√≤ng, t·ªïng c·ªông 65,553 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,394 d√≤ng, t·ªïng c·ªông 27,673 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n DoS: Th√™m 40,054 d√≤ng, t·ªïng c·ªông 201,891 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,384 d√≤ng, t·ªïng c·ªông 12,288 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,751 d√≤ng, t·ªïng c·ªông 8,916 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 327 d√≤ng\nüìå Nh√£n Web-based: Th√™m 119 d√≤ng, t·ªïng c·ªông 596 d√≤ng\nüìå File 4: Gi·ªØ 62,689 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,881 d√≤ng, t·ªïng c·ªông 10,797 d√≤ng\nüìå Nh√£n DoS: Th√™m 44,363 d√≤ng, t·ªïng c·ªông 246,254 d√≤ng\nüìå Nh√£n Mirai: Th√™m 14,296 d√≤ng, t·ªïng c·ªông 79,849 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,967 d√≤ng, t·ªïng c·ªông 33,640 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,745 d√≤ng, t·ªïng c·ªông 15,033 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 398 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 728 d√≤ng\nüìå File 5: Gi·ªØ 69,455 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,595 d√≤ng, t·ªïng c·ªông 39,235 d√≤ng\nüìå Nh√£n DoS: Th√™m 41,313 d√≤ng, t·ªïng c·ªông 287,567 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,503 d√≤ng, t·ªïng c·ªông 93,352 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,439 d√≤ng, t·ªïng c·ªông 17,472 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,792 d√≤ng, t·ªïng c·ªông 12,589 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 458 d√≤ng\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 841 d√≤ng\nüìå File 6: Gi·ªØ 64,815 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n DoS: Th√™m 75,694 d√≤ng, t·ªïng c·ªông 363,261 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,570 d√≤ng, t·ªïng c·ªông 22,042 d√≤ng\nüìå Nh√£n Mirai: Th√™m 24,591 d√≤ng, t·ªïng c·ªông 117,943 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,369 d√≤ng, t·ªïng c·ªông 15,958 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 10,315 d√≤ng, t·ªïng c·ªông 49,550 d√≤ng\nüìå Nh√£n Web-based: Th√™m 218 d√≤ng, t·ªïng c·ªông 1,059 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 113 d√≤ng, t·ªïng c·ªông 571 d√≤ng\nüìå File 7: Gi·ªØ 118,870 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,507 d√≤ng, t·ªïng c·ªông 60,057 d√≤ng\nüìå Nh√£n DoS: Th√™m 36,739 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\nüìå Nh√£n Mirai: Th√™m 25,726 d√≤ng, t·ªïng c·ªông 143,669 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,515 d√≤ng, t·ªïng c·ªông 19,473 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,731 d√≤ng, t·ªïng c·ªông 26,773 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 133 d√≤ng, t·ªïng c·ªông 704 d√≤ng\nüìå Nh√£n Web-based: Th√™m 238 d√≤ng, t·ªïng c·ªông 1,297 d√≤ng\nüìå File 8: Gi·ªØ 81,589 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 14,721 d√≤ng, t·ªïng c·ªông 158,390 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 6,171 d√≤ng, t·ªïng c·ªông 66,228 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,676 d√≤ng, t·ªïng c·ªông 29,449 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,036 d√≤ng, t·ªïng c·ªông 21,509 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 91 d√≤ng, t·ªïng c·ªông 795 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 1,440 d√≤ng\nüìå File 9: Gi·ªØ 25,838 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,570 d√≤ng, t·ªïng c·ªông 71,798 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,343 d√≤ng, t·ªïng c·ªông 171,733 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,808 d√≤ng, t·ªïng c·ªông 23,317 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,418 d√≤ng, t·ªïng c·ªông 31,867 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 1,555 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 860 d√≤ng\nüìå File 10: Gi·ªØ 23,319 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,096 d√≤ng, t·ªïng c·ªông 184,829 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,773 d√≤ng, t·ªïng c·ªông 25,090 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,409 d√≤ng, t·ªïng c·ªông 34,276 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,460 d√≤ng, t·ªïng c·ªông 77,258 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 923 d√≤ng\nüìå Nh√£n Web-based: Th√™m 119 d√≤ng, t·ªïng c·ªông 1,674 d√≤ng\nüìå File 11: Gi·ªØ 22,920 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,036 d√≤ng, t·ªïng c·ªông 197,865 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,432 d√≤ng, t·ªïng c·ªông 82,690 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,797 d√≤ng, t·ªïng c·ªông 26,887 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,467 d√≤ng, t·ªïng c·ªông 36,743 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 1,806 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 983 d√≤ng\nüìå File 12: Gi·ªØ 22,924 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,255 d√≤ng, t·ªïng c·ªông 92,945 d√≤ng\nüìå Nh√£n Mirai: Th√™m 24,651 d√≤ng, t·ªïng c·ªông 222,516 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,506 d√≤ng, t·ªïng c·ªông 41,249 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,300 d√≤ng, t·ªïng c·ªông 30,187 d√≤ng\nüìå Nh√£n Web-based: Th√™m 231 d√≤ng, t·ªïng c·ªông 2,037 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 116 d√≤ng, t·ªïng c·ªông 1,099 d√≤ng\nüìå File 13: Gi·ªØ 43,059 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,337 d√≤ng, t·ªïng c·ªông 235,853 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,740 d√≤ng, t·ªïng c·ªông 31,927 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,526 d√≤ng, t·ªïng c·ªông 98,471 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,448 d√≤ng, t·ªïng c·ªông 43,697 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 1,156 d√≤ng\nüìå Nh√£n Web-based: Th√™m 112 d√≤ng, t·ªïng c·ªông 2,149 d√≤ng\nüìå File 14: Gi·ªØ 23,220 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Mirai: Th√™m 13,949 d√≤ng, t·ªïng c·ªông 249,802 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,622 d√≤ng, t·ªïng c·ªông 46,319 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,774 d√≤ng, t·ªïng c·ªông 104,245 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,816 d√≤ng, t·ªïng c·ªông 33,743 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 58 d√≤ng, t·ªïng c·ªông 1,214 d√≤ng\nüìå Nh√£n Web-based: Th√™m 127 d√≤ng, t·ªïng c·ªông 2,276 d√≤ng\nüìå File 15: Gi·ªØ 24,346 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 25,078 d√≤ng, t·ªïng c·ªông 274,880 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,341 d√≤ng, t·ªïng c·ªông 114,586 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,581 d√≤ng, t·ªïng c·ªông 50,900 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,366 d√≤ng, t·ªïng c·ªông 37,109 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 139 d√≤ng, t·ªïng c·ªông 1,353 d√≤ng\nüìå Nh√£n Web-based: Th√™m 222 d√≤ng, t·ªïng c·ªông 2,498 d√≤ng\nüìå File 16: Gi·ªØ 43,727 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 6,034 d√≤ng, t·ªïng c·ªông 120,620 d√≤ng\nüìå Nh√£n Mirai: Th√™m 14,294 d√≤ng, t·ªïng c·ªông 289,174 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,915 d√≤ng, t·ªïng c·ªông 39,024 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,595 d√≤ng, t·ªïng c·ªông 53,495 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 1,425 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 2,638 d√≤ng\nüìå File 17: Gi·ªØ 25,050 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,400 d√≤ng, t·ªïng c·ªông 126,020 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,322 d√≤ng, t·ªïng c·ªông 302,496 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,742 d√≤ng, t·ªïng c·ªông 40,766 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,473 d√≤ng, t·ªïng c·ªông 55,968 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 1,480 d√≤ng\nüìå Nh√£n Web-based: Th√™m 125 d√≤ng, t·ªïng c·ªông 2,763 d√≤ng\nüìå File 18: Gi·ªØ 23,117 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 13,604 d√≤ng, t·ªïng c·ªông 316,100 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,478 d√≤ng, t·ªïng c·ªông 58,446 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,680 d√≤ng, t·ªïng c·ªông 131,700 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,832 d√≤ng, t·ªïng c·ªông 42,598 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 1,537 d√≤ng\nüìå Nh√£n Web-based: Th√™m 129 d√≤ng, t·ªïng c·ªông 2,892 d√≤ng\nüìå File 19: Gi·ªØ 23,780 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 11,949 d√≤ng, t·ªïng c·ªông 328,049 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 4,886 d√≤ng, t·ªïng c·ªông 136,586 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,606 d√≤ng, t·ªïng c·ªông 44,204 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,214 d√≤ng, t·ªïng c·ªông 60,660 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 1,604 d√≤ng\nüìå Nh√£n Web-based: Th√™m 103 d√≤ng, t·ªïng c·ªông 2,995 d√≤ng\nüìå File 20: Gi·ªØ 20,825 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 14,224 d√≤ng, t·ªïng c·ªông 342,273 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,716 d√≤ng, t·ªïng c·ªông 63,376 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,906 d√≤ng, t·ªïng c·ªông 142,492 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,001 d√≤ng, t·ªïng c·ªông 46,205 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 1,682 d√≤ng\nüìå Nh√£n Web-based: Th√™m 148 d√≤ng, t·ªïng c·ªông 3,143 d√≤ng\nüìå File 21: Gi·ªØ 25,073 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Mirai: Th√™m 15,456 d√≤ng, t·ªïng c·ªông 357,729 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,090 d√≤ng, t·ªïng c·ªông 48,295 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,905 d√≤ng, t·ªïng c·ªông 66,281 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 6,387 d√≤ng, t·ªïng c·ªông 148,879 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 3,265 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 92 d√≤ng, t·ªïng c·ªông 1,774 d√≤ng\nüìå File 22: Gi·ªØ 27,052 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,753 d√≤ng, t·ªïng c·ªông 50,048 d√≤ng\nüìå Nh√£n Mirai: Th√™m 13,082 d√≤ng, t·ªïng c·ªông 370,811 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,397 d√≤ng, t·ªïng c·ªông 154,276 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 1,838 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,376 d√≤ng, t·ªïng c·ªông 68,657 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 3,380 d√≤ng\nüìå File 23: Gi·ªØ 22,787 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 24,392 d√≤ng, t·ªïng c·ªông 395,203 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 10,210 d√≤ng, t·ªïng c·ªông 164,486 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,478 d√≤ng, t·ªïng c·ªông 73,135 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,429 d√≤ng, t·ªïng c·ªông 53,477 d√≤ng\nüìå Nh√£n Web-based: Th√™m 235 d√≤ng, t·ªïng c·ªông 3,615 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 128 d√≤ng, t·ªïng c·ªông 1,966 d√≤ng\nüìå File 24: Gi·ªØ 42,872 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Mirai: Th√™m 4,797 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,209 d√≤ng, t·ªïng c·ªông 75,344 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,158 d√≤ng, t·ªïng c·ªông 169,644 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,662 d√≤ng, t·ªïng c·ªông 55,139 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 3,732 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 2,036 d√≤ng\nüìå File 25: Gi·ªØ 14,013 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,864 d√≤ng, t·ªïng c·ªông 57,003 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,519 d√≤ng, t·ªïng c·ªông 77,863 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,609 d√≤ng, t·ªïng c·ªông 175,253 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 2,110 d√≤ng\nüìå Nh√£n Web-based: Th√™m 133 d√≤ng, t·ªïng c·ªông 3,865 d√≤ng\nüìå File 26: Gi·ªØ 10,199 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,447 d√≤ng, t·ªïng c·ªông 180,700 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,687 d√≤ng, t·ªïng c·ªông 58,690 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,309 d√≤ng, t·ªïng c·ªông 80,172 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 2,174 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 4,002 d√≤ng\nüìå File 27: Gi·ªØ 9,644 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,519 d√≤ng, t·ªïng c·ªông 82,691 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,830 d√≤ng, t·ªïng c·ªông 60,520 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,519 d√≤ng, t·ªïng c·ªông 186,219 d√≤ng\nüìå Nh√£n Web-based: Th√™m 131 d√≤ng, t·ªïng c·ªông 4,133 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 2,244 d√≤ng\nüìå File 28: Gi·ªØ 10,069 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,563 d√≤ng, t·ªïng c·ªông 196,782 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,245 d√≤ng, t·ªïng c·ªông 63,765 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,583 d√≤ng, t·ªïng c·ªông 87,274 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 118 d√≤ng, t·ªïng c·ªông 2,362 d√≤ng\nüìå Nh√£n Web-based: Th√™m 206 d√≤ng, t·ªïng c·ªông 4,339 d√≤ng\nüìå File 29: Gi·ªØ 18,715 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Spoofing: Th√™m 4,541 d√≤ng, t·ªïng c·ªông 91,815 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,566 d√≤ng, t·ªïng c·ªông 207,348 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,297 d√≤ng, t·ªïng c·ªông 67,062 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 127 d√≤ng, t·ªïng c·ªông 2,489 d√≤ng\nüìå Nh√£n Web-based: Th√™m 240 d√≤ng, t·ªïng c·ªông 4,579 d√≤ng\nüìå File 30: Gi·ªØ 18,771 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,432 d√≤ng, t·ªïng c·ªông 212,780 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,755 d√≤ng, t·ªïng c·ªông 68,817 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,403 d√≤ng, t·ªïng c·ªông 94,218 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 2,549 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 4,705 d√≤ng\nüìå File 31: Gi·ªØ 9,776 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,175 d√≤ng, t·ªïng c·ªông 217,955 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,256 d√≤ng, t·ªïng c·ªông 96,474 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,713 d√≤ng, t·ªïng c·ªông 70,530 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 2,626 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 4,844 d√≤ng\nüìå File 32: Gi·ªØ 9,360 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,221 d√≤ng, t·ªïng c·ªông 223,176 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,398 d√≤ng, t·ªïng c·ªông 98,872 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,636 d√≤ng, t·ªïng c·ªông 72,166 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 53 d√≤ng, t·ªïng c·ªông 2,679 d√≤ng\nüìå Nh√£n Web-based: Th√™m 134 d√≤ng, t·ªïng c·ªông 4,978 d√≤ng\nüìå File 33: Gi·ªØ 9,442 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,345 d√≤ng, t·ªïng c·ªông 228,521 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,820 d√≤ng, t·ªïng c·ªông 73,986 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,485 d√≤ng, t·ªïng c·ªông 101,357 d√≤ng\nüìå Nh√£n Web-based: Th√™m 98 d√≤ng, t·ªïng c·ªông 5,076 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 2,734 d√≤ng\nüìå File 34: Gi·ªØ 9,803 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,227 d√≤ng, t·ªïng c·ªông 238,748 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,382 d√≤ng, t·ªïng c·ªông 77,368 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,433 d√≤ng, t·ªïng c·ªông 105,790 d√≤ng\nüìå Nh√£n Web-based: Th√™m 243 d√≤ng, t·ªïng c·ªông 5,319 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 114 d√≤ng, t·ªïng c·ªông 2,848 d√≤ng\nüìå File 35: Gi·ªØ 18,399 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,481 d√≤ng, t·ªïng c·ªông 244,229 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,435 d√≤ng, t·ªïng c·ªông 108,225 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,744 d√≤ng, t·ªïng c·ªông 79,112 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 5,458 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 79 d√≤ng, t·ªïng c·ªông 2,927 d√≤ng\nüìå File 36: Gi·ªØ 9,878 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,163 d√≤ng, t·ªïng c·ªông 249,392 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,698 d√≤ng, t·ªïng c·ªông 80,810 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,311 d√≤ng, t·ªïng c·ªông 110,536 d√≤ng\nüìå Nh√£n Web-based: Th√™m 133 d√≤ng, t·ªïng c·ªông 5,591 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 2,989 d√≤ng\nüìå File 37: Gi·ªØ 9,367 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,845 d√≤ng, t·ªïng c·ªông 82,655 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,838 d√≤ng, t·ªïng c·ªông 255,230 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,582 d√≤ng, t·ªïng c·ªông 113,118 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 3,056 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 5,708 d√≤ng\nüìå File 38: Gi·ªØ 10,449 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 6,490 d√≤ng, t·ªïng c·ªông 261,720 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,106 d√≤ng, t·ªïng c·ªông 84,761 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,926 d√≤ng, t·ªïng c·ªông 116,044 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 3,129 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 5,848 d√≤ng\nüìå File 39: Gi·ªØ 11,735 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,722 d√≤ng, t·ªïng c·ªông 86,483 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,317 d√≤ng, t·ªïng c·ªông 267,037 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,335 d√≤ng, t·ªïng c·ªông 118,379 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 5,987 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 56 d√≤ng, t·ªïng c·ªông 3,185 d√≤ng\nüìå File 40: Gi·ªØ 9,569 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,451 d√≤ng, t·ªïng c·ªông 120,830 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,608 d√≤ng, t·ªïng c·ªông 272,645 d√≤ng\nüìå Nh√£n Web-based: Th√™m 123 d√≤ng, t·ªïng c·ªông 6,110 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,804 d√≤ng, t·ªïng c·ªông 88,287 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 3,250 d√≤ng\nüìå File 41: Gi·ªØ 10,051 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Spoofing: Th√™m 4,557 d√≤ng, t·ªïng c·ªông 125,387 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,348 d√≤ng, t·ªïng c·ªông 282,993 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,231 d√≤ng, t·ªïng c·ªông 91,518 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 232 d√≤ng, t·ªïng c·ªông 6,342 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 140 d√≤ng, t·ªïng c·ªông 3,390 d√≤ng\nüìå File 42: Gi·ªØ 18,508 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 3,462 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,464 d√≤ng, t·ªïng c·ªông 127,851 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,656 d√≤ng, t·ªïng c·ªông 288,649 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,843 d√≤ng, t·ªïng c·ªông 93,361 d√≤ng\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 6,470 d√≤ng\nüìå File 43: Gi·ªØ 10,163 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,367 d√≤ng, t·ªïng c·ªông 130,218 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,291 d√≤ng, t·ªïng c·ªông 293,940 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,639 d√≤ng, t·ªïng c·ªông 95,000 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 59 d√≤ng, t·ªïng c·ªông 3,521 d√≤ng\nüìå Nh√£n Web-based: Th√™m 119 d√≤ng, t·ªïng c·ªông 6,589 d√≤ng\nüìå File 44: Gi·ªØ 9,475 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,390 d√≤ng, t·ªïng c·ªông 299,330 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,345 d√≤ng, t·ªïng c·ªông 132,563 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,746 d√≤ng, t·ªïng c·ªông 96,746 d√≤ng\nüìå Nh√£n Web-based: Th√™m 155 d√≤ng, t·ªïng c·ªông 6,744 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 56 d√≤ng, t·ªïng c·ªông 3,577 d√≤ng\nüìå File 45: Gi·ªØ 9,692 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,699 d√≤ng, t·ªïng c·ªông 98,445 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,270 d√≤ng, t·ªïng c·ªông 134,833 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,199 d√≤ng, t·ªïng c·ªông 304,529 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 6,874 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 3,640 d√≤ng\nüìå File 46: Gi·ªØ 9,361 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,694 d√≤ng, t·ªïng c·ªông 139,527 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 10,417 d√≤ng, t·ªïng c·ªông 314,946 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,326 d√≤ng, t·ªïng c·ªông 101,771 d√≤ng\nüìå Nh√£n Web-based: Th√™m 249 d√≤ng, t·ªïng c·ªông 7,123 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 122 d√≤ng, t·ªïng c·ªông 3,762 d√≤ng\nüìå File 47: Gi·ªØ 18,808 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,656 d√≤ng, t·ªïng c·ªông 320,602 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,837 d√≤ng, t·ªïng c·ªông 103,608 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,431 d√≤ng, t·ªïng c·ªông 141,958 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 3,831 d√≤ng\nüìå Nh√£n Web-based: Th√™m 149 d√≤ng, t·ªïng c·ªông 7,272 d√≤ng\nüìå File 48: Gi·ªØ 10,142 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,779 d√≤ng, t·ªïng c·ªông 326,381 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,913 d√≤ng, t·ªïng c·ªông 105,521 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,497 d√≤ng, t·ªïng c·ªông 144,455 d√≤ng\nüìå Nh√£n Web-based: Th√™m 133 d√≤ng, t·ªïng c·ªông 7,405 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 3,896 d√≤ng\nüìå File 49: Gi·ªØ 10,387 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,874 d√≤ng, t·ªïng c·ªông 332,255 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,563 d√≤ng, t·ªïng c·ªông 147,018 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,759 d√≤ng, t·ªïng c·ªông 107,280 d√≤ng\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 7,540 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 3,950 d√≤ng\nüìå File 50: Gi·ªØ 10,385 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,325 d√≤ng, t·ªïng c·ªông 337,580 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,378 d√≤ng, t·ªïng c·ªông 149,396 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,714 d√≤ng, t·ªïng c·ªông 108,994 d√≤ng\nüìå Nh√£n Web-based: Th√™m 139 d√≤ng, t·ªïng c·ªông 7,679 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 45 d√≤ng, t·ªïng c·ªông 3,995 d√≤ng\nüìå File 51: Gi·ªØ 9,601 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,200 d√≤ng, t·ªïng c·ªông 342,780 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,259 d√≤ng, t·ªïng c·ªông 151,655 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,629 d√≤ng, t·ªïng c·ªông 110,623 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 4,052 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 7,801 d√≤ng\nüìå File 52: Gi·ªØ 9,267 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,708 d√≤ng, t·ªïng c·ªông 112,331 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,467 d√≤ng, t·ªïng c·ªông 154,122 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,395 d√≤ng, t·ªïng c·ªông 348,175 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 4,114 d√≤ng\nüìå Nh√£n Web-based: Th√™m 118 d√≤ng, t·ªïng c·ªông 7,919 d√≤ng\nüìå File 53: Gi·ªØ 9,750 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,311 d√≤ng, t·ªïng c·ªông 156,433 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,463 d√≤ng, t·ªïng c·ªông 353,638 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,742 d√≤ng, t·ªïng c·ªông 114,073 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 8,040 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 52 d√≤ng, t·ªïng c·ªông 4,166 d√≤ng\nüìå File 54: Gi·ªØ 9,689 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,559 d√≤ng, t·ªïng c·ªông 359,197 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,459 d√≤ng, t·ªïng c·ªông 158,892 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,746 d√≤ng, t·ªïng c·ªông 115,819 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 8,172 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 4,243 d√≤ng\nüìå File 55: Gi·ªØ 9,973 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,421 d√≤ng, t·ªïng c·ªông 161,313 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,529 d√≤ng, t·ªïng c·ªông 364,726 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,731 d√≤ng, t·ªïng c·ªông 117,550 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 8,293 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 4,312 d√≤ng\nüìå File 56: Gi·ªØ 9,871 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 5,213 d√≤ng, t·ªïng c·ªông 369,939 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,719 d√≤ng, t·ªïng c·ªông 119,269 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,324 d√≤ng, t·ªïng c·ªông 163,637 d√≤ng\nüìå Nh√£n Web-based: Th√™m 103 d√≤ng, t·ªïng c·ªông 8,396 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 4,377 d√≤ng\nüìå File 57: Gi·ªØ 9,424 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,612 d√≤ng, t·ªïng c·ªông 120,881 d√≤ng\nüìå Nh√£n BENIGN: Th√™m 5,186 d√≤ng, t·ªïng c·ªông 375,125 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,259 d√≤ng, t·ªïng c·ªông 165,896 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 8,511 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 50 d√≤ng, t·ªïng c·ªông 4,427 d√≤ng\nüìå File 58: Gi·ªØ 9,222 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 6,051 d√≤ng, t·ªïng c·ªông 381,176 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,935 d√≤ng, t·ªïng c·ªông 122,816 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,713 d√≤ng, t·ªïng c·ªông 168,609 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 48 d√≤ng, t·ªïng c·ªông 4,475 d√≤ng\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 8,641 d√≤ng\nüìå File 59: Gi·ªØ 10,877 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Recon: Th√™m 3,317 d√≤ng, t·ªïng c·ªông 126,133 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 10,568 d√≤ng, t·ªïng c·ªông 391,744 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,521 d√≤ng, t·ªïng c·ªông 173,130 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 120 d√≤ng, t·ªïng c·ªông 4,595 d√≤ng\nüìå Nh√£n Web-based: Th√™m 239 d√≤ng, t·ªïng c·ªông 8,880 d√≤ng\nüìå File 60: Gi·ªØ 18,765 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n BENIGN: Th√™m 5,430 d√≤ng, t·ªïng c·ªông 397,174 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,456 d√≤ng, t·ªïng c·ªông 175,586 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,823 d√≤ng, t·ªïng c·ªông 127,956 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 4,665 d√≤ng\nüìå Nh√£n Web-based: Th√™m 124 d√≤ng, t·ªïng c·ªông 9,004 d√≤ng\nüìå File 61: Gi·ªØ 9,903 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BENIGN: Th√™m 2,826 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,752 d√≤ng, t·ªïng c·ªông 129,708 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,372 d√≤ng, t·ªïng c·ªông 177,958 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 4,719 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 9,125 d√≤ng\nüìå File 62: Gi·ªØ 7,125 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,561 d√≤ng, t·ªïng c·ªông 180,519 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,858 d√≤ng, t·ªïng c·ªông 131,566 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 87 d√≤ng, t·ªïng c·ªông 4,806 d√≤ng\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 9,255 d√≤ng\nüìå File 63: Gi·ªØ 4,636 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,382 d√≤ng, t·ªïng c·ªông 182,901 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,753 d√≤ng, t·ªïng c·ªông 133,319 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 9,370 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 4,868 d√≤ng\nüìå File 64: Gi·ªØ 4,312 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,717 d√≤ng, t·ªïng c·ªông 185,618 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,948 d√≤ng, t·ªïng c·ªông 135,267 d√≤ng\nüìå Nh√£n Web-based: Th√™m 103 d√≤ng, t·ªïng c·ªông 9,473 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 4,932 d√≤ng\nüìå File 65: Gi·ªØ 4,832 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,798 d√≤ng, t·ªïng c·ªông 137,065 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,468 d√≤ng, t·ªïng c·ªông 188,086 d√≤ng\nüìå Nh√£n Web-based: Th√™m 151 d√≤ng, t·ªïng c·ªông 9,624 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 5,003 d√≤ng\nüìå File 66: Gi·ªØ 4,488 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,751 d√≤ng, t·ªïng c·ªông 138,816 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,375 d√≤ng, t·ªïng c·ªông 190,461 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 123 d√≤ng, t·ªïng c·ªông 9,747 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 75 d√≤ng, t·ªïng c·ªông 5,078 d√≤ng\nüìå File 67: Gi·ªØ 4,324 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,307 d√≤ng, t·ªïng c·ªông 192,768 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,730 d√≤ng, t·ªïng c·ªông 140,546 d√≤ng\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 9,875 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 53 d√≤ng, t·ªïng c·ªông 5,131 d√≤ng\nüìå File 68: Gi·ªØ 4,218 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,324 d√≤ng, t·ªïng c·ªông 195,092 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,732 d√≤ng, t·ªïng c·ªông 142,278 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 82 d√≤ng, t·ªïng c·ªông 5,213 d√≤ng\nüìå Nh√£n Web-based: Th√™m 115 d√≤ng, t·ªïng c·ªông 9,990 d√≤ng\nüìå File 69: Gi·ªØ 4,253 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,390 d√≤ng, t·ªïng c·ªông 197,482 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 5,275 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,762 d√≤ng, t·ªïng c·ªông 144,040 d√≤ng\nüìå Nh√£n Web-based: Th√™m 118 d√≤ng, t·ªïng c·ªông 10,108 d√≤ng\nüìå File 70: Gi·ªØ 4,332 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,690 d√≤ng, t·ªïng c·ªông 202,172 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,381 d√≤ng, t·ªïng c·ªông 147,421 d√≤ng\nüìå Nh√£n Web-based: Th√™m 261 d√≤ng, t·ªïng c·ªông 10,369 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 117 d√≤ng, t·ªïng c·ªông 5,392 d√≤ng\nüìå File 71: Gi·ªØ 8,449 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,495 d√≤ng, t·ªïng c·ªông 204,667 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,839 d√≤ng, t·ªïng c·ªông 149,260 d√≤ng\nüìå Nh√£n Web-based: Th√™m 129 d√≤ng, t·ªïng c·ªông 10,498 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 61 d√≤ng, t·ªïng c·ªông 5,453 d√≤ng\nüìå File 72: Gi·ªØ 4,524 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,677 d√≤ng, t·ªïng c·ªông 209,344 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,417 d√≤ng, t·ªïng c·ªông 152,677 d√≤ng\nüìå Nh√£n Web-based: Th√™m 239 d√≤ng, t·ªïng c·ªông 10,737 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 120 d√≤ng, t·ªïng c·ªông 5,573 d√≤ng\nüìå File 73: Gi·ªØ 8,453 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,692 d√≤ng, t·ªïng c·ªông 214,036 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,435 d√≤ng, t·ªïng c·ªông 156,112 d√≤ng\nüìå Nh√£n Web-based: Th√™m 232 d√≤ng, t·ªïng c·ªông 10,969 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 117 d√≤ng, t·ªïng c·ªông 5,690 d√≤ng\nüìå File 74: Gi·ªØ 8,476 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,740 d√≤ng, t·ªïng c·ªông 157,852 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,490 d√≤ng, t·ªïng c·ªông 216,526 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 11,106 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 61 d√≤ng, t·ªïng c·ªông 5,751 d√≤ng\nüìå File 75: Gi·ªØ 4,428 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,531 d√≤ng, t·ªïng c·ªông 219,057 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,773 d√≤ng, t·ªïng c·ªông 159,625 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 11,249 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 5,813 d√≤ng\nüìå File 76: Gi·ªØ 4,509 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,443 d√≤ng, t·ªïng c·ªông 221,500 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,796 d√≤ng, t·ªïng c·ªông 161,421 d√≤ng\nüìå Nh√£n Web-based: Th√™m 150 d√≤ng, t·ªïng c·ªông 11,399 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 5,878 d√≤ng\nüìå File 77: Gi·ªØ 4,454 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,550 d√≤ng, t·ªïng c·ªông 224,050 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,778 d√≤ng, t·ªïng c·ªông 163,199 d√≤ng\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 11,527 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 5,943 d√≤ng\nüìå File 78: Gi·ªØ 4,521 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,752 d√≤ng, t·ªïng c·ªông 164,951 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,383 d√≤ng, t·ªïng c·ªông 226,433 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 76 d√≤ng, t·ªïng c·ªông 6,019 d√≤ng\nüìå Nh√£n Web-based: Th√™m 136 d√≤ng, t·ªïng c·ªông 11,663 d√≤ng\nüìå File 79: Gi·ªØ 4,347 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,421 d√≤ng, t·ªïng c·ªông 228,854 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,821 d√≤ng, t·ªïng c·ªông 166,772 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 59 d√≤ng, t·ªïng c·ªông 6,078 d√≤ng\nüìå Nh√£n Web-based: Th√™m 105 d√≤ng, t·ªïng c·ªông 11,768 d√≤ng\nüìå File 80: Gi·ªØ 4,406 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,333 d√≤ng, t·ªïng c·ªông 231,187 d√≤ng\nüìå Nh√£n Web-based: Th√™m 114 d√≤ng, t·ªïng c·ªông 11,882 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,745 d√≤ng, t·ªïng c·ªông 168,517 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 6,132 d√≤ng\nüìå File 81: Gi·ªØ 4,246 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,285 d√≤ng, t·ªïng c·ªông 233,472 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,661 d√≤ng, t·ªïng c·ªông 170,178 d√≤ng\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 11,995 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 6,200 d√≤ng\nüìå File 82: Gi·ªØ 4,127 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,406 d√≤ng, t·ªïng c·ªông 235,878 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,729 d√≤ng, t·ªïng c·ªông 171,907 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 12,112 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 88 d√≤ng, t·ªïng c·ªông 6,288 d√≤ng\nüìå File 83: Gi·ªØ 4,340 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,746 d√≤ng, t·ªïng c·ªông 240,624 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,458 d√≤ng, t·ªïng c·ªông 175,365 d√≤ng\nüìå Nh√£n Web-based: Th√™m 269 d√≤ng, t·ªïng c·ªông 12,381 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 141 d√≤ng, t·ªïng c·ªông 6,429 d√≤ng\nüìå File 84: Gi·ªØ 8,614 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,534 d√≤ng, t·ªïng c·ªông 243,158 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,823 d√≤ng, t·ªïng c·ªông 177,188 d√≤ng\nüìå Nh√£n Web-based: Th√™m 146 d√≤ng, t·ªïng c·ªông 12,527 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 6,499 d√≤ng\nüìå File 85: Gi·ªØ 4,573 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,860 d√≤ng, t·ªïng c·ªông 179,048 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,444 d√≤ng, t·ªïng c·ªông 245,602 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 12,662 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 6,556 d√≤ng\nüìå File 86: Gi·ªØ 4,496 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,906 d√≤ng, t·ªïng c·ªông 180,954 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,585 d√≤ng, t·ªïng c·ªông 248,187 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 12,797 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 60 d√≤ng, t·ªïng c·ªông 6,616 d√≤ng\nüìå File 87: Gi·ªØ 4,686 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,529 d√≤ng, t·ªïng c·ªông 184,483 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,713 d√≤ng, t·ªïng c·ªông 252,900 d√≤ng\nüìå Nh√£n Web-based: Th√™m 244 d√≤ng, t·ªïng c·ªông 13,041 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 135 d√≤ng, t·ªïng c·ªông 6,751 d√≤ng\nüìå File 88: Gi·ªØ 8,621 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,864 d√≤ng, t·ªïng c·ªông 186,347 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,685 d√≤ng, t·ªïng c·ªông 255,585 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 6,822 d√≤ng\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 13,176 d√≤ng\nüìå File 89: Gi·ªØ 4,755 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,436 d√≤ng, t·ªïng c·ªông 189,783 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,561 d√≤ng, t·ªïng c·ªông 260,146 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 125 d√≤ng, t·ªïng c·ªông 6,947 d√≤ng\nüìå Nh√£n Web-based: Th√™m 227 d√≤ng, t·ªïng c·ªông 13,403 d√≤ng\nüìå File 90: Gi·ªØ 8,349 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 7,013 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,695 d√≤ng, t·ªïng c·ªông 191,478 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,277 d√≤ng, t·ªïng c·ªông 262,423 d√≤ng\nüìå Nh√£n Web-based: Th√™m 108 d√≤ng, t·ªïng c·ªông 13,511 d√≤ng\nüìå File 91: Gi·ªØ 4,146 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,652 d√≤ng, t·ªïng c·ªông 265,075 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 7,091 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,873 d√≤ng, t·ªïng c·ªông 193,351 d√≤ng\nüìå Nh√£n Web-based: Th√™m 120 d√≤ng, t·ªïng c·ªông 13,631 d√≤ng\nüìå File 92: Gi·ªØ 4,723 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,508 d√≤ng, t·ªïng c·ªông 267,583 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,883 d√≤ng, t·ªïng c·ªông 195,234 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 13,763 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 7,165 d√≤ng\nüìå File 93: Gi·ªØ 4,597 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 13,884 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,440 d√≤ng, t·ªïng c·ªông 270,023 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,682 d√≤ng, t·ªïng c·ªông 196,916 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 7,234 d√≤ng\nüìå File 94: Gi·ªØ 4,312 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,543 d√≤ng, t·ªïng c·ªông 200,459 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,630 d√≤ng, t·ªïng c·ªông 274,653 d√≤ng\nüìå Nh√£n Web-based: Th√™m 249 d√≤ng, t·ªïng c·ªông 14,133 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 129 d√≤ng, t·ªïng c·ªông 7,363 d√≤ng\nüìå File 95: Gi·ªØ 8,551 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,287 d√≤ng, t·ªïng c·ªông 203,746 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,659 d√≤ng, t·ªïng c·ªông 279,312 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 104 d√≤ng, t·ªïng c·ªông 7,467 d√≤ng\nüìå Nh√£n Web-based: Th√™m 219 d√≤ng, t·ªïng c·ªông 14,352 d√≤ng\nüìå File 96: Gi·ªØ 8,269 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,779 d√≤ng, t·ªïng c·ªông 205,525 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,350 d√≤ng, t·ªïng c·ªông 281,662 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 7,540 d√≤ng\nüìå Nh√£n Web-based: Th√™m 127 d√≤ng, t·ªïng c·ªông 14,479 d√≤ng\nüìå File 97: Gi·ªØ 4,329 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 14,609 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,522 d√≤ng, t·ªïng c·ªông 284,184 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,693 d√≤ng, t·ªïng c·ªông 207,218 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 7,594 d√≤ng\nüìå File 98: Gi·ªØ 4,399 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,668 d√≤ng, t·ªïng c·ªông 286,852 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,917 d√≤ng, t·ªïng c·ªông 209,135 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 64 d√≤ng, t·ªïng c·ªông 7,658 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 14,749 d√≤ng\nüìå File 99: Gi·ªØ 4,789 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,397 d√≤ng, t·ªïng c·ªông 289,249 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,792 d√≤ng, t·ªïng c·ªông 210,927 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 128 d√≤ng, t·ªïng c·ªông 14,877 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 52 d√≤ng, t·ªïng c·ªông 7,710 d√≤ng\nüìå File 100: Gi·ªØ 4,369 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,398 d√≤ng, t·ªïng c·ªông 291,647 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 14,999 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,707 d√≤ng, t·ªïng c·ªông 212,634 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 57 d√≤ng, t·ªïng c·ªông 7,767 d√≤ng\nüìå File 101: Gi·ªØ 4,284 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,539 d√≤ng, t·ªïng c·ªông 294,186 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,860 d√≤ng, t·ªïng c·ªông 214,494 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 15,136 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 7,830 d√≤ng\nüìå File 102: Gi·ªØ 4,599 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,918 d√≤ng, t·ªïng c·ªông 216,412 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,486 d√≤ng, t·ªïng c·ªông 296,672 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 15,262 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 80 d√≤ng, t·ªïng c·ªông 7,910 d√≤ng\nüìå File 103: Gi·ªØ 4,610 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,645 d√≤ng, t·ªïng c·ªông 301,317 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,325 d√≤ng, t·ªïng c·ªông 219,737 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 131 d√≤ng, t·ªïng c·ªông 8,041 d√≤ng\nüìå Nh√£n Web-based: Th√™m 263 d√≤ng, t·ªïng c·ªông 15,525 d√≤ng\nüìå File 104: Gi·ªØ 8,364 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,757 d√≤ng, t·ªïng c·ªông 304,074 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,007 d√≤ng, t·ªïng c·ªông 221,744 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 8,114 d√≤ng\nüìå Nh√£n Web-based: Th√™m 146 d√≤ng, t·ªïng c·ªông 15,671 d√≤ng\nüìå File 105: Gi·ªØ 4,983 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,773 d√≤ng, t·ªïng c·ªông 223,517 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,488 d√≤ng, t·ªïng c·ªông 306,562 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 125 d√≤ng, t·ªïng c·ªông 15,796 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 58 d√≤ng, t·ªïng c·ªông 8,172 d√≤ng\nüìå File 106: Gi·ªØ 4,444 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,740 d√≤ng, t·ªïng c·ªông 225,257 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,393 d√≤ng, t·ªïng c·ªông 308,955 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 8,226 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 15,928 d√≤ng\nüìå File 107: Gi·ªØ 4,319 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,796 d√≤ng, t·ªïng c·ªông 311,751 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,034 d√≤ng, t·ªïng c·ªông 227,291 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 16,071 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 8,299 d√≤ng\nüìå File 108: Gi·ªØ 5,046 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,880 d√≤ng, t·ªïng c·ªông 229,171 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,614 d√≤ng, t·ªïng c·ªông 314,365 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 16,193 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 8,367 d√≤ng\nüìå File 109: Gi·ªØ 4,684 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,586 d√≤ng, t·ªïng c·ªông 316,951 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,899 d√≤ng, t·ªïng c·ªông 231,070 d√≤ng\nüìå Nh√£n Web-based: Th√™m 131 d√≤ng, t·ªïng c·ªông 16,324 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 8,438 d√≤ng\nüìå File 110: Gi·ªØ 4,687 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,563 d√≤ng, t·ªïng c·ªông 319,514 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,837 d√≤ng, t·ªïng c·ªông 232,907 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 8,515 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 16,450 d√≤ng\nüìå File 111: Gi·ªØ 4,603 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,422 d√≤ng, t·ªïng c·ªông 321,936 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,851 d√≤ng, t·ªïng c·ªông 234,758 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 56 d√≤ng, t·ªïng c·ªông 8,571 d√≤ng\nüìå Nh√£n Web-based: Th√™m 109 d√≤ng, t·ªïng c·ªông 16,559 d√≤ng\nüìå File 112: Gi·ªØ 4,438 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,782 d√≤ng, t·ªïng c·ªông 236,540 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,476 d√≤ng, t·ªïng c·ªông 324,412 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 8,639 d√≤ng\nüìå Nh√£n Web-based: Th√™m 124 d√≤ng, t·ªïng c·ªông 16,683 d√≤ng\nüìå File 113: Gi·ªØ 4,450 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Spoofing: Th√™m 2,639 d√≤ng, t·ªïng c·ªông 327,051 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,849 d√≤ng, t·ªïng c·ªông 238,389 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 8,706 d√≤ng\nüìå Nh√£n Web-based: Th√™m 136 d√≤ng, t·ªïng c·ªông 16,819 d√≤ng\nüìå File 114: Gi·ªØ 4,691 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,513 d√≤ng, t·ªïng c·ªông 329,564 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,895 d√≤ng, t·ªïng c·ªông 240,284 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 8,774 d√≤ng\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 16,935 d√≤ng\nüìå File 115: Gi·ªØ 4,592 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,696 d√≤ng, t·ªïng c·ªông 241,980 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,259 d√≤ng, t·ªïng c·ªông 331,823 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 17,065 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 65 d√≤ng, t·ªïng c·ªông 8,839 d√≤ng\nüìå File 116: Gi·ªØ 4,150 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,703 d√≤ng, t·ªïng c·ªông 336,526 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,340 d√≤ng, t·ªïng c·ªông 245,320 d√≤ng\nüìå Nh√£n Web-based: Th√™m 231 d√≤ng, t·ªïng c·ªông 17,296 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 113 d√≤ng, t·ªïng c·ªông 8,952 d√≤ng\nüìå File 117: Gi·ªØ 8,387 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,027 d√≤ng, t·ªïng c·ªông 247,347 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,644 d√≤ng, t·ªïng c·ªông 339,170 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 17,428 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 87 d√≤ng, t·ªïng c·ªông 9,039 d√≤ng\nüìå File 118: Gi·ªØ 4,890 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,936 d√≤ng, t·ªïng c·ªông 249,283 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,500 d√≤ng, t·ªïng c·ªông 341,670 d√≤ng\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 17,541 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 9,117 d√≤ng\nüìå File 119: Gi·ªØ 4,627 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,810 d√≤ng, t·ªïng c·ªông 251,093 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,365 d√≤ng, t·ªïng c·ªông 344,035 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 17,654 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 9,183 d√≤ng\nüìå File 120: Gi·ªØ 4,354 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,600 d√≤ng, t·ªïng c·ªông 346,635 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,914 d√≤ng, t·ªïng c·ªông 253,007 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 9,237 d√≤ng\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 17,789 d√≤ng\nüìå File 121: Gi·ªØ 4,703 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,692 d√≤ng, t·ªïng c·ªông 349,327 d√≤ng\nüìå Nh√£n Recon: Th√™m 2,038 d√≤ng, t·ªïng c·ªông 255,045 d√≤ng\nüìå Nh√£n Web-based: Th√™m 140 d√≤ng, t·ªïng c·ªông 17,929 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 9,306 d√≤ng\nüìå File 122: Gi·ªØ 4,939 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,538 d√≤ng, t·ªïng c·ªông 351,865 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,961 d√≤ng, t·ªïng c·ªông 257,006 d√≤ng\nüìå Nh√£n Web-based: Th√™m 134 d√≤ng, t·ªïng c·ªông 18,063 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 9,368 d√≤ng\nüìå File 123: Gi·ªØ 4,695 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,893 d√≤ng, t·ªïng c·ªông 258,899 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,524 d√≤ng, t·ªïng c·ªông 354,389 d√≤ng\nüìå Nh√£n Web-based: Th√™m 141 d√≤ng, t·ªïng c·ªông 18,204 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 77 d√≤ng, t·ªïng c·ªông 9,445 d√≤ng\nüìå File 124: Gi·ªØ 4,635 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,510 d√≤ng, t·ªïng c·ªông 262,409 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,601 d√≤ng, t·ªïng c·ªông 358,990 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 129 d√≤ng, t·ªïng c·ªông 9,574 d√≤ng\nüìå Nh√£n Web-based: Th√™m 220 d√≤ng, t·ªïng c·ªông 18,424 d√≤ng\nüìå File 125: Gi·ªØ 8,460 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,939 d√≤ng, t·ªïng c·ªông 264,348 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,613 d√≤ng, t·ªïng c·ªông 361,603 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 9,640 d√≤ng\nüìå Nh√£n Web-based: Th√™m 127 d√≤ng, t·ªïng c·ªông 18,551 d√≤ng\nüìå File 126: Gi·ªØ 4,745 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,484 d√≤ng, t·ªïng c·ªông 364,087 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,808 d√≤ng, t·ªïng c·ªông 266,156 d√≤ng\nüìå Nh√£n Web-based: Th√™m 126 d√≤ng, t·ªïng c·ªông 18,677 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 75 d√≤ng, t·ªïng c·ªông 9,715 d√≤ng\nüìå File 127: Gi·ªØ 4,493 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,495 d√≤ng, t·ªïng c·ªông 366,582 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,669 d√≤ng, t·ªïng c·ªông 267,825 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 18,799 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 9,784 d√≤ng\nüìå File 128: Gi·ªØ 4,355 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,590 d√≤ng, t·ªïng c·ªông 371,172 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,292 d√≤ng, t·ªïng c·ªông 271,117 d√≤ng\nüìå Nh√£n Web-based: Th√™m 255 d√≤ng, t·ªïng c·ªông 19,054 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 120 d√≤ng, t·ªïng c·ªông 9,904 d√≤ng\nüìå File 129: Gi·ªØ 8,257 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,630 d√≤ng, t·ªïng c·ªông 373,802 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,906 d√≤ng, t·ªïng c·ªông 273,023 d√≤ng\nüìå Nh√£n Web-based: Th√™m 142 d√≤ng, t·ªïng c·ªông 19,196 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 9,976 d√≤ng\nüìå File 130: Gi·ªØ 4,750 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,630 d√≤ng, t·ªïng c·ªông 376,432 d√≤ng\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,966 d√≤ng, t·ªïng c·ªông 274,989 d√≤ng\nüìå Nh√£n Web-based: Th√™m 132 d√≤ng, t·ªïng c·ªông 19,328 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 10,050 d√≤ng\nüìå File 131: Gi·ªØ 4,802 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\nüìå Nh√£n Recon: Th√™m 1,733 d√≤ng, t·ªïng c·ªông 276,722 d√≤ng\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,433 d√≤ng, t·ªïng c·ªông 378,865 d√≤ng\nüìå Nh√£n Web-based: Th√™m 130 d√≤ng, t·ªïng c·ªông 19,458 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 72 d√≤ng, t·ªïng c·ªông 10,122 d√≤ng\nüìå File 132: Gi·ªØ 4,368 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,372 d√≤ng, t·ªïng c·ªông 280,094 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 4,655 d√≤ng, t·ªïng c·ªông 383,520 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 128 d√≤ng, t·ªïng c·ªông 10,250 d√≤ng\nüìå Nh√£n Web-based: Th√™m 251 d√≤ng, t·ªïng c·ªông 19,709 d√≤ng\nüìå File 133: Gi·ªØ 8,406 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,640 d√≤ng, t·ªïng c·ªông 386,160 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,940 d√≤ng, t·ªïng c·ªông 282,034 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 73 d√≤ng, t·ªïng c·ªông 10,323 d√≤ng\nüìå Nh√£n Web-based: Th√™m 169 d√≤ng, t·ªïng c·ªông 19,878 d√≤ng\nüìå File 134: Gi·ªØ 4,822 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 2,414 d√≤ng, t·ªïng c·ªông 388,574 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,781 d√≤ng, t·ªïng c·ªông 283,815 d√≤ng\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 19,994 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 68 d√≤ng, t·ªïng c·ªông 10,391 d√≤ng\nüìå File 135: Gi·ªØ 4,379 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,050 d√≤ng, t·ªïng c·ªông 285,865 d√≤ng\nüìå Nh√£n Spoofing: Th√™m 2,710 d√≤ng, t·ªïng c·ªông 391,284 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 20,129 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 10,462 d√≤ng\nüìå File 136: Gi·ªØ 4,966 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 4,717 d√≤ng, t·ªïng c·ªông 396,001 d√≤ng\nüìå Nh√£n Recon: Th√™m 3,274 d√≤ng, t·ªïng c·ªông 289,139 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 231 d√≤ng, t·ªïng c·ªông 20,360 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 126 d√≤ng, t·ªïng c·ªông 10,588 d√≤ng\nüìå File 137: Gi·ªØ 8,348 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Spoofing: Th√™m 3,999 d√≤ng, t·ªïng c·ªông 400,000 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,294 d√≤ng, t·ªïng c·ªông 292,433 d√≤ng\nüìå Nh√£n Web-based: Th√™m 195 d√≤ng, t·ªïng c·ªông 20,555 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 128 d√≤ng, t·ªïng c·ªông 10,716 d√≤ng\nüìå File 138: Gi·ªØ 7,616 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,877 d√≤ng, t·ªïng c·ªông 294,310 d√≤ng\nüìå Nh√£n Web-based: Th√™m 124 d√≤ng, t·ªïng c·ªông 20,679 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 74 d√≤ng, t·ªïng c·ªông 10,790 d√≤ng\nüìå File 139: Gi·ªØ 2,075 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 10,859 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,790 d√≤ng, t·ªïng c·ªông 296,100 d√≤ng\nüìå Nh√£n Web-based: Th√™m 136 d√≤ng, t·ªïng c·ªông 20,815 d√≤ng\nüìå File 140: Gi·ªØ 1,995 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,750 d√≤ng, t·ªïng c·ªông 297,850 d√≤ng\nüìå Nh√£n Web-based: Th√™m 95 d√≤ng, t·ªïng c·ªông 20,910 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 54 d√≤ng, t·ªïng c·ªông 10,913 d√≤ng\nüìå File 141: Gi·ªØ 1,899 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,774 d√≤ng, t·ªïng c·ªông 299,624 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 125 d√≤ng, t·ªïng c·ªông 21,035 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 10,975 d√≤ng\nüìå File 142: Gi·ªØ 1,961 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,833 d√≤ng, t·ªïng c·ªông 301,457 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 67 d√≤ng, t·ªïng c·ªông 11,042 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 21,156 d√≤ng\nüìå File 143: Gi·ªØ 2,021 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,808 d√≤ng, t·ªïng c·ªông 303,265 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 11,105 d√≤ng\nüìå Nh√£n Web-based: Th√™m 121 d√≤ng, t·ªïng c·ªông 21,277 d√≤ng\nüìå File 144: Gi·ªØ 1,992 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,884 d√≤ng, t·ªïng c·ªông 305,149 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 94 d√≤ng, t·ªïng c·ªông 11,199 d√≤ng\nüìå Nh√£n Web-based: Th√™m 122 d√≤ng, t·ªïng c·ªông 21,399 d√≤ng\nüìå File 145: Gi·ªØ 2,100 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,696 d√≤ng, t·ªïng c·ªông 306,845 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 113 d√≤ng, t·ªïng c·ªông 21,512 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 11,265 d√≤ng\nüìå File 146: Gi·ªØ 1,875 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,807 d√≤ng, t·ªïng c·ªông 308,652 d√≤ng\nüìå Nh√£n Web-based: Th√™m 131 d√≤ng, t·ªïng c·ªông 21,643 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 71 d√≤ng, t·ªïng c·ªông 11,336 d√≤ng\nüìå File 147: Gi·ªØ 2,009 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,410 d√≤ng, t·ªïng c·ªông 312,062 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 221 d√≤ng, t·ªïng c·ªông 21,864 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 106 d√≤ng, t·ªïng c·ªông 11,442 d√≤ng\nüìå File 148: Gi·ªØ 3,737 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,025 d√≤ng, t·ªïng c·ªông 314,087 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 75 d√≤ng, t·ªïng c·ªông 11,517 d√≤ng\nüìå Nh√£n Web-based: Th√™m 143 d√≤ng, t·ªïng c·ªông 22,007 d√≤ng\nüìå File 149: Gi·ªØ 2,243 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 109 d√≤ng, t·ªïng c·ªông 22,116 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,789 d√≤ng, t·ªïng c·ªông 315,876 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 11,580 d√≤ng\nüìå File 150: Gi·ªØ 1,961 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 66 d√≤ng, t·ªïng c·ªông 11,646 d√≤ng\nüìå Nh√£n Recon: Th√™m 1,775 d√≤ng, t·ªïng c·ªông 317,651 d√≤ng\nüìå Nh√£n Web-based: Th√™m 141 d√≤ng, t·ªïng c·ªông 22,257 d√≤ng\nüìå File 151: Gi·ªØ 1,982 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,374 d√≤ng, t·ªïng c·ªông 321,025 d√≤ng\nüìå Nh√£n Web-based: Th√™m 243 d√≤ng, t·ªïng c·ªông 22,500 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 151 d√≤ng, t·ªïng c·ªông 11,797 d√≤ng\nüìå File 152: Gi·ªØ 3,768 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,285 d√≤ng, t·ªïng c·ªông 324,310 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 227 d√≤ng, t·ªïng c·ªông 22,727 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 111 d√≤ng, t·ªïng c·ªông 11,908 d√≤ng\nüìå File 153: Gi·ªØ 3,623 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,859 d√≤ng, t·ªïng c·ªông 326,169 d√≤ng\nüìå Nh√£n Web-based: Th√™m 137 d√≤ng, t·ªïng c·ªông 22,864 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 63 d√≤ng, t·ªïng c·ªông 11,971 d√≤ng\nüìå File 154: Gi·ªØ 2,059 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,671 d√≤ng, t·ªïng c·ªông 327,840 d√≤ng\nüìå Nh√£n Web-based: Th√™m 117 d√≤ng, t·ªïng c·ªông 22,981 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 58 d√≤ng, t·ªïng c·ªông 12,029 d√≤ng\nüìå File 155: Gi·ªØ 1,846 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,947 d√≤ng, t·ªïng c·ªông 329,787 d√≤ng\nüìå Nh√£n Web-based: Th√™m 134 d√≤ng, t·ªïng c·ªông 23,115 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 91 d√≤ng, t·ªïng c·ªông 12,120 d√≤ng\nüìå File 156: Gi·ªØ 2,172 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,659 d√≤ng, t·ªïng c·ªông 331,446 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 23,231 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 79 d√≤ng, t·ªïng c·ªông 12,199 d√≤ng\nüìå File 157: Gi·ªØ 1,854 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,906 d√≤ng, t·ªïng c·ªông 333,352 d√≤ng\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 135 d√≤ng, t·ªïng c·ªông 23,366 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 78 d√≤ng, t·ªïng c·ªông 12,277 d√≤ng\nüìå File 158: Gi·ªØ 2,119 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,623 d√≤ng, t·ªïng c·ªông 334,975 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 105 d√≤ng, t·ªïng c·ªông 23,471 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 61 d√≤ng, t·ªïng c·ªông 12,338 d√≤ng\nüìå File 159: Gi·ªØ 1,789 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,007 d√≤ng, t·ªïng c·ªông 336,982 d√≤ng\nüìå Nh√£n Web-based: Th√™m 152 d√≤ng, t·ªïng c·ªông 23,623 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 12,407 d√≤ng\nüìå File 160: Gi·ªØ 2,228 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,369 d√≤ng, t·ªïng c·ªông 340,351 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 124 d√≤ng, t·ªïng c·ªông 12,531 d√≤ng\nüìå Nh√£n Web-based: Th√™m 261 d√≤ng, t·ªïng c·ªông 23,884 d√≤ng\nüìå File 161: Gi·ªØ 3,754 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,725 d√≤ng, t·ªïng c·ªông 342,076 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 100 d√≤ng, t·ªïng c·ªông 23,984 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 70 d√≤ng, t·ªïng c·ªông 12,601 d√≤ng\nüìå File 162: Gi·ªØ 1,895 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 2,033 d√≤ng, t·ªïng c·ªông 344,109 d√≤ng\nüìå Nh√£n Web-based: Th√™m 124 d√≤ng, t·ªïng c·ªông 24,108 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 84 d√≤ng, t·ªïng c·ªông 12,685 d√≤ng\nüìå File 163: Gi·ªØ 2,241 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,838 d√≤ng, t·ªïng c·ªông 345,947 d√≤ng\nüìå Nh√£n Web-based: Th√™m 114 d√≤ng, t·ªïng c·ªông 24,222 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 69 d√≤ng, t·ªïng c·ªông 12,754 d√≤ng\nüìå File 164: Gi·ªØ 2,021 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,800 d√≤ng, t·ªïng c·ªông 347,747 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 55 d√≤ng, t·ªïng c·ªông 12,809 d√≤ng\nüìå Nh√£n Web-based: Th√™m 111 d√≤ng, t·ªïng c·ªông 24,333 d√≤ng\nüìå File 165: Gi·ªØ 1,966 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 1,789 d√≤ng, t·ªïng c·ªông 349,536 d√≤ng\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n BruteForce: Th√™m 62 d√≤ng, t·ªïng c·ªông 12,871 d√≤ng\nüìå Nh√£n Web-based: Th√™m 116 d√≤ng, t·ªïng c·ªông 24,449 d√≤ng\nüìå File 166: Gi·ªØ 1,967 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚ö† Nh√£n DoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n DDoS ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Mirai ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\n‚ö† Nh√£n Spoofing ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Recon: Th√™m 3,260 d√≤ng, t·ªïng c·ªông 352,796 d√≤ng\n‚ö† Nh√£n BENIGN ƒë√£ ƒë·ªß 400,000 d√≤ng, kh√¥ng ƒë·ªçc th√™m!\nüìå Nh√£n Web-based: Th√™m 235 d√≤ng, t·ªïng c·ªông 24,684 d√≤ng\nüìå Nh√£n BruteForce: Th√™m 133 d√≤ng, t·ªïng c·ªông 13,004 d√≤ng\nüìå File 167: Gi·ªØ 3,628 d√≤ng sau khi l·ªçc gi·ªõi h·∫°n\n‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi! K√≠ch th∆∞·ªõc: (2390484, 47)\nüìã Nh√£n duy nh·∫•t: ['Mirai', 'DDoS', 'Spoofing', 'BENIGN', 'DoS', 'Recon', 'BruteForce', 'Web-based']\n\nüìã Ph√¢n b·ªë nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng:\nlabel\nMirai         400000\nDDoS          400000\nSpoofing      400000\nBENIGN        400000\nDoS           400000\nRecon         352796\nWeb-based      24684\nBruteForce     13004\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACvhklEQVR4nOzdeVhV1eL/8c8RBFQ8IBogDjgmYg6lpZiaCYFTZVpOOF7SBuimlhllTrebpZmWmV7vLfWWXk0zU3PCuZRMyZGU0jQzBafgOKQi7N8f/dhfj4A5sQ/B+/U853k8a6+91jp7sY/yce+1bYZhGAIAAAAAAAAsVMLVAwAAAAAAAEDxQygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAMCfGDVqlGw2myV9tW7dWq1btzbfr1+/XjabTQsWLLCk/379+qlatWqW9HWzzp49qyeffFKBgYGy2WwaNGiQq4d0XapVq6aOHTve1jZtNptGjRp129obN26cQkJClJ2dfdvazM/WrVvVvHlzlSlTRjabTTt27CjwPuEaV3+vHTp0SDabTTNnzizQfl9++WU1bdq0QPsAANwaQikAQLEyc+ZM2Ww28+Xl5aWgoCBFRUXpvffe05kzZ25LP0ePHtWoUaMK5S/ahXls1+ONN97QzJkz9cwzz+jjjz9W7969862bnZ2tadOmqVGjRvL29lZAQIDatWunzZs3/2k/Ob84v/3227dz+IWWw+HQW2+9pWHDhqlEif/7J+KV54vNZlOZMmUUGhqq119/XefPn7+pvjIzM/XEE0/o9OnTmjhxoj7++GMFBwffro9yy5KTk9WrVy9VqlRJnp6eCgoKUnR0tJKTk109NNyAQYMGaefOnVq8eLGrhwIAyIe7qwcAAIArjBkzRtWrV1dmZqZSU1O1fv16DRo0SO+8844WL16sBg0amHWHDx+ul19++YbaP3r0qEaPHq1q1aqpUaNG173fqlWrbqifm3Gtsf373/+25CqZW7F27Vo1a9ZMI0eO/NO6Q4cO1TvvvKNevXrp2WefVXp6uv71r3/pgQce0KZNm3TfffdZMOK/ho8++kiXL19Wjx49cm176KGH1KdPH0l/XKn21Vdf6bXXXtPOnTs1f/78G+7rwIED+vnnn/Xvf/9bTz755C2P/XZauHChevToIT8/P8XExKh69eo6dOiQPvzwQy1YsEBz587VY4895uph/qUFBwfr999/V8mSJQu0n8DAQD366KN6++239cgjjxRoXwCAm0MoBQAoltq1a6cmTZqY7+Pj47V27Vp17NhRjzzyiPbu3atSpUpJktzd3eXuXrB/ZZ4/f16lS5eWh4dHgfbzZwr6l8Tb4fjx4woNDf3TepcvX9bUqVP1+OOP6+OPPzbLn3jiCdWoUUOzZ88mlLrCjBkz9Mgjj8jLyyvXtjvvvFO9evUy3z/99NO6dOmSFi5cqAsXLuS5z7UcP35ckuTr63tLY77SuXPnVKZMmVtq48CBA+rdu7dq1KihjRs36o477jC3Pf/882rZsqV69+6tXbt2qUaNGrc65Ot2Oz5bYZJzlaoVunbtqieeeEI//fSTpXMGALg+3L4HAMD/16ZNG7322mv6+eef9cknn5jlea0plZCQoBYtWsjX11fe3t6qU6eOXnnlFUl/rAN17733SpL69+9v3vaUs35K69atdddddykpKUmtWrVS6dKlzX2vXnslR1ZWll555RUFBgaqTJkyeuSRR/TLL7841alWrZr69euXa98r2/yzseW1ptS5c+f0wgsvqEqVKvL09FSdOnX09ttvyzAMp3o2m01xcXFatGiR7rrrLnl6eqpevXpasWJF3gf8KsePH1dMTIwCAgLk5eWlhg0batasWeb2nPW1Dh48qC+//NIc+6FDh/JsLzMzU7///rsCAgKcyv39/VWiRAkzdLxVM2bMUJs2beTv7y9PT0+FhoZq6tSp+dZftWqVGjVqJC8vL4WGhmrhwoW56qSnp2vQoEHmMa9Vq5beeuutP72K7cyZMxo0aJCqVasmT09P+fv766GHHtJ33313zf0OHjyoXbt2KSIi4vo+tGSu6XV1YLtlyxa1bdtWPj4+Kl26tHlVWo5+/frpgQcekPRHQGiz2Zx+5teuXauWLVuqTJky8vX11aOPPqq9e/c69ZFzTn7//ffq2bOnypUrpxYtWpjbP/nkEzVu3FilSpWSn5+funfvnut8ycv48eN1/vx5TZ8+3SmQkqQKFSroX//6l86dO6dx48ZJkhYsWCCbzaYNGzbkautf//qXbDab9uzZY5bt27dPjz/+uPz8/OTl5aUmTZrkurUs5xbjDRs26Nlnn5W/v78qV64s6frm96uvvtITTzyhqlWrytPTU1WqVNHgwYP1+++/O/XTr18/eXt76/Dhw+rYsaO8vb1VqVIlTZkyRZK0e/dutWnTRmXKlFFwcLDmzJmT5zg3btyop556SuXLl5fdblefPn3022+/XfM457WmVM54fv31V3Xq1Ene3t6644479OKLLyorK8tp/1OnTql3796y2+3y9fVV3759tXPnzjzXqcr5mf7iiy+uOSYAgGtwpRQAAFfo3bu3XnnlFa1atUoDBgzIs05ycrI6duyoBg0aaMyYMfL09NT+/fvNX7zr1q2rMWPGaMSIERo4cKBatmwpSWrevLnZxqlTp9SuXTt1795dvXr1yhWcXO2f//ynbDabhg0bpuPHj2vSpEmKiIjQjh07bihcuZ6xXckwDD3yyCNat26dYmJi1KhRI61cuVJDhw7Vr7/+qokTJzrV//rrr7Vw4UI9++yzKlu2rN577z116dJFhw8fVvny5fMd1++//67WrVtr//79iouLU/Xq1TV//nz169dP6enpev7551W3bl19/PHHGjx4sCpXrqwXXnhBknKFBzlKlSqlpk2baubMmQoLC1PLli2Vnp6uf/zjHypXrpwGDhx43cftWqZOnap69erpkUcekbu7u5YsWaJnn31W2dnZio2Ndar7448/qlu3bnr66afVt29fzZgxQ0888YRWrFihhx56SNIfV8098MAD+vXXX/XUU0+patWq2rx5s+Lj43Xs2DFNmjQp37E8/fTTWrBggeLi4hQaGqpTp07p66+/1t69e3XPPffku1/OGlv51blw4YJOnjwp6Y+QctOmTZo1a5Z69uzpFEqtXbtW7dq1U+PGjTVy5EiVKFHCDO2++uor3XfffXrqqadUqVIlvfHGG/r73/+ue++91/z5X716tdq1a6caNWpo1KhR+v333zV58mTdf//9+u6773IFpk888YRq166tN954wwxJ//nPf+q1115T165d9eSTT+rEiROaPHmyWrVqpe3bt1/z6qwlS5aoWrVq5nlxtVatWqlatWr68ssvJUkdOnSQt7e3Pv30UzNoyzFv3jzVq1dPd911l6Q/vjfuv/9+VapUSS+//LLKlCmjTz/9VJ06ddJnn32W65bAZ599VnfccYdGjBihc+fOSbq++Z0/f77Onz+vZ555RuXLl9e3336ryZMn68iRI7lutczKylK7du3UqlUrjRs3TrNnz1ZcXJzKlCmjV199VdHR0ercubOmTZumPn36KCwsTNWrV3dqIy4uTr6+vho1apRSUlI0depU/fzzz2aIfCOysrIUFRWlpk2b6u2339bq1as1YcIE1axZU88884ykP9aJe/jhh/Xtt9/qmWeeUUhIiL744gv17ds3zzZ9fHxUs2ZNbdq0SYMHD76h8QAALGAAAFCMzJgxw5BkbN26Nd86Pj4+xt13322+HzlypHHlX5kTJ040JBknTpzIt42tW7cakowZM2bk2vbAAw8Ykoxp06blue2BBx4w369bt86QZFSqVMlwOBxm+aeffmpIMt59912zLDg42Ojbt++ftnmtsfXt29cIDg423y9atMiQZLz++utO9R5//HHDZrMZ+/fvN8skGR4eHk5lO3fuNCQZkydPztXXlSZNmmRIMj755BOz7NKlS0ZYWJjh7e3t9NmDg4ONDh06XLO9HD/++KNxzz33GJLMV40aNYx9+/b96b4HDx40JBnjx4+/Zr3z58/nKouKijJq1KjhVBYcHGxIMj777DOzLCMjw6hYsaLTz9s//vEPo0yZMsYPP/zgtP/LL79suLm5GYcPHzbLJBkjR4403/v4+BixsbF/+tmuNnz4cEOScebMmVzbrjx2V746depkXLhwwayXnZ1t1K5d24iKijKys7PN8vPnzxvVq1c3HnroIbMs5+d6/vz5Tn01atTI8Pf3N06dOmWW7dy50yhRooTRp08fsyznnOzRo4fT/ocOHTLc3NyMf/7zn07lu3fvNtzd3XOVXyk9Pd2QZDz66KP51jEMw3jkkUcMSebPZI8ePQx/f3/j8uXLZp1jx44ZJUqUMMaMGWOWhYeHG/Xr1891zJo3b27Url3bLMv5jmrRooVTm4ZxffOb18/j2LFjDZvNZvz8889mWd++fQ1JxhtvvGGW/fbbb0apUqUMm81mzJ071yzft29frp+1nHE2btzYuHTpklk+btw4Q5LxxRdfmGVXfwflnFtXfgfljOfKY2YYhnH33XcbjRs3Nt9/9tlnhiRj0qRJZllWVpbRpk2bfL/XIiMjjbp16+YqBwC4HrfvAQBwFW9v72s+hS/nSosvvvjiphcF9/T0VP/+/a+7fp8+fVS2bFnz/eOPP66KFStq2bJlN9X/9Vq2bJnc3Nz097//3an8hRdekGEYWr58uVN5RESEatasab5v0KCB7Ha7fvrppz/tJzAw0GmR7ZIlS+rvf/+7zp49m+ftUdejbNmyqlevnmJjY7Vw4UJ98MEHunz5sjp16mRe+XOrrrxSLSMjQydPntQDDzygn376SRkZGU51g4KCnK6Iybndafv27UpNTZX0x5UuLVu2VLly5XTy5EnzFRERoaysLG3cuDHfsfj6+mrLli06evToDX2GU6dOyd3dXd7e3nluf/TRR5WQkKCEhAR98cUXio+P14oVK9SzZ0/zCqUdO3boxx9/VM+ePXXq1Clz3OfOnVN4eLg2btx4zfPl2LFj2rFjh/r16yc/Pz+zvEGDBnrooYfy/Fl/+umnnd4vXLhQ2dnZ6tq1q9OxCwwMVO3atbVu3bp8+8855688z/KSs93hcEiSunXrpuPHj2v9+vVmnQULFig7O1vdunWTJJ0+fVpr165V165ddebMGXNcp06dUlRUlH788Uf9+uuvTv0MGDBAbm5uTmXXM79X/jyeO3dOJ0+eVPPmzWUYhrZv356r/pULzfv6+qpOnToqU6aMunbtapbXqVNHvr6+eZ7HAwcOdFqL7plnnpG7u/tNfzddPactW7Z06nfFihUqWbKk05WsJUqUyHVV4pVyziUAQOHD7XsAAFzl7Nmz8vf3z3d7t27d9J///EdPPvmkXn75ZYWHh6tz5856/PHHVaLE9f1/T6VKlW5oUfPatWs7vbfZbKpVq1a+6yndLj///LOCgoJy/aJet25dc/uVqlatmquNcuXK/ekaMz///LNq166d6/jl18/1uHz5siIiItS6dWtNnjzZLI+IiFC9evU0fvx4vfXWWzfc7tU2bdqkkSNHKjExUefPn3falpGRIR8fH/N9rVq1ct3SdOedd0r6Y52dwMBA/fjjj9q1a1e+tyXmLBKel3Hjxqlv376qUqWKGjdurPbt26tPnz63vMBz5cqVndabeuSRR1S+fHm9+OKLWrp0qR5++GH9+OOPkpTvbVTSH8ejXLlyeW7LmeM6derk2la3bl2tXLky14LfV99K9uOPP8owjFznS45rLeSf8zN+rUD6yu059XPWz5o3b57Cw8Ml/XHrXqNGjcy53b9/vwzD0GuvvabXXnstz3aPHz+uSpUq5fvZpOub38OHD2vEiBFavHhxrvPu6pDUy8sr18+Zj4+PKleunOvn1MfHJ8/z+Opj7e3trYoVK97Ud1Ne47n6++Pnn39WxYoVVbp0aad6tWrVyrddwzBu+FZCAIA1CKUAALjCkSNHlJGRcc1fcEqVKqWNGzdq3bp1+vLLL7VixQrNmzdPbdq00apVq3Jd3ZBfG7dbfr90ZWVlXdeYbof8+jGuWhTdChs3btSePXv0zjvvOJXXrl1bdevWdVp8+2YdOHBA4eHhCgkJ0TvvvKMqVarIw8NDy5Yt08SJE2/qSrrs7Gw99NBDeumll/LcnhN05KVr165q2bKlPv/8c61atcoM3hYuXKh27drlu1/58uV1+fJlnTlz5k+vFMqRE8Bs3LhRDz/8sPlZx48fr0aNGuW5T35XYt2sq8+j7Oxs2Ww2LV++PM+fxWv17+Pjo4oVK2rXrl3X7HPXrl2qVKmS7Ha7pD+ueuzUqZM+//xzffDBB0pLS9OmTZv0xhtvOI1Lkl588UVFRUXl2e7V3zl5fUf82fxmZWXpoYce0unTpzVs2DCFhISoTJky+vXXX9WvX79cP4/5na+uOo8L6nvqt99+U4UKFQqkbQDArSGUAgDgCh9//LEk5fuLY44SJUooPDxc4eHheuedd/TGG2/o1Vdf1bp16xQREXHb/1c+5yqUHIZhaP/+/WrQoIFZVq5cOaWnp+fa9+eff3a6kuJGxhYcHKzVq1fnCiv27dtnbr8dgoODtWvXLmVnZztdLXUr/aSlpUlSrid3SX88me/y5cs3Odr/s2TJEl28eFGLFy92ukosv9vEcq6YuXIOfvjhB0kyF/GuWbOmzp49e0NPwrtSxYoV9eyzz+rZZ5/V8ePHdc899+if//znNUOpkJAQSX88he/Kn6lryTl+Z8+eNcct/XFL4s2MPWeOU1JScm3bt2+fKlSo4HSVVF5q1qwpwzBUvXr1a4Z3+enYsaP+/e9/6+uvv3Z6ml+Or776SocOHdJTTz3lVN6tWzfNmjVLa9as0d69e2UYhnnrniTz/CtZsuRNz2uOa83v7t279cMPP2jWrFnq06ePuU9CQsIt9XktP/74ox588EHz/dmzZ3Xs2DG1b9++QPoLDg7WunXrdP78eaerpfbv35/vPgcPHlTDhg0LZDwAgFvDmlIAAPx/a9eu1T/+8Q9Vr15d0dHR+dY7ffp0rrKcK0MuXrwoSeYvz3mFRDfjv//9r9NtRQsWLNCxY8ecgoaaNWvqm2++0aVLl8yypUuX6pdffnFq60bG1r59e2VlZen99993Kp84caJsNts1g44b0b59e6WmpmrevHlm2eXLlzV58mR5e3vnerLZ9cgJJebOnetU/t133yklJUV33333rQ1a/3dlx5VXkGRkZGjGjBl51j969Kg+//xz873D4dB///tfNWrUSIGBgZL+uBomMTFRK1euzLV/enp6vmFaVlZWrtuz/P39FRQUZP5c5icsLEyStG3btmvWu9KSJUskyfxlv3HjxqpZs6befvttM6i60okTJ67ZXsWKFdWoUSPNmjXL6Wdzz549WrVq1XWFHJ07d5abm5tGjx6d66oewzB06tSpa+4/dOhQlSpVSk899VSuuqdPn9bTTz+t0qVLa+jQoU7bIiIi5Ofnp3nz5mnevHm67777nG6/8/f3V+vWrfWvf/1Lx44dy9Xvnx0b6frmN6+fR8Mw9O677/5p+zdr+vTpyszMNN9PnTpVly9fvm3fDVeLiopSZmam/v3vf5tl2dnZmjJlSp71MzIydODAgXyfMAoAcC2ulAIAFEvLly/Xvn37dPnyZaWlpWnt2rVKSEhQcHCwFi9eLC8vr3z3HTNmjDZu3KgOHTooODhYx48f1wcffKDKlSubV1fUrFlTvr6+mjZtmsqWLasyZcqoadOmea4Tcz38/PzUokUL9e/fX2lpaZo0aZJq1arltNjvk08+qQULFqht27bq2rWrDhw4oE8++cRp4fEbHdvDDz+sBx98UK+++qoOHTqkhg0batWqVfriiy80aNCgXG3frIEDB+pf//qX+vXrp6SkJFWrVk0LFizQpk2bNGnSpOu+pexKjRs31kMPPaRZs2bJ4XAoMjJSx44d0+TJk1WqVCkNGjToutpZs2aNLly4kKu8U6dOioyMlIeHhx5++GE99dRTOnv2rP7973/L398/z/DhzjvvVExMjLZu3aqAgAB99NFHSktLcwqxhg4dqsWLF6tjx47q16+fGjdurHPnzmn37t1asGCBDh06lOetSGfOnFHlypX1+OOPq2HDhvL29tbq1au1detWTZgw4ZqfsUaNGrrrrru0evVq/e1vf8u1/YcfftAnn3wiSTp//ry++eYbzZo1S7Vq1VLv3r0l/XH14H/+8x+1a9dO9erVU//+/VWpUiX9+uuvWrdunex2uxlk5Wf8+PFq166dwsLCFBMTo99//12TJ0+Wj4+PRo0adc19pT9+tl9//XXFx8fr0KFD6tSpk8qWLauDBw/q888/18CBA/Xiiy/mu3/t2rU1a9YsRUdHq379+oqJiVH16tV16NAhffjhhzp58qT+97//5fq5L1mypDp37qy5c+fq3Llzevvtt3O1PWXKFLVo0UL169fXgAEDVKNGDaWlpSkxMVFHjhzRzp07r/nZrmd+Q0JCVLNmTb344ov69ddfZbfb9dlnn/3pmm634tKlSwoPD1fXrl2VkpKiDz74QC1atNAjjzxSIP116tRJ9913n1544QXt379fISEhWrx4sfmfBVdfCbp69WoZhqFHH320QMYDALhFVj/uDwAAV8p5jHnOy8PDwwgMDDQeeugh49133zUf836lnMfP51izZo3x6KOPGkFBQYaHh4cRFBRk9OjRw/jhhx+c9vviiy+M0NBQw93d3elR5Q888IBRr169PMd39aPT161bZ0gy/ve//xnx8fGGv7+/UapUKaNDhw5Oj3fPMWHCBKNSpUqGp6encf/99xvbtm3L1ea1xta3b18jODjYqe6ZM2eMwYMHG0FBQUbJkiWN2rVrG+PHjzeys7Od6knK83H1wcHBRt++ffP8vFdKS0sz+vfvb1SoUMHw8PAw6tevn+fj3YODg40OHTr8aXuGYRjnz583xowZY4SGhhqlSpUyfHx8jI4dOxrbt2//031zHluf3+vjjz82DMMwFi9ebDRo0MDw8vIyqlWrZrz11lvGRx99ZEgyDh48mGvcK1euNBo0aGB4enoaISEhxvz583P1febMGSM+Pt6oVauW4eHhYVSoUMFo3ry58fbbbxuXLl0y60kyRo4caRiGYVy8eNEYOnSo0bBhQ6Ns2bJGmTJljIYNGxoffPDBdR2rd955x/D29jbOnz/vVH7153ZzczMqV65sDBw40EhLS8vVzvbt243OnTsb5cuXNzw9PY3g4GCja9euxpo1a8w6OT/XeX321atXG/fff79RqlQpw263Gw8//LDx/fffO9XJOSdPnDiR52f57LPPjBYtWhhlypQxypQpY4SEhBixsbFGSkrKdR2LXbt2GT169DAqVqxolCxZ0ggMDDR69Ohh7N69O999EhISDEmGzWYzfvnllzzrHDhwwOjTp48RGBholCxZ0qhUqZLRsWNHY8GCBWadnO+orVu3Ou17vfP7/fffGxEREYa3t7dRoUIFY8CAAcbOnTudznPD+ONcL1OmTK4x5vf9dPV5lzPODRs2GAMHDjTKlStneHt7G9HR0capU6dytXnld1DOuXU947n6+9cwDOPEiRNGz549jbJlyxo+Pj5Gv379jE2bNhmSjLlz5zrV7datm9GiRYtc7QIACgebYbhg5VEAAAAUKhkZGapRo4bGjRunmJgYVw8HhdzMmTPVv39/bd26VU2aNHH1cLRo0SI99thj+vrrr3X//fdLklJTU1W9enXNnTuXK6UAoJBiTSkAAADIx8dHL730ksaPH39TTw0ErPL77787vc/KytLkyZNlt9t1zz33mOWTJk1S/fr1CaQAoBBjTSkAAABIkoYNG6Zhw4a5ehjANT333HP6/fffFRYWposXL2rhwoXavHmz3njjDZUqVcqs9+abb7pwlACA60EoBQAAAOAvo02bNpowYYKWLl2qCxcuqFatWpo8ebLi4uJcPTQAwA1iTSkAAAAAAABYjjWlAAAAAAAAYDlCKQAAAAAAAFiONaVcKDs7W0ePHlXZsmVls9lcPRwAAAAAAIBbZhiGzpw5o6CgIJUokf/1UIRSLnT06FFVqVLF1cMAAAAAAAC47X755RdVrlw53+2EUi5UtmxZSX9Mkt1ud/FoAAAAAAAAbp3D4VCVKlXM3CM/hFIulHPLnt1uJ5QCAAAAAABFyp8tVcRC5wAAAAAAALAcoRQAAAAAAAAsRyiFv5Q333xTNptNgwYNMssuXLig2NhYlS9fXt7e3urSpYvS0tKc9jt8+LA6dOig0qVLy9/fX0OHDtXly5ev2dfp06cVHR0tu90uX19fxcTE6OzZs051du3apZYtW8rLy0tVqlTRuHHjcrUzf/58hYSEyMvLS/Xr19eyZctu/gAUY8x98cS8F0/Me/HF3AMAUMwYcJmMjAxDkpGRkeHqofwlfPvtt0a1atWMBg0aGM8//7xZ/vTTTxtVqlQx1qxZY2zbts1o1qyZ0bx5c3P75cuXjbvuusuIiIgwtm/fbixbtsyoUKGCER8ff83+2rZtazRs2ND45ptvjK+++sqoVauW0aNHD3N7RkaGERAQYERHRxt79uwx/ve//xmlSpUy/vWvf5l1Nm3aZLi5uRnjxo0zvv/+e2P48OFGyZIljd27d9++A1MMMPfFE/NePDHvxRdzDwBA0XG9eQehlAsRSl2/M2fOGLVr1zYSEhKMBx54wPzHanp6ulGyZElj/vz5Zt29e/cakozExETDMAxj2bJlRokSJYzU1FSzztSpUw273W5cvHgxz/6+//57Q5KxdetWs2z58uWGzWYzfv31V8MwDOODDz4wypUr59TGsGHDjDp16pjvu3btanTo0MGp7aZNmxpPPfXUTR6J4oe5L56Y9+KJeS++mHsAAIqW6807uH0PfwmxsbHq0KGDIiIinMqTkpKUmZnpVB4SEqKqVasqMTFRkpSYmKj69esrICDArBMVFSWHw6Hk5OQ8+0tMTJSvr6+aNGlilkVERKhEiRLasmWLWadVq1by8PBwajclJUW//fabWefqMUdFRZljw59j7osn5r14Yt6LL+YeAIDiyd3VAwD+zNy5c/Xdd99p69atubalpqbKw8NDvr6+TuUBAQFKTU0161z5D9Wc7Tnb8pKamip/f3+nMnd3d/n5+Tm1W7169XzbLVeuXL5959cvnDH3xRPzXjwx78UXcw8AQPFFKIVC7ZdfftHzzz+vhIQEeXl5uXo4sBBzXzwx78UT8158MfcAABRv3L6HQi0pKUnHjx/XPffcI3d3d7m7u2vDhg1677335O7uroCAAF26dEnp6elO+6WlpSkwMFCSFBgYmOspPTnvc+pcLTAwUMePH3cqu3z5sk6fPn1D7eZXJ79+8X+Y++KJeS+emPfii7kHAKB4I5RCoRYeHq7du3drx44d5qtJkyaKjo42/1yyZEmtWbPG3CclJUWHDx9WWFiYJCksLEy7d+92+sdnQkKC7Ha7QkND8+w3LCxM6enpSkpKMsvWrl2r7OxsNW3a1KyzceNGZWZmOrVbp04dlStXzqxz5dhy6uSMDflj7osn5r14Yt6LL+YeAIBizqKF15EHnr53c658Ko9h/PGo6KpVqxpr1641tm3bZoSFhRlhYWHm9pxHRUdGRho7duwwVqxYYdxxxx3X9ajou+++29iyZYvx9ddfG7Vr13Z6VHR6eroREBBg9O7d29izZ48xd+5co3Tp0rkeFe3u7m68/fbbxt69e42RI0fyqOhbwNwXT8x78cS8F1/MPQAAf33Xm3cQSrkQodTNufofq7///rvx7LPPGuXKlTNKly5tPPbYY8axY8ec9jl06JDRrl07o1SpUkaFChWMF154wcjMzDS3Hzx40JBkrFu3ziw7deqU0aNHD8Pb29uw2+1G//79jTNnzji1u3PnTqNFixaGp6enUalSJePNN9/MNd5PP/3UuPPOOw0PDw+jXr16xpdffnl7DkQxxNwXT8x78cS8F1/MPQAAf33Xm3fYDMMwXHaZVjHncDjk4+OjjIwM2e12Vw+nWFu3bp06d+6sn376ybwkH8UDc188Me/FE/NefDH3AABY63rzDtaUAiQtW7ZMr7zyCv9QLYaY++KJeS+emPfii7kHAKBwKjSh1JtvvimbzaZBgwaZZRcuXFBsbKzKly8vb29vdenSJdcTTg4fPqwOHTqodOnS8vf319ChQ3X58uVr9nX69GlFR0fLbrfL19dXMTExOnv2rFOdXbt2qWXLlvLy8lKVKlU0bty4XO3Mnz9fISEh8vLyUv369bVs2bKbPwBwqfHjx2vo0KGuHgZcgLkvnpj34ol5L76YewAACqdCEUpt3bpV//rXv9SgQQOn8sGDB2vJkiWaP3++NmzYoKNHj6pz587m9qysLHXo0EGXLl3S5s2bNWvWLM2cOVMjRoy4Zn/R0dFKTk5WQkKCli5dqo0bN2rgwIHmdofDocjISAUHByspKUnjx4/XqFGjNH36dLPO5s2b1aNHD8XExGj79u3q1KmTOnXqpD179tymowIAAAAAAFB0uXxNqbNnz+qee+7RBx98oNdff12NGjXSpEmTlJGRoTvuuENz5szR448/Lknat2+f6tatq8TERDVr1kzLly9Xx44ddfToUQUEBEiSpk2bpmHDhunEiRPy8PDI1d/evXsVGhqqrVu3qkmTJpKkFStWqH379jpy5IiCgoI0depUvfrqq0pNTTXbePnll7Vo0SLt27dPktStWzedO3dOS5cuNdtu1qyZGjVqpGnTpl3XZ2dNKQAAAAAAUNT8ZdaUio2NVYcOHRQREeFUnpSUpMzMTKfykJAQVa1aVYmJiZKkxMRE1a9f3wykJCkqKkoOh0PJycl59peYmChfX18zkJKkiIgIlShRQlu2bDHrtGrVyinUioqKUkpKin777TezztVjjoqKMscGAAAAAACA/Lm7svO5c+fqu+++09atW3Nty7lKydfX16k8ICBAqampZp0rA6mc7Tnb8pKamip/f3+nMnd3d/n5+Tm1W7169XzbLVeuXL5959evJF28eFEXL1403zscjnzrAgAAAAAAFGUuC6V++eUXPf/880pISJCXl5erhmGpsWPHavTo0a4eRoGw2Vw9AlzNkhtzmfjCx4KJt41m3gsbY2TBz/toW9H8++uvbqQxsuA7mcM5X+j0dOnqGwAA3DYuu30vKSlJx48f1z333CN3d3e5u7trw4YNeu+99+Tu7q6AgABdunRJ6enpTvulpaUpMDBQkhQYGJjraXw573PqXC0wMFDHjx93Krt8+bJOnz59Q+3mVye/fiUpPj5eGRkZ5uuXX37Jty4AAAAAAEBR5rJQKjw8XLt379aOHTvMV5MmTRQdHW3+uWTJklqzZo25T0pKig4fPqywsDBJUlhYmHbv3u0UMiUkJMhutys0NDTPfsPCwpSenq6kpCSzbO3atcrOzlbTpk3NOhs3blRmZqZTu3Xq1FG5cuXMOleOLadOztjy4unpKbvd7vQCAAAAAAAojlx2+17ZsmV11113OZWVKVNG5cuXN8tjYmI0ZMgQ+fn5yW6367nnnlNYWJiaNWsmSYqMjFRoaKh69+6tcePGKTU1VcOHD1dsbKw8PT3z7Ldu3bpq27atBgwYoGnTpikzM1NxcXHq3r27goKCJEk9e/bU6NGjFRMTo2HDhmnPnj169913NXHiRLOd559/Xg888IAmTJigDh06aO7cudq2bZumT59eEIcLAAAAAACgSHH50/euZeLEierYsaO6dOmiVq1aKTAwUAsXLjS3u7m5aenSpXJzc1NYWJh69eqlPn36aMyYMWadQ4cOyWazaf369WbZ7NmzFRISovDwcLVv314tWrRwCpN8fHy0atUqHTx4UI0bN9YLL7ygESNGaODAgWad5s2ba86cOZo+fboaNmyoBQsWaNGiRbmCNgAAAAAAAORmMwxLlkN2mXXr1qlz58766aefzFvvCguHwyEfHx9lZGT85W/lY73rwoeFzospFjovlljovPhiofNiioXOAQCF3PXmHYX6SqnbYdmyZXrllVcKXSAFAAAAAABQnLlsTSmrjB8/3tVDAAAAAAAAwFWK/JVSAAAAAAAAKHwIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAlpk6daoaNGggu90uu92usLAwLV++3NzeunVr2Ww2p9fTTz9tbt+5c6d69OihKlWqqFSpUqpbt67efffda/a5fv36XG3mvLZu3WrW+/TTT9WoUSOVLl1awcHBGj9+fK62Ll68qFdffVXBwcHy9PRUtWrV9NFHH92GIwMAxY+7qwcAAAAAoPioXLmy3nzzTdWuXVuGYWjWrFl69NFHtX37dtWrV0+SNGDAAI0ZM8bcp3Tp0uafk5KS5O/vr08++URVqlTR5s2bNXDgQLm5uSkuLi7PPps3b65jx445lb322mtas2aNmjRpIklavny5oqOjNXnyZEVGRmrv3r0aMGCASpUq5dRu165dlZaWpg8//FC1atXSsWPHlJ2dfduODwAUJ4RSAAAAACzz8MMPO73/5z//qalTp+qbb74xQ6nSpUsrMDAwz/3/9re/Ob2vUaOGEhMTtXDhwnxDKQ8PD6f2MjMz9cUXX+i5556TzWaTJH388cfq1KmTeVVWjRo1FB8fr7feekuxsbGy2WxasWKFNmzYoJ9++kl+fn6SpGrVqt34QQAASOL2PQAAAAAukpWVpblz5+rcuXMKCwszy2fPnq0KFSrorrvuUnx8vM6fP3/NdjIyMsyQ6HosXrxYp06dUv/+/c2yixcvysvLy6leqVKldOTIEf3888/mfk2aNNG4ceNUqVIl3XnnnXrxxRf1+++/X3ffAID/w5VSAAAAACy1e/duhYWF6cKFC/L29tbnn3+u0NBQSVLPnj0VHBysoKAg7dq1S8OGDVNKSooWLlyYZ1ubN2/WvHnz9OWXX153/x9++KGioqJUuXJlsywqKkqDBw9Wv3799OCDD2r//v2aMGGCJOnYsWOqVq2afvrpJ3399dfy8vLS559/rpMnT+rZZ5/VqVOnNGPGjFs4IgBQPBFKAQAAALBUnTp1tGPHDmVkZGjBggXq27evNmzYoNDQUA0cONCsV79+fVWsWFHh4eE6cOCAatas6dTOnj179Oijj2rkyJGKjIy8rr6PHDmilStX6tNPP3UqHzBggA4cOKCOHTsqMzNTdrtdzz//vEaNGqUSJf64wSQ7O1s2m02zZ8+Wj4+PJOmdd97R448/rg8++EClSpW6lcMCAMUOt+8BAAAAsJSHh4dq1aqlxo0ba+zYsWrYsGG+T9Br2rSpJGn//v1O5d9//73Cw8M1cOBADR8+/Lr7njFjhsqXL69HHnnEqdxms+mtt97S2bNn9fPPPys1NVX33XefpD/Wl5KkihUrqlKlSmYgJUl169aVYRg6cuTIdY8BAPAHQikAAAAALpWdna2LFy/muW3Hjh2S/giEciQnJ+vBBx9U37599c9//vO6+zEMQzNmzFCfPn1UsmTJPOu4ubmpUqVK8vDw0P/+9z+FhYXpjjvukCTdf//9Onr0qM6ePWvW/+GHH1SiRAmnWwEBANeH2/cAAAAAWCY+Pl7t2rVT1apVdebMGc2ZM0fr16/XypUrdeDAAc2ZM0ft27dX+fLltWvXLg0ePFitWrVSgwYNJP1xy16bNm0UFRWlIUOGKDU1VdIfYVJOeJSftWvX6uDBg3ryySdzbTt58qQWLFig1q1b68KFC5oxY4bmz5+vDRs2mHV69uypf/zjH+rfv79Gjx6tkydPaujQofrb3/7GrXsAcBO4UgoAAACAZY4fP64+ffqoTp06Cg8P19atW7Vy5Uo99NBD8vDw0OrVqxUZGamQkBC98MIL6tKli5YsWWLuv2DBAp04cUKffPKJKlasaL7uvfdes86hQ4dks9m0fv16p74//PBDNW/eXCEhIXmObdasWWrSpInuv/9+JScna/369eYtfJLk7e2thIQEpaenq0mTJoqOjtbDDz+s99577/YeJAAoJmyGYRiuHkRx5XA45OPjo4yMDNntdlcP55bYbK4eAa5myZnNxBc+Fky8bTTzXtgYIwt+3kfbRhd4H7hxI42RBd/JHM75Qqcn/3z/M+vWrVPnzp31008/qVy5cq4eDgAUO9ebd3ClFAAAAIAiZdmyZXrllVcIpACgkGNNKQAAAABFyvjx4109BADAdeBKKQAAAAAAAFiOUAoAAAAAAACWc2koNXXqVDVo0EB2u112u11hYWFavny5ub1169ay2WxOr6efftqpjcOHD6tDhw4qXbq0/P39NXToUF2+fPma/Z4+fVrR0dGy2+3y9fVVTEyMzp4961Rn165datmypby8vFSlShWNGzcuVzvz589XSEiIvLy8VL9+fS1btuwWjgYAAAAAAEDx4dJQqnLlynrzzTeVlJSkbdu2qU2bNnr00UeVnJxs1hkwYICOHTtmvq4Mh7KystShQwddunRJmzdv1qxZszRz5kyNGDHimv1GR0crOTlZCQkJWrp0qTZu3KiBAwea2x0OhyIjIxUcHKykpCSNHz9eo0aN0vTp0806mzdvVo8ePRQTE6Pt27erU6dO6tSpk/bs2XMbjxAAAAAAAEDRZDMMSx4cf938/Pw0fvx4xcTEqHXr1mrUqJEmTZqUZ93ly5erY8eOOnr0qAICAiRJ06ZN07Bhw3TixAl5eHjk2mfv3r0KDQ3V1q1b1aRJE0nSihUr1L59ex05ckRBQUGaOnWqXn31VaWmppptvPzyy1q0aJH27dsnSerWrZvOnTunpUuXmm03a9ZMjRo10rRp067rs17vIxL/Cmw8LbrQseTMZuILHwsm3jaaeS9sjJEFP++jbaMLvA/cuJHGyILvZA7nfKHT04Lv+gLvATeqUP3SBgB/4nrzjkKzplRWVpbmzp2rc+fOKSwszCyfPXu2KlSooLvuukvx8fE6f/68uS0xMVH169c3AylJioqKksPhcLra6kqJiYny9fU1AylJioiIUIkSJbRlyxazTqtWrZxCraioKKWkpOi3334z60RERDi1HRUVpcTExFs4CgAAAAAAAMWDu6sHsHv3boWFhenChQvy9vbW559/rtDQUElSz549FRwcrKCgIO3atUvDhg1TSkqKFi5cKElKTU11CqQkme9TU1Pz7C81NVX+/v5OZe7u7vLz8zP3SU1NVfXq1fNtt1y5cvn2nV+/knTx4kVdvHjRfO9wOPKtCwAAAAAAUJS5PJSqU6eOduzYoYyMDC1YsEB9+/bVhg0bFBoa6rTOU/369VWxYkWFh4frwIEDqlmzpgtHfXPGjh2r0aO5/QEAAAAAAMDlt+95eHioVq1aaty4scaOHauGDRvq3XffzbNu06ZNJUn79++XJAUGBiotLc2pTs77wMDAPNsIDAzU8ePHncouX76s06dPm/tcT7v51cmvX0mKj49XRkaG+frll1/yrQsAAAAAAFCUuTyUulp2drbTLW5X2rFjhySpYsWKkqSwsDDt3r3bKWRKSEiQ3W43bwG8WlhYmNLT05WUlGSWrV27VtnZ2WboFRYWpo0bNyozM9Op3Tp16qhcuXJmnTVr1ji1nZCQ4LQe1tU8PT1lt9udXgAAAAAAAMWRS0Op+Ph4bdy4UYcOHdLu3bsVHx+v9evXKzo6WgcOHNA//vEPJSUl6dChQ1q8eLH69OmjVq1aqUGDBpKkyMhIhYaGqnfv3tq5c6dWrlyp4cOHKzY2Vp6ennn2WbduXbVt21YDBgzQt99+q02bNikuLk7du3dXUFCQpD/WsvLw8FBMTIySk5M1b948vfvuuxoyZIjZzvPPP68VK1ZowoQJ2rdvn0aNGqVt27YpLi6u4A8cAAAAAADAX5xLQ6njx4+rT58+qlOnjsLDw7V161atXLlSDz30kDw8PLR69WpFRkYqJCREL7zwgrp06aIlS5aY+7u5uWnp0qVyc3NTWFiYevXqpT59+mjMmDFmnUOHDslms2n9+vVm2ezZsxUSEqLw8HC1b99eLVq00PTp083tPj4+WrVqlQ4ePKjGjRvrhRde0IgRI5zWuGrevLnmzJmj6dOnq2HDhlqwYIEWLVqku+66q2APGgAAAAAAQBFgMwzDcPUgCtK6devUuXNn/fTTT+atd4WFw+GQj4+PMjIy/vK38tlsrh4BrmbJmc3EFz4WTLxtNPNe2BgjC37eR9t4UEdhNNIYWfCdzOGcL3R6WvBdX+A94EYV6V/aABQ515t3FLo1pW63ZcuW6ZVXXil0gRQAAAAAAEBx5u7qARS08ePHu3oIAAAAAAAAuEqRv1IKAAAAAAAAhQ+hFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACzn0lBq6tSpatCggex2u+x2u8LCwrR8+XJz+4ULFxQbG6vy5cvL29tbXbp0UVpamlMbhw8fVocOHVS6dGn5+/tr6NChunz58jX7PX36tKKjo2W32+Xr66uYmBidPXvWqc6uXbvUsmVLeXl5qUqVKho3blyudubPn6+QkBB5eXmpfv36WrZs2S0cDQAAAAAAgOLDpaFU5cqV9eabbyopKUnbtm1TmzZt9Oijjyo5OVmSNHjwYC1ZskTz58/Xhg0bdPToUXXu3NncPysrSx06dNClS5e0efNmzZo1SzNnztSIESOu2W90dLSSk5OVkJCgpUuXauPGjRo4cKC53eFwKDIyUsHBwUpKStL48eM1atQoTZ8+3ayzefNm9ejRQzExMdq+fbs6deqkTp06ac+ePbf5KAEAAAAAABQ9NsMwDFcP4kp+fn4aP368Hn/8cd1xxx2aM2eOHn/8cUnSvn37VLduXSUmJqpZs2Zavny5OnbsqKNHjyogIECSNG3aNA0bNkwnTpyQh4dHrvb37t2r0NBQbd26VU2aNJEkrVixQu3bt9eRI0cUFBSkqVOn6tVXX1VqaqrZxssvv6xFixZp3759kqRu3brp3LlzWrp0qdl2s2bN1KhRI02bNu26PqvD4ZCPj48yMjJkt9tv/qAVAjabq0eAq1lyZjPxhY8FE28bzbwXNsbIgp/30bbRBd4HbtxIY2TBdzKHc77Q6WnBd32B94AbVah+aQOAP3G9eUehWVMqKytLc+fO1blz5xQWFqakpCRlZmYqIiLCrBMSEqKqVasqMTFRkpSYmKj69eubgZQkRUVFyeFwmFdbXS0xMVG+vr5mICVJERERKlGihLZs2WLWadWqlVOoFRUVpZSUFP32229mnSvHllMnZ2x5uXjxohwOh9MLAAAAAACgOHJ5KLV79255e3vL09NTTz/9tD7//HOFhoaaVyn5+vo61Q8ICFBqaqokKTU11SmQytmesy0vqamp8vf3dypzd3eXn5/fDbWbX538+pWksWPHysfHx3xVqVIl37oAAAAAAABFmctDqTp16mjHjh3asmWLnnnmGfXt21fff/+9q4dVIOLj45WRkWG+fvnlF1cPCQAAAAAAwCXcXT0ADw8P1apVS5LUuHFjbd26Ve+++666deumS5cuKT093elqqbS0NAUGBkqSAgMD9e233zq1l/N0vpw6VwsMDNTx48edyi5fvqzTp087tXv1U/6ubje/Ovn1K0menp7y9PTMdzsAAAAAAEBx4fIrpa6WnZ2tixcvqnHjxipZsqTWrFljbktJSdHhw4cVFhYmSQoLC9Pu3budQqaEhATZ7XaFhobm2X5YWJjS09OVlJRklq1du1bZ2dlq2rSpWWfjxo3KzMx0ardOnToqV66cWefKseXUyRkbAAAAAAAA8ufSUCo+Pl4bN27UoUOHtHv3bsXHx2v9+vWKjo6Wj4+PYmJiNGTIEK1bt05JSUnq37+/wsLC1KxZM0lSZGSkQkND1bt3b+3cuVMrV67U8OHDFRsbm+8VSXXr1lXbtm01YMAAffvtt9q0aZPi4uLUvXt3BQUFSZJ69uwpDw8PxcTEKDk5WfPmzdO7776rIUOGmO08//zzWrFihSZMmKB9+/Zp1KhR2rZtm+Li4gr+wAEAAAAAAPzFuTSUOn78uPr06aM6deooPDxcW7du1cqVK/XQQw9JkiZOnKiOHTuqS5cuatWqlQIDA7Vw4UJzfzc3Ny1dulRubm4KCwtTr1691KdPH40ZM8asc+jQIdlsNq1fv94smz17tkJCQhQeHq727durRYsWmj59urndx8dHq1at0sGDB9W4cWO98MILGjFihAYOHGjWad68uebMmaPp06erYcOGWrBggRYtWqS77rqrAI8YAAAAAABA0WAzDMNw9SAK0rp169S5c2f99NNP5q13hYXD4ZCPj48yMjJkt9tdPZxbYrO5egS4miVnNhNf+Fgw8bbRzHthY4ws+HkfbRtd4H3gxo00RhZ8J3M45wudnhZ81xd4D7hRRfqXNgBFzvXmHYVuTanbbdmyZXrllVcKXSAFAAAAAABQnLn86XsFbfz48a4eAgAAAAAAAK5S5K+UAgAAAAAAQOFDKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACzn0lBq7Nixuvfee1W2bFn5+/urU6dOSklJcarTunVr2Ww2p9fTTz/tVOfw4cPq0KGDSpcuLX9/fw0dOlSXL1++Zt+nT59WdHS07Ha7fH19FRMTo7NnzzrV2bVrl1q2bCkvLy9VqVJF48aNy9XO/PnzFRISIi8vL9WvX1/Lli27yaMBAAAAAABQfLg0lNqwYYNiY2P1zTffKCEhQZmZmYqMjNS5c+ec6g0YMEDHjh0zX1eGQ1lZWerQoYMuXbqkzZs3a9asWZo5c6ZGjBhxzb6jo6OVnJyshIQELV26VBs3btTAgQPN7Q6HQ5GRkQoODlZSUpLGjx+vUaNGafr06WadzZs3q0ePHoqJidH27dvVqVMnderUSXv27LlNRwgAAAAAAKBoshmGYbh6EDlOnDghf39/bdiwQa1atZL0x5VSjRo10qRJk/LcZ/ny5erYsaOOHj2qgIAASdK0adM0bNgwnThxQh4eHrn22bt3r0JDQ7V161Y1adJEkrRixQq1b99eR44cUVBQkKZOnapXX31VqampZhsvv/yyFi1apH379kmSunXrpnPnzmnp0qVm282aNVOjRo00bdq0P/28DodDPj4+ysjIkN1uv/4DVQjZbK4eAa5myZnNxBc+Fky8bTTzXtgYIwt+3kfbRhd4H7hxI42RBd/JHM75QqenBd/1Bd4DblSh+aUNAK7D9eYdhWpNqYyMDEmSn5+fU/ns2bNVoUIF3XXXXYqPj9f58+fNbYmJiapfv74ZSElSVFSUHA6HkpOT8+wnMTFRvr6+ZiAlSRERESpRooS2bNli1mnVqpVTqBUVFaWUlBT99ttvZp2IiAintqOiopSYmJhnvxcvXpTD4XB6AQAAAAAAFEfurh5AjuzsbA0aNEj333+/7rrrLrO8Z8+eCg4OVlBQkHbt2qVhw4YpJSVFCxculCSlpqY6BVKSzPepqal59pWamip/f3+nMnd3d/n5+Zn7pKamqnr16vm2W65cuXz7zq/fsWPHavRo/qcZAAAAAACg0IRSsbGx2rNnj77++mun8ivXeapfv74qVqyo8PBwHThwQDVr1rR6mLckPj5eQ4YMMd87HA5VqVLFhSMCAAAAAABwjUJx+15cXJyWLl2qdevWqXLlytes27RpU0nS/v37JUmBgYFKS0tzqpPzPjAwMM82AgMDdfz4caeyy5cv6/Tp0+Y+19NufnXy69fT01N2u93pBQAAAAAAUBy5NJQyDENxcXH6/PPPtXbt2ly3y+Vlx44dkqSKFStKksLCwrR7926nkCkhIUF2u12hoaF5thEWFqb09HQlJSWZZWvXrlV2drYZeoWFhWnjxo3KzMx0ardOnToqV66cWWfNmjVObSckJCgsLOw6Pj0AAAAAAEDx5dJQKjY2Vp988onmzJmjsmXLKjU1Vampqfr9998lSQcOHNA//vEPJSUl6dChQ1q8eLH69OmjVq1aqUGDBpKkyMhIhYaGqnfv3tq5c6dWrlyp4cOHKzY2Vp6ennn2W7duXbVt21YDBgzQt99+q02bNikuLk7du3dXUFCQpD/WsvLw8FBMTIySk5M1b948vfvuu0633z3//PNasWKFJkyYoH379mnUqFHatm2b4uLiCvjIAQAAAAAA/LW5NJSaOnWqMjIy1Lp1a1WsWNF8zZs3T5Lk4eGh1atXKzIyUiEhIXrhhRfUpUsXLVmyxGzDzc1NS5culZubm8LCwtSrVy/16dNHY8aMMescOnRINptN69evN8tmz56tkJAQhYeHq3379mrRooWmT59ubvfx8dGqVat08OBBNW7cWC+88IJGjBjhtMZV8+bNNWfOHE2fPl0NGzbUggULtGjRIqeF2gEAAAAAAJCbzTAMw9WDKGjr1q1T586d9dNPP5m33hUGDodDPj4+ysjI+MuvL2WzuXoEuJolZzYTX/hYMPG20cx7YWOMLPh5H23j6bGF0UhjZMF3ModzvtDpacF3fYH3gBtV5H9pA1CkXG/eUSgWOi9oy5Yt0yuvvFKoAikAAAAAAIDizN3VA7DC+PHjXT0EAAAAAAAAXKFYXCkFAAAAAACAwoVQCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABguZsKpWrUqKFTp07lKk9PT1eNGjVueVAAAAAAAAAo2m4qlDp06JCysrJylV+8eFG//vrrLQ8KAAAAAAAARZv7jVRevHix+eeVK1fKx8fHfJ+VlaU1a9aoWrVqt21wAAAAAAAAKJpuKJTq1KmTJMlms6lv375O20qWLKlq1appwoQJt21wAAAAAAAAKJpuKJTKzs6WJFWvXl1bt25VhQoVCmRQAAAAAAAAKNpuKJTKcfDgwds9DgAAAAAAABQjNxVKSdKaNWu0Zs0aHT9+3LyCKsdHH310ywMDAAAAAABA0XVTodTo0aM1ZswYNWnSRBUrVpTNZrvd4wIAAAAAAEARdlOh1LRp0zRz5kz17t37do8HAAAAAAAAxUCJm9np0qVLat68+e0eCwAAAAAAAIqJmwqlnnzySc2ZM+d2jwUAAAAAAADFxE3dvnfhwgVNnz5dq1evVoMGDVSyZEmn7e+8885tGRwAAAAAAACKppsKpXbt2qVGjRpJkvbs2eO0jUXPAQAAAAAA8GduKpRat27d7R4HAAAAAAAAipGbWlMKAAAAAAAAuBU3daXUgw8+eM3b9NauXXvTAwIAAAAAAEDRd1OhVM56UjkyMzO1Y8cO7dmzR3379r0d4wIAAAAAAEARdlOh1MSJE/MsHzVqlM6ePXtLAwIAAAAAAEDRd1vXlOrVq5c++uij29kkAAAAAAAAiqDbGkolJibKy8vrdjYJAAAAAACAIuimbt/r3Lmz03vDMHTs2DFt27ZNr7322m0ZGAAAAAAAAIqumwqlfHx8nN6XKFFCderU0ZgxYxQZGXlbBgYAAAAAAICi66ZCqRkzZtzucQAAAAAAAKAYualQKkdSUpL27t0rSapXr57uvvvu2zIoAAAAAAAAFG03FUodP35c3bt31/r16+Xr6ytJSk9P14MPPqi5c+fqjjvuuJ1jBAAAAAAAQBFzU0/fe+6553TmzBklJyfr9OnTOn36tPbs2SOHw6G///3v193O2LFjde+996ps2bLy9/dXp06dlJKS4lTnwoULio2NVfny5eXt7a0uXbooLS3Nqc7hw4fVoUMHlS5dWv7+/ho6dKguX758zb5Pnz6t6Oho2e12+fr6KiYmRmfPnnWqs2vXLrVs2VJeXl6qUqWKxo0bl6ud+fPnKyQkRF5eXqpfv76WLVt23Z8fAAAAAACguLqpUGrFihX64IMPVLduXbMsNDRUU6ZM0fLly6+7nQ0bNig2NlbffPONEhISlJmZqcjISJ07d86sM3jwYC1ZskTz58/Xhg0bdPToUaen/2VlZalDhw66dOmSNm/erFmzZmnmzJkaMWLENfuOjo5WcnKyEhIStHTpUm3cuFEDBw40tzscDkVGRio4OFhJSUkaP368Ro0apenTp5t1Nm/erB49eigmJkbbt29Xp06d1KlTJ+3Zs+e6jwEAAAAAAEBxZDMMw7jRncqWLauvvvpKjRo1cirfvn27HnjgATkcjpsazIkTJ+Tv768NGzaoVatWysjI0B133KE5c+bo8ccflyTt27dPdevWVWJiopo1a6bly5erY8eOOnr0qAICAiRJ06ZN07Bhw3TixAl5eHjk6mfv3r0KDQ3V1q1b1aRJE0l/BG3t27fXkSNHFBQUpKlTp+rVV19Vamqq2cbLL7+sRYsWad++fZKkbt266dy5c1q6dKnZdrNmzdSoUSNNmzbtTz+vw+GQj4+PMjIyZLfbb+qYFRY2m6tHgKvd+Jl9E5j4wseCibeNZt4LG2Nkwc/7aNvoAu8DN26kMbLgO5nDOV/o9LTgu77Ae8CNsuKfdgBwu1xv3nFTV0q1adNGzz//vI4ePWqW/frrrxo8eLDCw8NvpklJUkZGhiTJz89P0h8LqWdmZioiIsKsExISoqpVqyoxMVGSlJiYqPr165uBlCRFRUXJ4XAoOTk5z34SExPl6+trBlKSFBERoRIlSmjLli1mnVatWjmFWlFRUUpJSdFvv/1m1rlybDl1csZ2tYsXL8rhcDi9AAAAAAAAiqObCqXef/99ORwOVatWTTVr1lTNmjVVvXp1ORwOTZ48+aYGkp2drUGDBun+++/XXXfdJUnmVUo5i6nnCAgIUGpqqlnnykAqZ3vOtrykpqbK39/fqczd3V1+fn431G5+dfLrd+zYsfLx8TFfVapUybMeAAAAAABAUXdTT9+rUqWKvvvuO61evdq8la1u3bq5rhq6EbGxsdqzZ4++/vrrm26jsIuPj9eQIUPM9w6Hg2AKAAAAAAAUSzd0pdTatWsVGhoqh8Mhm82mhx56SM8995yee+453XvvvapXr56++uqrGx5EXFycli5dqnXr1qly5cpmeWBgoC5duqT09HSn+mlpaQoMDDTrXP00vpz3OXWuFhgYqOPHjzuVXb58WadPn76hdvOrk1+/np6estvtTi8AAAAAAIDi6IZCqUmTJmnAgAF5hik+Pj566qmn9M4771x3e4ZhKC4uTp9//rnWrl2r6tWrO21v3LixSpYsqTVr1phlKSkpOnz4sMLCwiRJYWFh2r17t1PIlJCQILvdrtDQ0Dz7DQsLU3p6upKSksyytWvXKjs7W02bNjXrbNy4UZmZmU7t1qlTR+XKlTPrXDm2nDo5YwMAAAAAAEDebiiU2rlzp9q2bZvv9sjISKeg58/Exsbqk08+0Zw5c1S2bFmlpqYqNTVVv//+u6Q/gq6YmBgNGTJE69atU1JSkvr376+wsDA1a9bM7DM0NFS9e/fWzp07tXLlSg0fPlyxsbHy9PTMs9+6deuqbdu2GjBggL799ltt2rRJcXFx6t69u4KCgiRJPXv2lIeHh2JiYpScnKx58+bp3Xffdbr97vnnn9eKFSs0YcIE7du3T6NGjdK2bdsUFxd33ccAAAAAAACgOLqhUCotLU0lS5bMd7u7u7tOnDhx3e1NnTpVGRkZat26tSpWrGi+5s2bZ9aZOHGiOnbsqC5duqhVq1YKDAzUwoULze1ubm5aunSp3NzcFBYWpl69eqlPnz4aM2aMWefQoUOy2Wxav369WTZ79myFhIQoPDxc7du3V4sWLTR9+nRzu4+Pj1atWqWDBw+qcePGeuGFFzRixAgNHDjQrNO8eXPNmTNH06dPV8OGDbVgwQItWrTIXKgdAAAAAAAAebuhhc4rVaqkPXv2qFatWnlu37VrlypWrHjd7RmG8ad1vLy8NGXKFE2ZMiXfOsHBwVq2bFm+2w8ePChfX181bNjQLPPz89OcOXOu2XeDBg3+dI2sJ554Qk888cQ16wAAAAAAAMDZDV0p1b59e7322mu6cOFCrm2///67Ro4cqY4dO962wd0uy5Yt0yuvvGKuBQUAAAAAAADXuqErpYYPH66FCxfqzjvvVFxcnOrUqSNJ2rdvn6ZMmaKsrCy9+uqrBTLQWzF+/HhXDwEAAAAAAABXuKFQKiAgQJs3b9Yzzzyj+Ph48/Y7m82mqKgoTZkyRQEBAQUyUAAAAAAAABQdNxRKSf+3ftNvv/2m/fv3yzAM1a5dm1vjAAAAAAAAcN1uOJTKUa5cOd177723cywAAAAAAAAoJm5ooXMAAAAAAADgdiCUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOVcGkpt3LhRDz/8sIKCgmSz2bRo0SKn7f369ZPNZnN6tW3b1qnO6dOnFR0dLbvdLl9fX8XExOjs2bPX7PfChQuKjY1V+fLl5e3trS5duigtLc2pzuHDh9WhQweVLl1a/v7+Gjp0qC5fvuxUZ/369brnnnvk6empWrVqaebMmTd9LAAAAAAAAIoTl4ZS586dU8OGDTVlypR867Rt21bHjh0zX//73/+ctkdHRys5OVkJCQlaunSpNm7cqIEDB16z38GDB2vJkiWaP3++NmzYoKNHj6pz587m9qysLHXo0EGXLl3S5s2bNWvWLM2cOVMjRoww6xw8eFAdOnTQgw8+qB07dmjQoEF68skntXLlyps8GgAAAAAAAMWHuys7b9eundq1a3fNOp6engoMDMxz2969e7VixQpt3bpVTZo0kSRNnjxZ7du319tvv62goKBc+2RkZOjDDz/UnDlz1KZNG0nSjBkzVLduXX3zzTdq1qyZVq1ape+//16rV69WQECAGjVqpH/84x8aNmyYRo0aJQ8PD02bNk3Vq1fXhAkTJEl169bV119/rYkTJyoqKupWDgsAAAAAAECRV+jXlFq/fr38/f1Vp04dPfPMMzp16pS5LTExUb6+vmYgJUkREREqUaKEtmzZkmd7SUlJyszMVEREhFkWEhKiqlWrKjEx0Wy3fv36CggIMOtERUXJ4XAoOTnZrHNlGzl1ctrIy8WLF+VwOJxeAAAAAAAAxVGhDqXatm2r//73v1qzZo3eeustbdiwQe3atVNWVpYkKTU1Vf7+/k77uLu7y8/PT6mpqXm2mZqaKg8PD/n6+jqVBwQEmPukpqY6BVI523O2XauOw+HQ77//nmffY8eOlY+Pj/mqUqXKdRwFAAAAAACAoselt+/9me7du5t/rl+/vho0aKCaNWtq/fr1Cg8Pd+HIbk58fLyGDBlivnc4HARTAAAAAACgWCrUV0pdrUaNGqpQoYL2798vSQoMDNTx48ed6ly+fFmnT5/Odx2qwMBAXbp0Senp6U7laWlp5j6BgYG5nsaX8/7P6tjtdpUqVSrPvj09PWW3251eAAAAAAAAxdFfKpQ6cuSITp06pYoVK0qSwsLClJ6erqSkJLPO2rVrlZ2draZNm+bZRuPGjVWyZEmtWbPGLEtJSdHhw4cVFhZmtrt7926nwCshIUF2u12hoaFmnSvbyKmT0wYAAAAAAADy59Lb986ePWte9SRJBw8e1I4dO+Tn5yc/Pz+NHj1aXbp0UWBgoA4cOKCXXnpJtWrVMp9uV7duXbVt21YDBgzQtGnTlJmZqbi4OHXv3j3PJ+9Jko+Pj2JiYjRkyBD5+fnJbrfrueeeU1hYmJo1ayZJioyMVGhoqHr37q1x48YpNTVVw4cPV2xsrDw9PSVJTz/9tN5//3299NJL+tvf/qa1a9fq008/1ZdfflnARw0AAAAAAOCvz6VXSm3btk1333237r77bknSkCFDdPfdd2vEiBFyc3PTrl279Mgjj+jOO+9UTEyMGjdurK+++soMhiRp9uzZCgkJUXh4uNq3b68WLVpo+vTpTv3YbDbNnDnTfD9x4kR17NhRXbp0UatWrRQYGKiFCxea293c3LR06VK5ubkpLCxMvXr1Up8+fTRmzBizTvXq1fXll18qISFBDRs21IQJE/Sf//zHDMwAAAAAAACQP5thGIarB1GQDh48qDvvvFPff/+9ateu7erhOHE4HPLx8VFGRsZffn0pm83VI8DVLDmzmfjCx4KJt41m3gsbY2TBz/to2+gC7wM3bqQxsuA7mcM5X+j0tOC7vsB7wI0q0r+0AShyrjfv+EutKXUzli1bpoEDBxa6QAoAAAAAAKA4c+maUlaIjY119RAAAAAAAABwlSJ/pRQAAAAAAAAKH0IpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOZeGUhs3btTDDz+soKAg2Ww2LVq0yGm7YRgaMWKEKlasqFKlSikiIkI//vijU53Tp08rOjpadrtdvr6+iomJ0dmzZ6/Z74ULFxQbG6vy5cvL29tbXbp0UVpamlOdw4cPq0OHDipdurT8/f01dOhQXb582anO+vXrdc8998jT01O1atXSzJkzb/pYAAAAAAAAFCcuDaXOnTunhg0basqUKXluHzdunN577z1NmzZNW7ZsUZkyZRQVFaULFy6YdaKjo5WcnKyEhAQtXbpUGzdu1MCBA6/Z7+DBg7VkyRLNnz9fGzZs0NGjR9W5c2dze1ZWljp06KBLly5p8+bNmjVrlmbOnKkRI0aYdQ4ePKgOHTrowQcf1I4dOzRo0CA9+eSTWrly5S0eFQAAAAAAgKLPZhiG4epBSJLNZtPnn3+uTp06SfrjKqmgoCC98MILevHFFyVJGRkZCggI0MyZM9W9e3ft3btXoaGh2rp1q5o0aSJJWrFihdq3b68jR44oKCgoVz8ZGRm64447NGfOHD3++OOSpH379qlu3bpKTExUs2bNtHz5cnXs2FFHjx5VQECAJGnatGkaNmyYTpw4IQ8PDw0bNkxffvml9uzZY7bdvXt3paena8WKFdf1mR0Oh3x8fJSRkSG73X7Tx64wsNlcPQJczZIzm4kvfCyYeNto5r2wMUYW/LyPto0u8D5w40YaIwu+kzmc84VOTwu+6wu8B9yoQvFLGwBcp+vNOwrtmlIHDx5UamqqIiIizDIfHx81bdpUiYmJkqTExET5+vqagZQkRUREqESJEtqyZUue7SYlJSkzM9Op3ZCQEFWtWtWp3fr165uBlCRFRUXJ4XAoOTnZrHNlGzl1ctrIy8WLF+VwOJxeAAAAAAAAxVGhDaVSU1MlySkYynmfsy01NVX+/v5O293d3eXn52fWyatdDw8P+fr6XrPdvPq9clz51XE4HPr999/z7Hvs2LHy8fExX1WqVMmzHgAAAAAAQFFXaEOpoig+Pl4ZGRnm65dffnH1kAAAAAAAAFyi0IZSgYGBkpTrqXhpaWnmtsDAQB0/ftxp++XLl3X69GmzTl7tXrp0Senp6ddsN69+rxxXfnXsdrtKlSqVZ9+enp6y2+1OLwAAAAAAgOKo0IZS1atXV2BgoNasWWOWORwObdmyRWFhYZKksLAwpaenKykpyayzdu1aZWdnq2nTpnm227hxY5UsWdKp3ZSUFB0+fNip3d27dzsFXgkJCbLb7QoNDTXrXNlGTp2cNgAAAAAAAJA/d1d2fvbsWe3fv998f/DgQe3YsUN+fn6qWrWqBg0apNdff121a9dW9erV9dprrykoKMh8Ql/dunXVtm1bDRgwQNOmTVNmZqbi4uLUvXv3PJ+8J/2xWHpMTIyGDBkiPz8/2e12PffccwoLC1OzZs0kSZGRkQoNDVXv3r01btw4paamavjw4YqNjZWnp6ck6emnn9b777+vl156SX/729+0du1affrpp/ryyy8L9qABAAAAAAAUAS69Umrbtm26++67dffdd0uShgwZorvvvlsjRoyQJL300kt67rnnNHDgQN177706e/asVqxYIS8vL7ON2bNnKyQkROHh4Wrfvr1atGih6dOnO/Vjs9k0c+ZM8/3EiRPVsWNHdenSRa1atVJgYKAWLlxobndzc9PSpUvl5uamsLAw9erVS3369NGYMWPMOtWrV9eXX36phIQENWzYUBMmTNB//vMfRUVFFcShAgAAAAAAKFJshmEYrh5EQTp48KDuvPNOff/996pdu7arh+PE4XDIx8dHGRkZf/n1pWw2V48AV7PkzGbiCx8LJt42mnkvbIyRBT/vo22jC7wP3LiRxsiC72QO53yh09OC7/oC7wE3qkj/0gagyLnevKPQril1uyxbtkwDBw4sdIEUAAAAAABAcebSNaWsEBsb6+ohAAAAAAAA4CpF/kopAAAAAAAAFD6EUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKFOpQaNWqUbDab0yskJMTcfuHCBcXGxqp8+fLy9vZWly5dlJaWds02DcPQiBEjVLFiRZUqVUoRERH68ccfneqcPn1a0dHRstvt8vX1VUxMjM6ePetUZ9euXWrZsqW8vLxUpUoVjRs37vZ9cAAAAAAAgCKuUIdSklSvXj0dO3bMfH399dfmtsGDB2vJkiWaP3++NmzYoKNHj6pz587XbG/cuHF67733NG3aNG3ZskVlypRRVFSULly4YNaJjo5WcnKyEhIStHTpUm3cuFEDBw40tzscDkVGRio4OFhJSUkaP368Ro0apenTp9/+AwAAAAAAAFAEubt6AH/G3d1dgYGBucozMjL04Ycfas6cOWrTpo0kacaMGapbt66++eYbNWvWLNc+hmFo0qRJGj58uB599FFJ0n//+18FBARo0aJF6t69u/bu3asVK1Zo69atatKkiSRp8uTJat++vd5++20FBQVp9uzZunTpkj766CN5eHioXr162rFjh9555x2n8AoAAAAAAAB5K/RXSv34448KCgpSjRo1FB0drcOHD0uSkpKSlJmZqYiICLNuSEiIqlatqsTExDzbOnjwoFJTU5328fHxUdOmTc19EhMT5evrawZSkhQREaESJUpoy5YtZp1WrVrJw8PDrBMVFaWUlBT99ttv+X6WixcvyuFwOL0AAAAAAACKo0IdSjVt2lQzZ87UihUrNHXqVB08eFAtW7bUmTNnlJqaKg8PD/n6+jrtExAQoNTU1DzbyykPCAjId5/U1FT5+/s7bXd3d5efn59TnbzauLKPvIwdO1Y+Pj7mq0qVKn9yBAAAAAAAAIqmQn37Xrt27cw/N2jQQE2bNlVwcLA+/fRTlSpVyoUjuznx8fEaMmSI+d7hcBBMAQAAAACAYqlQXyl1NV9fX915553av3+/AgMDdenSJaWnpzvVSUtLy3MNKklm+dVP6Ltyn8DAQB0/ftxp++XLl3X69GmnOnm1cWUfefH09JTdbnd6AQAAAAAAFEd/qVDq7NmzOnDggCpWrKjGjRurZMmSWrNmjbk9JSVFhw8fVlhYWJ77V69eXYGBgU77OBwObdmyxdwnLCxM6enpSkpKMuusXbtW2dnZatq0qVln48aNyszMNOskJCSoTp06Kleu3G39zAAAAAAAAEVRoQ6lXnzxRW3YsEGHDh3S5s2b9dhjj8nNzU09evSQj4+PYmJiNGTIEK1bt05JSUnq37+/wsLC8nzyniTZbDYNGjRIr7/+uhYvXqzdu3erT58+CgoKUqdOnSRJdevWVdu2bTVgwAB9++232rRpk+Li4tS9e3cFBQVJknr27CkPDw/FxMQoOTlZ8+bN07vvvut0ax4AAAAAAADyV6jXlDpy5Ih69OihU6dO6Y477lCLFi30zTff6I477pAkTZw4USVKlFCXLl108eJFRUVF6YMPPnBqo1q1aurXr59GjRolSXrppZd07tw5DRw4UOnp6WrRooVWrFghLy8vc5/Zs2crLi5O4eHhZvvvvfeeud3Hx0erVq1SbGysGjdurAoVKmjEiBEaOHBgwR8UAAAAAACAIsBmGIbh6kEUlPPnz6t8+fJavny5Wrdu7erh5OJwOOTj46OMjIy//PpSNpurR4CrWXJmM/GFjwUTbxvNvBc2xsiCn/fRttEF3gdu3EhjZMF3ModzvtDpacF3fYH3gBtVZH9pA1AkXW/eUahv37tV69atU5s2bQplIAUAAAAAAFCcFelQqkOHDvryyy9dPQwAAAAAAABcpUiHUgAAAAAAACicCKUAAAAAAJYbO3as7r33XpUtW1b+/v7q1KmTUlJS8qxrGIbatWsnm82mRYsW/Wnbe/fu1SOPPCIfHx+VKVNG9957rw4fPmxuT01NVe/evRUYGKgyZcronnvu0WeffZZnWxcvXlSjRo1ks9m0Y8eOm/moAPJBKAUAAAAAsNyGDRsUGxurb775RgkJCcrMzFRkZKTOnTuXq+6kSZNku86H7Bw4cEAtWrRQSEiI1q9fr127dum1115zeuJ6nz59lJKSosWLF2v37t3q3Lmzunbtqu3bt+dq76WXXlJQUNDNf1AA+XJ39QAAAAAAAMXPihUrnN7PnDlT/v7+SkpKUqtWrczyHTt2aMKECdq2bZsqVqz4p+2++uqrat++vcaNG2eW1axZ06nO5s2bNXXqVN13332SpOHDh2vixIlKSkrS3XffbdZbvny5Vq1apc8++0zLly+/qc8JIH9cKQUAAAAAcLmMjAxJkp+fn1l2/vx59ezZU1OmTFFgYOCftpGdna0vv/xSd955p6KiouTv76+mTZvmuuWvefPmmjdvnk6fPq3s7GzNnTtXFy5ccHpye1pamgYMGKCPP/5YpUuXvi2fEYAzQikAAAAAgEtlZ2dr0KBBuv/++3XXXXeZ5YMHD1bz5s316KOPXlc7x48f19mzZ/Xmm2+qbdu2WrVqlR577DF17txZGzZsMOt9+umnyszMVPny5eXp6amnnnpKn3/+uWrVqiXpjzWs+vXrp6efflpNmjS5vR8WgInb9wAAAAAALhUbG6s9e/bo66+/NssWL16stWvX5rnOU36ys7MlSY8++qgGDx4sSWrUqJE2b96sadOm6YEHHpAkvfbaa0pPT9fq1atVoUIFLVq0SF27dtVXX32l+vXra/LkyTpz5ozi4+Nv46cEcDWulAIAAAAAuExcXJyWLl2qdevWqXLlymb52rVrdeDAAfn6+srd3V3u7n9cU9GlSxen2+yuVKFCBbm7uys0NNSpvG7duubT9w4cOKD3339fH330kcLDw9WwYUONHDlSTZo00ZQpU8y+ExMT5enpKXd3d/MKqiZNmqhv3763+xAAxRZXSgEAAAAALGcYhp577jl9/vnnWr9+vapXr+60/eWXX9aTTz7pVFa/fn1NnDhRDz/8cJ5tenh46N5771VKSopT+Q8//KDg4GBJf6xTJUklSjhfo+Hm5mZeafXee+/p9ddfN7cdPXpUUVFRmjdvnpo2bXoTnxZAXgilAAAAAACWi42N1Zw5c/TFF1+obNmySk1NlST5+PioVKlSCgwMzHNx86pVq+YKsK40dOhQdevWTa1atdKDDz6oFStWaMmSJVq/fr0kKSQkRLVq1dJTTz2lt99+W+XLl9eiRYuUkJCgpUuXmn1cydvbW9IfT/G78mouALeG2/cAAAAAAJabOnWqMjIy1Lp1a1WsWNF8zZs374baqVatmkaNGmW+f+yxxzRt2jSNGzdO9evX13/+8x999tlnatGihSSpZMmSWrZsme644w49/PDDatCggf773/9q1qxZat++/e38iAD+BFdKAQAAAAAsZxjGLe9z/vx5paWl5Vpj6m9/+5v+9re/5dtO7dq19dlnn113v9WqVbup8QK4Nq6UAgAAAAD8Ja1bt05t2rTJd+FzAIUboRQAAAAA4C+pQ4cO+vLLL109DAA3iVAKAAAAAABYZuPGjXr44YcVFBQkm82mRYsWOW0fNWqUQkJCVKZMGZUrV04RERHasmXLn7Y7ZcoUVatWTV5eXmratKm+/fZbp+0XLlxQbGysypcvL29vb3Xp0kVpaWl5tnXq1ClVrlxZNptN6enpN/tR8ScIpQAAAAAAgGXOnTunhg0basqUKXluv/POO/X+++9r9+7d+vrrr1WtWjVFRkbqxIkT+bY5b948DRkyRCNHjtR3332nhg0bKioqSsePHzfrDB48WEuWLNH8+fO1YcMGHT16VJ07d86zvZiYGDVo0ODWPij+FKEUAAAAAACwTLt27fT666/rsccey3N7z549FRERoRo1aqhevXp655135HA4tGvXrnzbfOeddzRgwAD1799foaGhmjZtmkqXLq2PPvpIkpSRkaEPP/xQ77zzjtq0aaPGjRtrxowZ2rx5s7755huntqZOnar09HS9+OKLt+9DI0+EUgAAAAAAoFC6dOmSpk+fLh8fHzVs2DDfOklJSYqIiDDLSpQooYiICCUmJkqSkpKSlJmZ6VQnJCREVatWNetI0vfff68xY8bov//9r0qUIDIpaBxhAAAAAABQqCxdulTe3t7y8vLSxIkTlZCQoAoVKuRZ9+TJk8rKylJAQIBTeUBAgFJTUyVJqamp8vDwkK+vb751Ll68qB49emj8+PGqWrXq7f9QyIVQCgAAAAAg2XgVulcx9uCDD2rHjh3avHmz2rZtq65duzqtD1UQ4uPjVbduXfXq1atA+8H/IZQCAAAAAACFSpkyZVSrVi01a9ZMH374odzd3fXhhx/mWbdChQpyc3PL9SS9tLQ0BQYGSpICAwN16dKlXE/Su7LO2rVrNX/+fLm7u8vd3V3h4eFm+yNHjrzNnxASoRQAAAAAACjksrOzdfHixTy3eXh4qHHjxlqzZo1T/TVr1igsLEyS1LhxY5UsWdKpTkpKig4fPmzW+eyzz7Rz507t2LFDO3bs0H/+8x9J0ldffaXY2NiC+mjFmrurBwAAAAAAAIqPs2fPav/+/eb7gwcPaseOHfLz81P58uX1z3/+U4888ogqVqyokydPasqUKfr111/1xBNP5NvmkCFD1LdvXzVp0kT33XefJk2apHPnzql///6SJB8fH8XExGjIkCHy8/OT3W7Xc889p7CwMDVr1kySVLNmTac2T548KUmqW7durrWocHsQSgEAAAAAAMts27ZNDz74oPl+yJAhkqS+fftq2rRp2rdvn2bNmqWTJ0+qfPnyuvfee/XVV1+pXr165j6tW7dWtWrVNHPmTElSt27ddOLECY0YMUKpqalq1KiRVqxY4bT4+cSJE1WiRAl16dJFFy9eVFRUlD744ANrPjTyZDMMw3D1IIorh8MhHx8fZWRkyG63u3o4t8RWzBfhK4wsObOZ+MLHgom3jWbeCxtjZMHP+2jb6ALvAzdupGHB+hZzOOcLnZ4WfNcXeA+4UZb80sbEFz78tp6v4OBgjR49Wv369XP1UJCH6807WFMKAAAAAAD8ZSQnJ8vHx0d9+vRx9VBwi7h9DwAAAAAA/GXUq1dPu3btcvUwcBtwpRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcC50DAAAAAFCs2Vw9AORiuHoAluBKKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUOo2mDJliqpVqyYvLy81bdpU3377rauHBAAAAAAAUKgRSt2iefPmaciQIRo5cqS+++47NWzYUFFRUTp+/LirhwYAAAAAAFBoEUrdonfeeUcDBgxQ//79FRoaqmnTpql06dL66KOPXD00AAAAAACAQsvd1QP4K7t06ZKSkpIUHx9vlpUoUUIRERFKTEzMVf/ixYu6ePGi+T4jI0OS5HA4Cn6wKHb4sSqmrJj4CwXfBW6MFX+PXGDiCyVL/g1xvuC7wA3iL/liiVkvppj4YuyvPfk5/0YxDOOa9QilbsHJkyeVlZWlgIAAp/KAgADt27cvV/2xY8dq9OjRucqrVKlSYGNE8eXj4+oRwCWY+GLJ503mvbh60+dNVw8BrjCAc744YtaLKSa+GCsak3/mzBn5XON3FEIpC8XHx2vIkCHm++zsbJ0+fVrly5eXzWZz4cgg/ZHkVqlSRb/88ovsdrurhwOLMO/FF3NfPDHvxRPzXnwx98UT8148Me+Fi2EYOnPmjIKCgq5Zj1DqFlSoUEFubm5KS0tzKk9LS1NgYGCu+p6envL09HQq8/X1Lcgh4ibY7Xa+xIoh5r34Yu6LJ+a9eGLeiy/mvnhi3osn5r3wuNYVUjlY6PwWeHh4qHHjxlqzZo1Zlp2drTVr1igsLMyFIwMAAAAAACjcuFLqFg0ZMkR9+/ZVkyZNdN9992nSpEk6d+6c+vfv7+qhAQAAAAAAFFqEUreoW7duOnHihEaMGKHU1FQ1atRIK1asyLX4OQo/T09PjRw5MtctlijamPfii7kvnpj34ol5L76Y++KJeS+emPe/JpvxZ8/nAwAAAAAAAG4z1pQCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAA8JfAkshA0UIohSKNv7QAAACAv77Vq1dLkmw2G//GB4oQQikUacnJya4eAgAL8Y9UoHi5cOGCq4cAwALbt29XZGSk/v73v0simAKKEkIpFFlz5sxR//795XA4lJ2d7erhwEJHjx7VmjVrdOzYMVcPBRaz2WySpIsXL7p4JLDS0aNHtXnzZlcPAxbbv3+/XnvtNc2YMYNfToEirlq1apoyZYrmzZun559/XhLBVHHDXBddhFIoskJDQ/XZZ5/Jbrfr5MmTrh4OLJKcnKz27dvro48+0g8//ODq4cAiVwbPCxYsUGRkpM6cOePCEcEqFy5cUHR0tEaMGKGvvvrK1cOBRXbv3q3w8HAdP35cPj4+ZiCN4olfVos2wzBUrlw5PfXUUxo7dqzmzZun4cOHSyKYKg7ym18uOig6CKVQZDVq1EhVq1bVrl271KpVK3322WeuHhIKWHJysu6//35FRkbq5Zdf1gMPPODqIcEC2dnZKlHij7/OVq1apdWrV+vrr7/WU089RTBVDHh5eWnMmDFyOByaNGmSNmzY4OohoYD9+OOPCg8PV8+ePfXee++pc+fOuerwS2rRlTO3p0+fNv/TkVCyaMuZ802bNiklJUVly5bVG2+8oZdfflkSwVRRZhiGbDabNmzYoJdeeknPPvus3nrrLUlSiRIlmPciglAKRV5mZqYaNmyoMWPGaPHixa4eDgrIb7/9pmeffVZPPfWUxo0bp/r165vbzp07p/T0dPM9f4EVLTmB1JAhQzR06FB5enrqgQce0MaNG9WrVy85HA4XjxAFJSsrS5LUsmVLvfvuuzp48KDee+89gqkiLCsrS9OnT1eHDh00duxY2e12SdKpU6e0Y8cOzZ07VydOnCCkKMJsNpsWLVqkVq1aqVWrVnr00Ud19OhRVw8LBahEiRJasmSJHnroIZUrV07PP/+8evXqpalTp2rw4MGSCKaKKpvNpoULF+rhhx9WRkaGSpYsqQ8++EAPPvigsrOz+a4vItxdPQCgoDVu3FhDhw7V+++/r/j4eEnSI4884uJR4XY7d+6cMjIyFBERYZZt2rRJX331lT766CMFBgaqa9euiouL4y+wImj9+vWaPXu2Fi5cqPvvv1+SNG3aNH300Ufq27ev/vvf/6ps2bIuHiVul0OHDsnhcKhy5cry8/OTJIWFhendd9/V3//+d02aNEmSuFqyCHJzc9Phw4fl5uYm6Y9fWD7//HMtWrRICxculKenp9zd3fXll1+qcePG5v+y468vZy6/++47DRgwQHFxcfL399f777+vtm3b6pNPPlGDBg1cPUwUgIsXL+rjjz/WwIEDzaujTp48qSZNmmj48OHy8vLS2LFjzWCKc77oOHLkiIYPH6433nhDcXFxOnjwoObOnavatWub/ykpiXn/i+NKKRQpOf9D8ssvvyglJUU//vijJKlJkyZ65plndO+99yo+Pp4rpoqgEydO6Oeff9a5c+eUlZWlqVOnatCgQVq1apXatGmjO++8U6+++qqWLFni6qGiAPz222/Kzs5WtWrVzLJ+/frp8ccf16pVqzRgwABu5Ssifv31V9WoUUONGjVSp06dFBMTo0WLFunYsWNq2bKlZs+erUOHDmnKlClas2aNq4eL28gwDF2+fFmBgYE6fvy4PvjgA7300kt67rnn5OnpqY8++kh79uxRw4YN9cwzz0jitq6ixGazaefOnfrll18UFxenkSNH6plnntG3336rkiVLqmfPntq9e7erh4kC4O7url9++cXpqvcKFSooOjpaUVFReuutt5wWP0fRcfr0aRmGobi4OB05ckStWrXSY489punTp+v/tXfn4Vzl/f/Anx9bEsYa2jBCMS0oFBWpJGnf95o02mWKdu3aKNrQLC3TNEmEFsk0ymhXaLPNjJApJIzI+vr90df55W7u+5675NNHr8d1dV15n3P0+lynz/Y87/N6A0BsbCwAPu+SjkMp1mzUJ+QREREYPnw4+vfvj1mzZsHd3R0AYGVlJQRTa9aswcmTJ8VbMGtUZmZmGDduHEaNGoXOnTvD3d0d48aNQ0BAAAIDA7F27Vpoa2tz8/Nm4M3p+fV/b9euHTQ1NXH79m1hm7y8PGbNmgVtbW0kJydjzpw5qKioaPJ6WeOSl5dH3759AQA2NjbIyMiAt7c3OnXqhMmTJ+P+/fvw8PBAZmYmjh49ikuXLom5YtaYZGRk4OHhAQD45ptvcPLkSfj6+mLdunUYO3YstLW10atXL8jIyKCmpkbM1bLGVFFRARcXF4wcORI5OTnCeKtWrXDlyhW0aNEC06ZNw927d8VYJfsQpKWlMWzYMGRnZzc4v+rq6rCwsEDnzp0RExODp0+firFK1pjqP9+pqqpCQ0MDUVFRsLGxgbOzM/bu3QsASE1NxeHDhxt89mOSiW/fY82GSCTC+fPnMWXKFPj4+GDgwIGIiIjA8uXLUVJSgu+//x5WVlYQiUTYtm0b/Pz84OTkhFatWnG63kwEBQWhf//+qK6uhq2tbYNZM0pKStDU1ISGhob4CmTv7c2m5rW1taitrYWcnByMjY2hrq6O3bt3o127drCwsAAAlJeXw9zcHBYWFvjpp5+QkJDQ4BZPJnnU1dURGhqKkSNH4tKlS/jxxx+hpqaGU6dO4d69e3Bzc4O5uTmSkpKQlJSEqqoq9OrVCy1bthR36ewd1V90qr81R1dXF2FhYSAiSEtLQ1FRscH+eXl5MDQ05JWZmpmWLVsiNjYWEydOxM2bN5GTk4P27duDiIRgqkuXLpg/fz7i4uIgJycn7pLZO6h/vufl5aGsrAwqKipo3bo1hgwZgmPHjiE4OBiurq4wNzcHAOTn52P8+PFYsmQJ36Yv4erP/fXr11FUVARLS0soKSmBiDBq1ChMnDgRgYGBwv7ffvst/vjjD3To0EGMVbPGICLuCMeaiYKCAkyZMgVOTk5wd3dHQUEBLCwsYGxsjJSUFDg6OuLIkSMAgMTEROjo6KBNmzZirpq9q/o3rsePH+PVq1eoq6tD586dG2x70+rVq3HixAn8/PPP/ObVDGzbtg0JCQmora3FvHnz4OzsjKdPn6Jv377Q0tKCo6MjunbtCn9/f6iqquKHH35A+/btsWjRIqxZs0bc5bP/0fPnz5GVlQUFBQXhef78+XMMGjQIr169QkREBDp27AgAePr0KbKysnD69GmkpKTA19dXOIZJnvrX84SEBCQkJKCoqAgDBgxAnz590KJFiwb7lpaWYtu2bQgKCkJ8fDyfdwlXf+6JCEQkXJDIyMjAgAEDYGBggOPHj0NLS0vYt7y8HM+ePYO+vr6Yq2fvov48nj59GitWrEBdXR2ICA4ODli/fj0SExOxfPlyKCoqQlNTE3Jycrhw4QJu3rwJY2NjcZfP3kP9uT916pTQM27atGno2LEjbt++DQcHBwwaNAjjxo1D69atERYWhsOHD+PKlSvcS645IMYkWF1dHRERZWRkEBHRnj176MGDB/T06VMyMTEhNzc3KisrI3d3dxKJRDRy5EhxlssaSf15P3XqFHXq1Il0dHTIwMCAXFxcqKysrMG+V69eJQ8PD1JXV6e7d++KoVrWGGpra4W/b9q0iTQ1NWnhwoXk4uJCIpGI9uzZQ0RET58+penTp1P37t3J0NCQBgwYQOXl5URE1KdPHzp8+LBY6mfv7uHDh2Rvb0+DBw+mmTNnNtj2/Plz6tmzJxkbG1NaWtpbx1ZUVDRVmewDCg0NJUVFRerXrx9ZWVmRSCSipUuX0u+//y7ss3//fpo1axZ16NCB7ty5I8ZqWWOof5+PiYmhRYsW0eDBgyk4OJhu3bpFRERpaWnUvn17sre3p2fPnjU4hkm2S5cukaKiIvn7+1N1dTVt2bKFZGRkhPfvq1evUkBAADk5OZGrqyulpKSIuWLWWK5du0aqqqr03XffCZ/d6l2+fJlsbW2pTZs2ZGJiQn369KGkpCQxVcoaG4dSTOKdPn2ajIyM6P79+8KYv78/OTk5UX5+PhER7du3j3r06EEWFhaUk5MjrlJZI4qLi6OWLVvSgQMH6JdffqGwsDDq2LEjWVtbC19ET5w4QV27diV7e3u6d++emCtmjeH333+nbdu20S+//EJERJWVleTj40NSUlIUEBBARERVVVX0119/UV5ennDcqlWrSFtbu8GXWPbxS0lJIXV1dVq1alWDc5eSkiK8vtcHU507d6b09HQi4i+nzUlmZiZ16NCBDh48KJzX48ePk4aGBnl5eVFNTQ3l5+fTrFmzaOHChX8bTjLJFB4eTvLy8jRz5kxydnambt26ka2tLZ07d46IiNLT08nAwIDMzMyE1wMmueqf34sWLaKvvvqKiIiePHlC+vr6NHfuXGG/yspKYf+ampqmL5Q1uvpzv2PHDurfvz9VVFQIY2+e47KyMsrJyaEnT55QaWmpWGplHwaHUkzi1NbWCi9UT548IWdnZwoMDGywj5ubG5mZmQk/L126lNatW/fWLBomuTZu3PjWzLc//viDPv/8cxo7dqwwdu3aNeEqKpMsXl5e9Ndffwk/R0dHk0gkojZt2tCVK1eE8draWtq6dStJS0vT/v37G/yOe/fukYuLC7Vt25ZnT0iY3Nxc6ty5M3l4eDQY37p1K8nKytKmTZvoxYsXRPQ6mOrVqxdpa2tTZmamGKplH0pKSgrp6elRUlJSg7Dx2LFjJCUlRfHx8UREVF5e/taVdSa5nj59Sj169KBdu3YJY5cvX6Zp06Y1mCHx6NEj6tq1K2VlZYmpUtbYZs+eTQcPHqSioiJq06YNzZkzR3juh4eHU0REBFVXV4u5StYY6s/ro0ePiIjI1dWVbGxshO1vzpK/d+8eFRYWNm2BrMnw6ntMYvz666+oqamBlJQURCIRrly5grVr16K6uhqDBg0C8LrxMQAMGTIExcXFGDFiBKZNm4bg4GBMmDABrVq1EudDYI2A/q8N3u+//46srCxhvKamBnp6evD29saDBw+ElXmsra3RunVrcZTK3kNWVhYSExMhLy8vjPXs2ROenp7Iz8/HH3/8AQBCnxFPT0/4+Phg/vz5OH36tHDMF198gTFjxuDSpUswMzNr6ofB3sP169ehqKiIuXPnCg2rt23bhk2bNmHmzJnw9vbG/v37UVxcDDU1NURGRsLU1FTMVbP3UV5ejsLCQsTFxeHJkycoLS2FgoICcnJyUF5eDpFIhMrKSgDApEmTYGJighs3bgB43QSbm9k3H3V1dfjzzz+hra0tjPXt2xezZs1CYWEhHj16BADo1KkTbt++DV1dXXGVyt5D/We6Fy9eCGMKCgrYsWMHunfvjtGjR2Pfvn3Cc//kyZO4detWg1V4meSqXzW9W7duyMjIgIODAx48eIDo6GgAEPrIlZaW4ptvvkFSUpIYq2UfEodSTCIcPXoU3t7eKCkpEcby8/Px008/IS4uDunp6QBeLxkLAL169cLKlStRUVGBv/76C/Hx8dwAUUJVV1ejrKwMjx49wosXL4QG5uPHj0dJSQl+/PFHAK+XCQcANTU14csLk0wDBgzAr7/+iosXL0JGRgYhISEoKSmBmpoavLy8MHfuXHz55Zc4e/as0ARXJBJh6dKlOHLkCIYOHdrg902bNg1GRkZiejTsXV2+fBmlpaXo2LEjpKSkUF1dDTU1NYSFhSEoKAj79u3D6tWrsXv3brx69QoaGhqIiYmBgYGBuEtn7yA9PR1z585Fnz594OTkBFNTU8ydOxdlZWWYN28eZs2ahczMTKG5eVVVFVq0aAFlZWUxV84aQ33IUFNTAwCQlZWFjo4Onj59CiISgul+/fpBQ0MDZ8+eFY6VlZVt+oLZe6t/7z5//jy+/PJLxMTEAADWrl0LbW1tlJeXw9fXFzIyMqipqcGGDRsQHx+PadOm8TlvJnJzcxEdHQ1/f38YGhrCwsIC9vb22LZtm/AcLy0thZ+fH0JCQvD555+LuWL2wYhvkhZj/139tM3S0lJ68uQJERFlZWVRVVUVERFduHCB2rRpQ+PHj/+3PYN4Or/kysjIoHnz5lGXLl1ITU2NtLW1acuWLZSRkUFFRUU0ZswYcnJyoqNHjxLR615Cy5cvpx49elBRUZGYq2fvYvr06Q1uvX327BlJS0vTsGHDhP4BxcXFNH/+fJKVlaWzZ88S0ds9hHhqv2Srq6ujFStWUOfOnamoqEjoKfGv53nixIlkZ2cnvCcwyZScnEw6Ojrk5uZGhw4dokePHpGXlxcZGBhQp06daOvWrTRt2jQyNDSk2NhYunz5Mq1atYo0NDTot99+E3f57D292dR83bp19PjxYyIicnd3J1VVVYqLi2vw3HdxcaF169aJpVbWuEJDQ6lly5a0bds24Rb76upqunDhAunr65Ouri45OTnRkCFDSFNTk2/Db0bu3LlDzs7O1KNHjwYNyy9dukRTp04lZWVl6tKlC/Xo0YO0tLT43DdzHEqxj1Z9IJWZmUlnzpwhoterMFlYWNDOnTuFLyHh4eHUvn17cnV1pQcPHgjHc/NDyZacnEwdOnSgGTNm0K5duyg0NJRmzJhBMjIyNHr0aMrJyaHMzEwaN24c6enpkaGhIdnb25Oqqiq/cUmo6upqGjVqFC1btoyIiL755hu6ffs23bx5k7S0tGjUqFFUUlJCRK+DqQULFpC8vDyFhoaKs2zWSB4/fkznz58XAsXQ0FASiUT0448/EtHrL671X0xra2upsrKS5syZQ8uXL+cQUoIlJyeTgoICrVix4q3zePz4cbK0tCQrKys6fPgwzZw5k1q2bElGRkZkamrKr/XNyKlTp0hJSYm+/vrrBp/lxo0bRyoqKrRx40YKDAykJUuWkLKyMj18+FCM1bLGkJqaSnp6ehQcHPzWOBFRfn4+rVq1itzd3WnHjh3cL7CZOXnyJFlZWVHLli3p4sWLDbbl5ubSxYsXafXq1fTNN9/wxYdPAIdS7KP25MkT0tDQIBMTEzpx4gRVVlbShAkTqHfv3hQQECAEU2FhYdS+fXtyc3Oj5ORkMVfN3lf9l5SVK1e+taT77t27SVFRkaZPn05ERDk5OZSQkECenp60b98+YfUtJnkqKirIzc2N7OzsaOjQoaSsrEy5ublERHTz5k1SV1d/K5iaPHky9e3bV5xls0ZQV1dHw4YNIyMjI4qIiKCqqiqqrKykESNGkKysLEVFRTXYv7a2llauXElt27bl57wEy87OJg0NjQaLU9TV1TUIpwIDA0ldXV344nr//n16/PgxFRQUNHm97MN48OABtWvXjg4ePPi325cvX059+/YlIyMj6t+/P929e7dpC2QfxJUrV8jAwIBevnxJlZWVtG/fPurXrx+1atWKnJ2dxV0eawJnzpwhKysr6t27N12/fl0Y5xV0Pz0iIu4Uxz5ecXFxcHBwgIWFBVq3bo2vvvoKjo6OcHNzw4MHDzBlyhS4ublBVlYWp0+fxuTJk+Hq6ort27dDTk5O3OWzd5CZmQkzMzNMmjQJQUFBAF73HaitrRX6Rm3duhUrV67E5cuX0adPH3GWyz6Adu3aobi4GN7e3li2bJkwfuvWLTg5OcHOzg7ff/89lJSU8PLlS7Rs2VJohskkT11dHaSkpFBSUoLRo0ejrKwMq1atgouLC+7evQsPDw8kJCRg8eLF6N27NwoKCvDrr78iKiqKG9hLuKysLIwbNw46OjpYtmwZbG1thW30f/1mAKBPnz7Q1NREWFiY8P+FNR+XLl2Ch4cHzp8/j9atW0NaWvqt81xWVoaamhpIS0tDSUlJjNWyxpKRkYGRI0dCS0sLz549Q8eOHWFkZITRo0ejV69eCA4OxuzZswE0fD1gkqf+/GVmZqK8vBzl5eWwtrYGAJw5cwb+/v5o0aIFvL290bNnTzFXy8SB39XZR83Ozg4zZsxAdXU15OXlsXPnTly8eBGBgYEwNTXFDz/8gMDAQFRXV2PEiBE4ceIE5s+fz4GUBEtLS0NFRQVUVVWRkZEB4PXqHDIyMkKj02XLlsHQ0BBRUVEAwKuwNBNVVVW4desW8vLyYGpqiujoaISEhAjbe/bsiejoaMTHx2PYsGEoLy9Hq1atICUlJfzfYJIlMzMTP/zwAwoKCvDZZ58hLCwM8vLy2LhxI86dOwczMzMEBwdj8eLFCAoKwtSpU+Hn54eKigokJCRwICXh9PT0cOzYMVRVVWHTpk349ddf/3Y/GRkZKCgoAAAHUs1Qbm4uUlNToaysDGlpadTW1grnOTExEdnZ2VBUVISKigoHUhKq/nMaEQnN7PX09ODj4wMDAwOMHj0avr6+2LZtG6ysrNC/f3+oq6sLx3MgJbnqA6lTp05h0KBBcHZ2xsiRI9G/f39kZWVh6NChWLBggfA+cPXqVXGXzMSA39nZR+Nfv1TWL/s8evRodO/eHXPmzIGGhga2bNmC2NhYBAYG4osvvsBPP/2E3bt3o7q6GkOHDoWhoaE4ymeNxNnZGYcOHcLRo0exZ88eIZgC/v+HEmlpadTU1KC2trbBOJM8bz7v5eTk0LNnT1RVVSE2NhYAsH//foSGhgr79OjRA+Hh4WjZsiXk5eWFcf6iKpm+++47zJgxAxEREXj+/DmUlZURGRkJBQUFeHt74+zZszAwMMCOHTtw//593LlzB9euXcORI0dgYmIi7vJZIzA0NERAQABEIhE2bdqEhIQEAK9f1+vq6pCbm4uWLVti4MCBAPgiRHPUr18/6OvrY8OGDSgpKRGCKQDYu3cvfvrpJ77wIMHqQ4mLFy9izpw5cHR0REBAAEpKSuDi4oLg4GCsX78eBgYGqKurg7e3N1JTU/miQzMhEomQkJCA6dOnY/Xq1QgPD8fp06fx7NkzuLi4IDc3F8OHD4ebmxuePn0Kf39/vHr1Stxls6YmnrsGGWuovql5dnY2hYWFNdiWn59PnTp1or1791J+fj6NGjWKbG1t6ezZs1RZWUljx44lBwcHXm1Ngr18+ZIKCgooNjZW6CEUFRVFOjo6tHDhQsrIyBD2rampodTUVLKzs6Nz584REd97Lqnqn/dEr/uIxcbG0rNnz6iwsJCIXvcL69+/P/Xr149Onjz5X38Hk0xLliwhDQ0NCgoKEs59SUkJ9evXjywtLSk8PJwbmX8C0tPTafDgweTo6Ejx8fHCuJeXF3Xr1o1ycnLEWB1rDPXv1bdu3aLDhw/Tnj176ObNm0REtGbNGrKysiJ3d3cqKCig1NRUWrVqFWlqanJT82YgPDyclJWVaebMmbR27VpSVlam2bNn0+3bt4V9zpw5Q9OnT+eV1pqBvLw8+vPPP4Wfd+3aRQ4ODg0WoaqoqKBOnTqRo6OjMHbmzBlh9U32aeFQin00srOzSV1dnUQiEQ0ZMoROnDhBaWlpREQUGRlJffr0ofz8fHr48CGNGjWK7OzsKCwsjKqqqigvL0/M1bN3lZaWRtOmTaNOnTqRvLw8KSkp0aRJkyg3N5diYmJIW1ubFi5c2KCZsZeXF1laWvJ5l2BvBoleXl6kp6dHampq1KFDB5o0aZKwPHBOTg4NGDCA+vfvT0eOHBFXuewDeDNoWrhw4b8NpmxsbCgkJIRXVP0EvBlM3blzh7Zt20aKiooNlgtnki00NJTU1NRo+PDhZGZmRmZmZrRp0yaqqakhb29vsrCwICkpKTI1NaXPP/+cw4lmIDk5mQwMDCgoKEgYU1FRoc8++4zGjh0rLFAUGhpKX3/9NT169EhcpbJGcOfOHZKSkqLo6GhhzN3dnUxMTISf6xcxunjxIrVv355SUlKavE72ceFQin00srKyqEePHtSrVy8yNzen2bNnk66uLgUFBdGJEydo6NChwsyYBw8e0IABA8jJyYnKysrEXDl7V8nJyaSjo0Nubm506NAhevToEXl5eZG+vj4ZGxvT77//TtHR0cKMqby8PNq4cSMpKSnxKovNxN69e0ldXZ1iYmIoNzeXAgMDafDgweTg4ED3798notdX3Lp3707z588Xc7XsfaWmptLq1aspJSWFnjx50mDbwoULSU1NjYKCgoSV1UpKSqh79+40YMAA+uuvv8RRMmti6enpNHToUGrdujXJyso2mEnBJFtKSgq1adOGAgMDiej1l1d5eXlavnw5Eb2e+VpSUkKRkZF08+ZNvvDUTCQkJNDatWuprq6OsrOzSU9Pj9zd3ennn38mKSkpmjZtmhA8v3r1SszVsveRlJRESkpK5Onp2WD8+vXrpKmpSfv27WswfunSJdLX16fffvutKctkHyEOpdhHJT09nUaNGkUjRoygsLAwCg8PJzs7OxoxYgSJRCKysrKiyspKInr95Yan80uu5ORkUlBQoBUrVrx1a86JEyeoW7duZGlpSWVlZRQSEkJ6enrUuXNnUlBQ4C8pzUD9su8TJkygr7/+usG2qKgosrGxIW9vb2FGVWFhId+qJ+FKSkpIX1+fRCIR9ezZkzp06EBff/11g6vn69evp9atW1NwcDDl5+cTEVFpaSllZWWJq2wmBqmpqTRs2DAhmGbNQ2hoKFlbWxMR0e+//066uro0Z84cYfu9e/fEVRprZG/Ohi4sLKTU1FSqrq6mMWPG0IwZM+jly5dERGRpaUlSUlI0Z84cDqQkXEpKCikoKJC3t3eD8aysLKqtraWFCxdS7969ac+ePUT0unXH6tWrqUuXLsKFKPbp4s6w7KNiaGiILVu2oLKyEoGBgTAxMcGZM2fg5eUFZ2dnLFiwAHJyciAiGBsbo127duIumb2DnJwcODg4wNnZGVu2bIGMjEyDFVnGjRuH+fPn48GDB/jxxx8xduxYrFmzBq9evcK1a9dgYWEh5kfA3lf9iopEhNzc3Abbhg4dCjMzM4SGhqKurg5EBHV1dUhJSQnNb5nkadWqFby8vKChoQFNTU34+vriwYMH8Pb2hpGREYYMGQJbW1vo6enB398fx48fx/Pnz6GkpARdXV1xl8+akLGxMUJDQ2FqairuUtg7ysnJwbfffouDBw8iPj4eACArKwstLS3k5OSgb9++cHR0xP79+wEA8fHxOHHiBP78809xls3eQ3V1tbAQQVlZGYDXi5moq6vD2NgYVVVVyM3NhaWlJRQUFFBTUwNzc3McPHgQnp6eaNGihTjLZ++hqKgIkydPhq6uLtatWyeM+/j4YMSIEairq8PcuXNhaWmJDRs2QF9fH/b29jhw4AAOHz4MDQ0N8RXPPgocSrGPjrGxMfz9/QEACxcuRFJSEqytrREVFYUpU6YA4NXWJF1tbS309fVRWVkpLAH+ZkgBAK6urrCwsMC5c+cAALNmzUJKSgq6du0qtrrZu/t3KycZGhri+vXrSE5ObjDeo0cPqKqqoqKiosHzXVpa+oPWyRpfeno6zp49CykpKUydOhVbtmxBdHQ0ioqKcP78eWRkZMDLywtaWlrw8PBAcXExHj58iKCgID7fnzBZWVlxl8DeUUpKCvr06YPg4GCsWLECM2fORGRkJLp27Ypz586hY8eOGDVqVIPneEhICJKSkqCgoCDm6tn/KioqCnV1dZCVlYVIJEJUVBScnJzQt29fDB8+HA8ePAARoaysDM+fP0dqaiouX76M9evXIzo6GqNGjYKBgYG4HwZ7D3V1dRg6dChkZWWxcuVKAICfnx927NiBrVu3QkZGBp07d8aaNWvwyy+/YPbs2Zg3bx5u3LjBqyyy18Q4S4ux/+jfrcTDmod/d37fnPJtZ2dHkyZNEkd5rBG9edvdrVu36Pbt23Tjxg1hrFevXtSpUyeKj4+np0+fUmlpKdnb29Po0aPFUS5rRElJSSQSiSggIEAYq6yspH379pGUlNRb0/wfP35Md+7coWXLlnGzW8YkUP2t+cuXL6eXL1/SxYsXqU2bNuTk5ERERN988w3JysrS9u3b6fHjx5SZmUnLli0jVVVVvl1TAt25c4f09PSEz2r37t0jaWlp8vLyolWrVtHAgQNJSUlJWEH3p59+IlVVVerYsSO1b9+eEhMTxVk+a0TPnj2jTZs2kampKdnY2JCGhgbFxcWJuywmIURE/zctgbGPUEZGBjw8PFBYWIhdu3bB2tpa3CWxRpSRkYFFixaBiLBmzRrY2NgAeH3FJS8vD3PmzMH48eMxffp0EBHPkJNAb543Ly8vnDx5Eq9evUJlZSWcnZ2xf/9+yMjIwNHREdnZ2aiuroaWlhZqampw+/ZtyMrK8rmXUElJSbCxsYG7uzs2b97cYFtlZSW+//57LFiwAN7e3lizZg0AoKamBjIyMuIolzH2nnJycmBubg57e3uEhIQI45aWliguLsatW7cgIyODEydOYP78+dDS0oKCggJEIhF++OEHnjEhgV6+fInDhw/ju+++g4mJCXr37o38/HysXbtW2Gfu3Lk4evQobt++jU6dOuHRo0fCbX3a2tpirJ41hjc/o+Xl5eH7779HUFAQrK2thdeB2tpanvnM/iMOpdhHLzU1FWvWrIGvry86dOgg7nJYI3szmFq9ejVsbW0BAMuXL0d0dDTOnDnDvcOagYCAAGzYsAGRkZGQl5dHYWEhJk2aBEtLS+EWzcjISBQWFkJOTg4TJ06EtLQ0hxQS6t69e+jVqxeWLFmCjRs3CuMnTpzAgAEDoK6ujqqqKnz33XdYsGABNmzYIEz5Z4xJpqysLIwbNw46Ojrw9PSEjY0NfHx8sGrVKvTo0QM6OjpQV1fH0KFDoaKigoqKCujq6kJTUxNaWlriLp/9j+rDiPLychw+fBhHjx5FRkYGvvrqK2zatAnV1dXCbbj29vbQ1NTEiRMn+CJTM1F//gsKCiASiSAtLQ1VVVW8ePEC+/fvx7FjxzBixAhs2bIFAAdT7D/jUIpJhKqqKsjJyYm7DPaBvBlM+fj44OLFi9i4cSN+/fVXdOvWTdzlsUYwY8YMKCsrIyAgQBhLT0+Hubk55s2bh+3bt791DH+AkUxPnjxB+/btMXHiRBw7dkwY37ZtG1asWIFbt24JixVUVVXh0KFDcHNzw/bt27F06VJxlc0YawT17+dycnJo3bo1IiIisH//flhaWiIxMRH379/Hnj170KpVK5ibm+PUqVPiLpm9h/pg4uXLlzhy5Ah27twJDQ0N3LhxAwCEYGrBggXIysrCmTNnxFwxawz15z0yMhIbNmxAVVUVioqKsGzZMkydOhUAcODAARw7dgyjR49ucHGKsb/Djc6ZROBAqnkzNDREQEAAZGVlMXjwYKxevRpxcXEcSDUD9H+rKmZkZODFixfCeFVVFYyMjIRzXVxc/NbKehxISaa2bdviiy++QFJSEhISEgAA27dvx86dO3HhwgVYWFgICxrIycnB1dUVBw8ehLOzszjLZow1AkNDQ/j7+6OiogI//PADPD09MWbMGHTo0AEjR47EmjVr8OjRI6EBMpNsIpEIRIRWrVph+vTpWL58OQoLCzF+/HgA/3/BgtLSUohEIlRWVoLnQ0g+kUiEmJgYTJw4EVOmTEFMTAwmT56MJUuW4NatW1BTU4OrqyumTp2KgwcPcijF/iueKcUY+2ikpaXB09MTW7Zs4aXAJVRdXR2kpN6+3hEUFIQNGzYgODi4Qfiwe/dunDhxAnFxcbwctIQjIlRXVwsXEaysrPDXX3/Bzs4OISEhCAkJQf/+/Rscc+PGDZiYmEBJSUkcJTPGPpDffvsN8+bNg7S0NFauXCncmv/mLV2sefjXWc0HDx7E1q1b8dlnn6FXr15o0aIFDhw4gBs3bvAKys0AEYGI8OWXX0JVVRV+fn7IycnBgAEDYGdnh6CgIGHfp0+fCrfx8QqL7D/hmVKMsY+GsbExQkNDOZCSUG8GUrdv30ZsbCyePXuGiooKDB8+HLa2tti+fTsiIyMBAM+fP0dMTAx0dXV5NqSES09Px6JFizBhwgT4+PgAeB04aWhoIDAwEKtXr34rkKpfKv7Vq1fiKJkx9gEZGBhg7969ICJs2rRJmDXJgVTzUlNTA2lpaTx+/BjDhw9HZmYmpkyZguXLl6OyshLHjh2DhYUFHj58yIGUhKupqRH+LiUlhT/++AN2dnaoqKiAtbV1g0Dq8OHDSE5Ohra2Ntzd3TmQYv8Vh1KMsY8Kf2CVXPWB1LJlyzBkyBCMHTsW1tbWmDt3LogIGzZsQIcOHTBx4kQYGRmhb9++yMvLw9GjR4VbAJjkSU5Ohq2tLXJzc9GiRQt4e3sLwdSVK1fQu3dv7N27F/Hx8airqwMArF27Frt378bhw4ehqakpzvIZYx/Im7fmL126FNevXxd3Sewd/d37c21tLWRkZPDbb7/B1tYWbdq0gb6+Plq2bIkpU6bgyy+/hLW1Nezt7aGvry+GqlljKCgoQHV1NWRkZPDzzz/j7t27AAATExP4+vrC2NgYI0eOxN69ewEAr169QmRkJM6ePcu9Qdk/xrfvMcYYey9vLgd85swZeHh44MCBA+jUqRPCw8Nx+vRpyMjI4PDhw1BWVkZSUhJu3rwJLS0tjB07llfZk2ApKSmwtrbGkiVLsHnzZtTV1WHx4sWQkZHB+vXroaysDOD1yktZWVkICwtDeHg4tm/fjoSEBKHhOWOs+eJVlCVb/WwokUiErKws1NTUoFWrVtDR0QEAdOnSBd26dWtwgal+Vb7KykqoqqqK+RGwd1VQUIDJkyfDysoKpqammDRpEiIiIuDi4oKLFy/Cy8sLlZWVSExMhLy8PIgIq1atwvHjxxEbG8szpNg/xqEUY4yxd1ZZWSn0gvruu++QnZ2NqqoqYQlgAEIIMWTIEKxevfqt5aD5SppkysnJgbm5Oezt7RESEiKMT5gwAWlpaXj16hXatm2LxYsXw8XFBf369UN8fDwUFRURFxcHc3NzMVbPGGtKvIqy5PH19UXv3r3Rq1cvAEBYWBjmz5+PFi1aID8/H/Pnz8eSJUugqKgoXICo9+bFKia5SktLsX37doSEhODx48c4cOAAZs2aBeB1fzh/f39hld2ePXsiPz8f8fHxiI2NhZmZmThLZxKGb99jjDH2TmJiYhAQECDckrFz505s2LAB9+/fF27TAoCRI0eie/fuOHnyZIPxehxISaba2lro6+ujsrJS6BezdetWREVFYfTo0Vi6dCny8vKwaNEiZGdn4/Llyxg1ahSuXLnCgRRjnxgOpCRLeXk5YmNj4eDggDt37uD58+f46quvsHLlSpw8eRJ79+5FZGQkli1bhqysrLeO50BK8tXV1UFZWRmDBw/Gn3/+CR0dHeTk5KC6uhrA63YbixYtwo4dO9CrVy8UFRXBxMQEV69e5UCK/c94phRjjLH/2ffff481a9Zg2LBhmD59OqysrAAATk5OSEhIEFZaq/8icuzYMezatQsxMTFQU1MTZ+msEWVkZGDRokWQk5ND69atERkZiaNHj2LQoEEAgOzsbOjp6SEgIAALFiwQc7WMMcb+qWfPnmHJkiU4d+4c/P39cfv2bezZs0fYfu7cOWGBi02bNv3b1XeZ5CotLQUA3Lp1C1euXEF0dDT69++PjRs3cssF1qj4lYMxxtj/5KeffsKCBQvg5+eHrVu3wsrKCrW1tQCA8+fPo3v37nB1dUV4eDj+/PNP5Ofn4+DBg9DU1OTeEs2MoaEh/P39UVFRgWPHjsHT0xODBg0CEaG6uhrS0tLo2rUrtLW1Afx9s1zGGGMfHy0tLezatQtDhgzBzJkzce3aNbx69QpEBCLCkCFD4OHhgT179qCwsJADqWYmOTkZXbt2RXJyMhwcHODu7g57e3tcunQJ69atEz73ffvtt0Lzc36PZ++KI07GGGP/WEFBAYKCgrB9+3aMGzdOGK+oqEBycjI0NDRw5coVDBs2DBMnToSBgQEsLCwgEokQERHRoAkqax6MjIxw4MABzJs3Dz///DMsLS3Rp08fyMrKIigoCKWlpcJMOj7vjDEmObS0tLBz504oKSnh8OHDiI+Px8CBA4XtRkZG0NLSEm7pYs1HTU0NunXrhtmzZyMoKAh2dnZYvnw5RCIRfv75Z6Snp0NXVxe+vr5ITU0FwO/x7N1xpM0YY+x/kp+fj7Zt2wo/HzhwADNnzkSfPn3Qp08fDB8+HJGRkRg9ejQeP36MKVOmICYmBnJycqiuruYPLc2QgYEB9u7dCyLC5s2bcffuXWzfvh07duzAqVOn0L59e3GXyBhj7D+onwEFACUlJXj69ClqamrQpk0b+Pr6YtiwYRg1ahQuXLiA4uJi1NXV4cKFCyAiYcETJrn+dZaThYUF1q1bB3Nzc8yaNQtxcXFQUVHB8uXLMXbsWJSXl+PatWu4e/cujIyMxFQ1ay64pxRjjLF/rKCgAObm5hg8eDAmTpyI/fv3Iz09Hba2thg5ciRKSkrg4eEBT09PLFiwAD169EBJSQmOHDkCCwsLbnbbzGVkZMDDwwM3b97EixcvcO3aNVhYWIi7LMYYY/9F/SzmiIgI7N69GxkZGejZsye6deuGdevWobi4GPPmzUNoaCgMDAzg4OCA8PBwnDlzhhtbNxPXr1+HoqIivvjiC2EsMTERvr6+uH79Oo4cOQJbW1tUVVVBRkYG5eXlUFRUFGPFrLngmVKMMcb+MU1NTRw6dAgnT56Eq6srMjMzsXv3bmzcuBEDBw6Eg4MD1NXVkZeXBwC4ffs2tLW14ezsLPQcYM2XoaEhdu7cCWtra9y9e5cDKcYY+0jVr4ZbWVkJ4PWtV+fPn8fEiRPh4uKCM2fOoF27dtiyZQvOnTsHFRUV+Pn5Yc6cOUhLS8OAAQOQkpLCgZSEq5+f8uTJE/j4+GDChAl4+PChsN3CwgKLFi2CkpISvvzyS1y+fBlycnKQkpLiQIo1Gp4pxRhj7H9WUFCAsrIy6OvrNxh/8eIFhg8fjilTpmDWrFnC6iwDBw7EgQMH0LFjR3GUy5pYdXU1ZGVlxV0GY4yx/yA3NxeOjo44f/48OnTogPHjx8PU1BRr167Fixcv0KVLF4waNQoBAQHCMfn5+Vi5ciWWLVsGY2NjMVbPGsvZs2eRl5cHJSUlHD9+HM+ePcO3334LU1NTYZ8JEyYgOjoa+vr6SEhIQMuWLbkdA2s0PFOKMcbY/0xTU/OtQKqgoABTp05FVVUVvvzyS8jIyAjNTy9evMiB1CeEAynGGPv4ERFevXqFtWvXoqamBi9fvoSpqSlyc3PRpUsXODs7C4FUREQErly5gtatWyM4OJgDKQlXPy8lOTkZI0eOxGeffYYJEyZg3rx5UFNTg6urK9LS0oT9tbW1sWPHDsTExEBBQYEDKdaoOJRijDH2XgoLC7F161bMnDkT+fn5iI+Ph7S0NGprazmcYIwxxj4S/3qDTJs2bfDVV18hMTERERERkJaWxoULF2BnZwcnJycEBgYCAJ4/f47Q0FA8evQIdXV1kJLir5CSTiQSITExEZmZmfj666+FFZUdHR2xePFiqKqqwtHREZs3b4arqyvCwsLg6OgITU1NMVfOmiN+RWGMMfZecnNzkZCQgI4dO+Lq1auQlZVFTU0NpKWlxV0aY4wxxvC6h5RIJMKLFy+EMWlpaXz11VcQiUSIiorCypUr8eOPP0JJSQkHDx4UZsP4+fnh2rVrGDhwIAdSEoyIhF5iVVVVmDhxIsaOHYv09PQGgaWjoyPWr18PFxcXHDt2DL/99hsiIyPRoUMHcZXOmjnuKcUYY+y9FRcX47PPPoNIJEJtbS0HUowxxthH5rfffoO1tTVsbGwQHBwMRUVFKCgo4MaNG7C1tcWOHTvQtm1bjB8/HmPHjoWCggJqa2sRGRmJX375hZuaS7D09HTs2bMHT548Qe/evbF06VJkZ2dj8uTJyMnJwblz52BiYvLWcUVFRWjRogVatWolhqrZp4KjbsYYY+9NRUUFIpEIRMSBFGOMMfYRqqurQ01NDSIjIzF16lQcPHgQ9+/fh5WVFRYuXIgff/wRenp6uHz5sjCrSktLC9evX+dASoIlJyfD1tYWubm5aNGiBVasWIEdO3agQ4cOOH78OBQUFDB9+nTk5OS8dayamhoHUuyD45lSjDHGGGOMMdYM1feAqqmpgYyMDAICApCVlQUFBQU8f/4ciYmJ2LBhA9TU1DB9+nSMHz8e69atQ0VFBVq2bMk9pCRcSkoKrK2tsWTJEmzevBl1dXVYvHgxpKWlsWXLFigoKCAnJwfDhw+HlJQUTp8+jXbt2om7bPaJ4VcYxhhjjDHGGGtG6ucdlJeXAwBkZGQAAN26dcOjR49gY2MDPz8/TJs2DRMnTkRCQgJ0dXWxe/dupKSkoGXLlgDAq6xJsJycHDg4OGDo0KHYvHkzAEBKSgoFBQWIi4uDubk5Bg8ejKtXryIiIgJ1dXXo378/njx5IubK2aeGQynGGGOMMcYYa0ZEIhGePn0KExMTrFq1CtnZ2QCAfv36wcbGBtOmTUNRUREWLFiAqKgo3L9/HzIyMigtLcXq1atRW1sr/B4mmWpra6Gvr4/KykokJCQAALZu3YqoqCiMGTMGy5Ytw+PHj7F69Wq8fPkS4eHhUFFRQXV1tZgrZ58avn2PMcYYY4wxxpqZ4uJiBAQEwM/PDxYWFnBxcYG7uzsAYMaMGQAAf39/fPbZZ3j27BkePnwIX19f+Pj4oEuXLuIrnDWajIwMLFq0CHJycmjdujUiIyNx9OhRDBo0CACQnZ0NPT097N+/H25ubsJtnow1JZ4pxRhjjDHGGGPNjIqKCtauXYurV69CTU0N+/btg729PdLS0uDs7AwAuHXrFgBAS0sL9vb2iIqK4kCqGTE0NIS/vz8qKipw7NgxeHp6YtCgQSAiVFdXQ1paGl26dIGGhgYAcCDFxIJDKcYYY4wxxhhrpkxMTBAUFITdu3ejpKQEQ4YMwZ07d3D//n2cPHmywb58u17zY2RkhAMHDqBPnz74+eefER8fD5FIBFlZWQQFBeGvv/6ClZWVuMtknzC+fY8xxhhjjDHGPhFLlixBamoq7t27h7y8PAQHB2P27NniLot9YPW38hERfHx8cPHiRXh7e+Pq1aswMzMTd3nsE8ahFGOMMcYYY4w1c0QkzISKi4tDdHQ09u/fj5s3b6JTp05iro41hYyMDHh4eODmzZt48eIFrl27BgsLC3GXxT5xHEoxxhhjjDHG2CfgzWAKAEpLS6GsrCzGilhTS0tLg6enJ7Zs2QJTU1Nxl8MYh1KMMcYYY4wxxtinorq6GrKysuIugzEAHEoxxhhjjDHGGGOMMTHg1fcYY4wxxhhjjDHGWJPjUIoxxhhjjDHGGGOMNTkOpRhjjDHGGGOMMcZYk+NQijHGGGOMMcYYY4w1OQ6lGGOMMcYYY4wxxliT41CKMcYYY4wxxhhjjDU5DqUYY4wxxhhjjDHGWJPjUIoxxhhjrJk5dOgQVFRU3vv3iEQinD59+r1/D2OMMcbY3+FQijHGGGPsIzRjxgyMGDFC3GUwxhhjjH0wHEoxxhhjjDHGGGOMsSbHoRRjjDHGmITx8/NDly5d0KpVK7Rv3x7z5s1DWVnZW/udPn0ahoaGkJeXh6OjI3Jychpsj4iIgLm5OeTl5fH5559j/fr1qKmp+dt/s6qqCgsWLICOjg7k5eWhq6sLHx+fD/L4GGOMMfZp4FCKMcYYY0zCSElJISAgAA8ePMDhw4dx6dIleHp6NtinvLwcmzdvxpEjR5CQkIDi4mJMmDBB2B4fH49p06Zh8eLFePjwIYKCgnDo0CFs3rz5b//NgIAAREZGIiQkBGlpaTh27Bj09PQ+5MNkjDHGWDMnIiISdxGMMcYYY6yhGTNmoLi4+B81Gg8NDYWbmxsKCwsBvG50PnPmTFy/fh1WVlYAgNTUVHTu3Bk3btyApaUlBgwYAAcHB6xYsUL4PT/88AM8PT2Rl5cH4HWj8/DwcIwYMQKLFi3CgwcPEBsbC5FI1PgPmDHGGGOfHJ4pxRhjjDEmYWJjY+Hg4IC2bdtCSUkJU6dOxfPnz1FeXi7sIyMjg549ewo/d+rUCSoqKnj06BEAIDk5GRs2bICioqLwx9XVFX/++WeD31NvxowZSEpKgrGxMRYtWoSYmJgP/0AZY4wx1qxxKMUYY4wxJkGysrIwdOhQdO3aFadOnUJiYiL27dsH4HXfp3+qrKwM69evR1JSkvDn3r17yMjIgLy8/Fv7m5ub448//sDGjRtRUVGBcePGYcyYMY32uBhjjDH26ZERdwGMMcYYY+yfS0xMRF1dHXx9fSEl9fr6YkhIyFv71dTU4Pbt27C0tAQApKWlobi4GJ07dwbwOmRKS0tDx44d//G/raysjPHjx2P8+PEYM2YMBg8ejKKiIqipqTXCI2OMMcbYp4ZDKcYYY4yxj1RJSQmSkpIajGloaKC6uhp79uyBi4sLEhISEBgY+NaxsrKyWLhwIQICAiAjI4MFCxbA2tpaCKnWrl2LoUOHokOHDhgzZgykpKSQnJyM+/fvY9OmTW/9Pj8/P+jo6MDMzAxSUlI4efIktLW1oaKi8iEeOmOMMcY+AXz7HmOMMcbYRyouLg5mZmYN/hw9ehR+fn7Ytm0bvvjiCxw7dgw+Pj5vHaugoAAvLy9MmjQJNjY2UFRUxIkTJ4Ttjo6OOHPmDGJiYtCzZ09YW1tj165d0NXV/dtalJSUsH37dvTo0QM9e/ZEVlYWzp07J8zWYowxxhj7X/Hqe4wxxhhjjDHGGGOsyfGlLcYYY4wxxhhjjDHW5DiUYowxxhhjjDHGGGNNjkMpxhhjjDHGGGOMMdbkOJRijDHGGGOMMcYYY02OQynGGGOMMcYYY4wx1uQ4lGKMMcYYY4wxxhhjTY5DKcYYY4wxxhhjjDHW5DiUYowxxhhjjDHGGGNNjkMpxhhjjDHGGGOMMdbkOJRijDHGGGOMMcYYY02OQynGGGOMMcYYY4wx1uQ4lGKMMcYYY4wxxhhjTe7/AbHEynWxcldUAAAAAElFTkSuQmCC\n"},"metadata":{}},{"name":"stdout","text":"üìå Nh√£n Mirai: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Nh√£n DDoS: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Nh√£n Spoofing: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Nh√£n BENIGN: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Nh√£n DoS: ƒê√£ c√≥ 400,000 d√≤ng, gi·ªØ nguy√™n\nüìå Oversampling nh√£n Recon: T·ª´ 352,796 l√™n 400,000 d√≤ng\nüìå Oversampling nh√£n BruteForce: T·ª´ 13,004 l√™n 400,000 d√≤ng\nüìå Oversampling nh√£n Web-based: T·ª´ 24,684 l√™n 400,000 d√≤ng\n\nüìã Ph√¢n b·ªë nh√£n sau khi c√¢n b·∫±ng b·∫±ng oversampling:\nlabel\nDDoS          400000\nBruteForce    400000\nMirai         400000\nWeb-based     400000\nDoS           400000\nRecon         400000\nSpoofing      400000\nBENIGN        400000\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# **√ÅNH X·∫† NH√ÉN**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer\nimport pickle\nimport os\nimport matplotlib.pyplot as plt\n\n# ƒê∆∞·ªùng d·∫´n l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Gi·∫£ ƒë·ªãnh df_full l√† DataFrame t·ª´ cell ƒë·ªçc d·ªØ li·ªáu tr∆∞·ªõc ƒë√≥ (cuDF)\n# Chuy·ªÉn t·ª´ cuDF sang Pandas\ndf_original = df_full.to_pandas()\n\n# Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o\nif df_original.empty or 'label' not in df_original.columns:\n    raise ValueError(\"‚ùå D·ªØ li·ªáu ƒë·∫ßu v√†o r·ªóng ho·∫∑c thi·∫øu c·ªôt 'label'!\")\n\n# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu cho c·ªôt s·ªë\nnumeric_columns = df_original.select_dtypes(include=[np.number]).columns\ndf_original[numeric_columns] = df_original[numeric_columns].fillna(df_original[numeric_columns].mean())\n\n# T√°ch ƒë·∫∑c tr∆∞ng v√† nh√£n\nX = df_original.drop(columns=['label']).select_dtypes(include=[np.number])\ny = df_original['label']\n\n# Ki·ªÉm tra nh√£n duy nh·∫•t\nprint(\"üìã Nh√£n duy nh·∫•t trong d·ªØ li·ªáu:\", y.unique().tolist())\n\n# Danh s√°ch 46 ƒë·∫∑c tr∆∞ng (gi·∫£ ƒë·ªãnh ch·ªçn 46 c·ªôt s·ªë ƒë·∫ßu ti√™n ho·∫∑c t·ª´ b√†i to√°n 34 nh√£n)\nall_numeric_columns = X.columns.tolist()\nif len(all_numeric_columns) < 46:\n    raise ValueError(f\"‚ùå D·ªØ li·ªáu ch·ªâ c√≥ {len(all_numeric_columns)} c·ªôt s·ªë, kh√¥ng ƒë·ªß 46 ƒë·∫∑c tr∆∞ng!\")\nselected_features = all_numeric_columns[:46]  # Ch·ªçn 46 c·ªôt ƒë·∫ßu ti√™n\n\n# Ki·ªÉm tra xem c√°c ƒë·∫∑c tr∆∞ng c√≥ t·ªìn t·∫°i trong d·ªØ li·ªáu kh√¥ng\nmissing_features = [f for f in selected_features if f not in X.columns]\nif missing_features:\n    raise ValueError(f\"‚ùå C√°c ƒë·∫∑c tr∆∞ng sau kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu: {missing_features}\")\n\n# L·∫•y ch·ªâ s·ªë c·ªßa c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn\nfeature_indices = [list(X.columns).index(f) for f in selected_features]\n\n# √Åp d·ª•ng c√°c ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn tr∆∞·ªõc khi chia d·ªØ li·ªáu\nX = X[selected_features]\n\n# Chia d·ªØ li·ªáu th√†nh t·∫≠p train, val, test\nX_temp, X_test, Y_temp, Y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\nX_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.1875, stratify=Y_temp, random_state=42)\n\n# M√£ h√≥a nh√£n (8 nh√£n: DDoS, DoS, Recon, Spoofing, BruteForce, Web-based, Mirai, BENIGN)\nlabel_encoder = LabelEncoder()\nY_train_encoded = label_encoder.fit_transform(Y_train)\nY_val_encoded = label_encoder.transform(Y_val)\nY_test_encoded = label_encoder.transform(Y_test)\nlabel_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n\n# In ra c√°c nh√£n ƒë√£ √°nh x·∫°\nprint(\"üìä C√°c nh√£n ƒë√£ √°nh x·∫° (8 nh√£n):\")\nfor label, encoded_value in label_mapping.items():\n    print(f\"  - {label}: {encoded_value}\")\n\n# Ki·ªÉm tra ph√¢n b·ªë nh√£n\nprint(\"\\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p hu·∫•n luy·ªán:\")\nprint(pd.Series(Y_train_encoded).value_counts().rename(label_mapping))\nprint(\"\\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p validation:\")\nprint(pd.Series(Y_val_encoded).value_counts().rename(label_mapping))\nprint(\"\\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p ki·ªÉm tra:\")\nprint(pd.Series(Y_test_encoded).value_counts().rename(label_mapping))\n\n# X·ª≠ l√Ω NaN v√† outlier b·∫±ng KNNImputer\nimputer = KNNImputer(n_neighbors=5)\nX_train_imputed = imputer.fit_transform(X_train)\nX_val_imputed = imputer.transform(X_val)\nX_test_imputed = imputer.transform(X_test)\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng RobustScaler\nscaler = RobustScaler()\nX_train_scaled = scaler.fit_transform(X_train_imputed)\nX_val_scaled = scaler.transform(X_val_imputed)\nX_test_scaled = scaler.transform(X_test_imputed)\n\n# Ki·ªÉm tra gi√° tr·ªã sau khi ch·ªçn ƒë·∫∑c tr∆∞ng\nprint(\"üîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_train_scaled:\")\nprint(pd.DataFrame(X_train_scaled, columns=selected_features).describe().loc[['min', 'max']])\nprint(\"üîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_val_scaled:\")\nprint(pd.DataFrame(X_val_scaled, columns=selected_features).describe().loc[['min', 'max']])\nprint(\"üîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_test_scaled:\")\nprint(pd.DataFrame(X_test_scaled, columns=selected_features).describe().loc[['min', 'max']])\n\n# L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω\nnp.save(f\"{output_dir}/X_train_scaled_8labels_46features.npy\", X_train_scaled)\nnp.save(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\", Y_train_encoded)\nnp.save(f\"{output_dir}/X_val_scaled_8labels_46features.npy\", X_val_scaled)\nnp.save(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\", Y_val_encoded)\nnp.save(f\"{output_dir}/X_test_scaled_8labels_46features.npy\", X_test_scaled)\nnp.save(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\", Y_test_encoded)\n\n# L∆∞u c√°c ƒë·ªëi t∆∞·ª£ng x·ª≠ l√Ω\nwith open(f\"{output_dir}/label_encoder_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(label_encoder, f)\nwith open(f\"{output_dir}/scaler_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(scaler, f)\nwith open(f\"{output_dir}/imputer_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(imputer, f)\nwith open(f\"{output_dir}/selected_features_8labels_46features.pkl\", 'wb') as f:\n    pickle.dump(selected_features, f)\n\n# In th√¥ng tin chi ti·∫øt\nprint(f\"‚úÖ D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√† l∆∞u trong '{output_dir}'!\")\nprint(f\"üìå S·ªë ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: {len(selected_features)}\")\nprint(f\"üìã C√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: {selected_features}\")\n\n# V·∫Ω bi·ªÉu ƒë·ªì danh s√°ch ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn\nplt.figure(figsize=(14, 6))\nplt.bar(selected_features, [1] * len(selected_features), color='skyblue')\nplt.title('Selected Features for Classification (46 Features, 8 Labels)', fontsize=12, fontweight='bold')\nplt.xlabel('Features', fontsize=10)\nplt.ylabel('Selected', fontsize=10)\nplt.xticks(rotation=45, ha='right', fontsize=8)\nplt.tight_layout()\nplt.savefig(f\"{output_dir}/selected_features_8labels_46features.png\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T07:34:06.981819Z","iopub.execute_input":"2025-05-04T07:34:06.982828Z","iopub.status.idle":"2025-05-04T07:34:37.950692Z","shell.execute_reply.started":"2025-05-04T07:34:06.982801Z","shell.execute_reply":"2025-05-04T07:34:37.949776Z"}},"outputs":[{"name":"stdout","text":"üìã Nh√£n duy nh·∫•t trong d·ªØ li·ªáu: ['Mirai', 'DDoS', 'Spoofing', 'BENIGN', 'DoS', 'Recon', 'BruteForce', 'Web-based']\nüìä C√°c nh√£n ƒë√£ √°nh x·∫° (8 nh√£n):\n  - BENIGN: 0\n  - BruteForce: 1\n  - DDoS: 2\n  - DoS: 3\n  - Mirai: 4\n  - Recon: 5\n  - Spoofing: 6\n  - Web-based: 7\n\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p hu·∫•n luy·ªán:\n0    260000\n4    260000\n6    260000\n7    260000\n3    260000\n1    260000\n5    260000\n2    260000\nName: count, dtype: int64\n\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p validation:\n7    60000\n5    60000\n4    60000\n1    60000\n6    60000\n2    60000\n3    60000\n0    60000\nName: count, dtype: int64\n\nüìä Ph√¢n b·ªë nh√£n trong t·∫≠p ki·ªÉm tra:\n7    80000\n1    80000\n4    80000\n3    80000\n6    80000\n2    80000\n0    80000\n5    80000\nName: count, dtype: int64\nüîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_train_scaled:\n     flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\nmin      -0.082901      -0.077443      -0.922078 -1.855932     -0.269625   \nmax    2059.517632      69.790990       5.181818  5.347458  75595.755050   \n\n            Srate     Drate  fin_flag_number  syn_flag_number  \\\nmin     -0.269625  0.000000              0.0              0.0   \nmax  75595.755050  0.044042              1.0              1.0   \n\n     rst_flag_number  ...        AVG        Std   Tot size       IAT  Number  \\\nmin              0.0  ...  -0.165144  -0.212623  -0.157736 -0.499342 -1.0625   \nmax              1.0  ...  23.126075  66.455459  20.893030  0.507391  0.6875   \n\n     Magnitue     Radius   Covariance  Variance    Weight  \nmin -0.286234  -0.212564    -0.048605      -0.8 -0.681951  \nmax  5.754449  66.845022  2935.537323       0.2  0.500000  \n\n[2 rows x 46 columns]\nüîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_val_scaled:\n     flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\nmin      -0.082901      -0.077443      -0.922078 -1.855932     -0.269625   \nmax    3857.281767      69.398655       5.181818  5.347458  54995.839257   \n\n            Srate      Drate  fin_flag_number  syn_flag_number  \\\nmin     -0.269625   0.000000              0.0              0.0   \nmax  54995.839257  29.715225              1.0              1.0   \n\n     rst_flag_number  ...        AVG        Std   Tot size       IAT  Number  \\\nmin              0.0  ...  -0.165144  -0.212623  -0.157736 -0.499342 -1.0625   \nmax              1.0  ...  17.273380  51.729745  17.392627  0.507391  0.6875   \n\n     Magnitue     Radius   Covariance  Variance    Weight  \nmin -0.286234  -0.212564    -0.048605      -0.8 -0.681951  \nmax  5.047848  51.926415  2017.874582       0.2  0.500000  \n\n[2 rows x 46 columns]\nüîç Gi√° tr·ªã t·ªëi ƒëa v√† t·ªëi thi·ªÉu trong X_test_scaled:\n     flow_duration  Header_Length  Protocol Type  Duration          Rate  \\\nmin      -0.082901      -0.077443      -0.922078 -1.855932     -0.269625   \nmax    2059.517632      69.791419       5.181818  5.347458  66146.251965   \n\n            Srate     Drate  fin_flag_number  syn_flag_number  \\\nmin     -0.269625  0.000000              0.0              0.0   \nmax  66146.251965  0.019357              1.0              1.0   \n\n     rst_flag_number  ...        AVG        Std   Tot size       IAT  Number  \\\nmin              0.0  ...  -0.165144  -0.212623  -0.157736 -0.499342 -1.0625   \nmax              1.0  ...  20.792146  42.995213  15.642425  0.507391  0.6875   \n\n     Magnitue     Radius   Covariance  Variance    Weight  \nmin -0.286234  -0.212564    -0.048605      -0.8 -0.681951  \nmax  5.630131  43.158821  1396.735830       0.2  0.500000  \n\n[2 rows x 46 columns]\n‚úÖ D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√† l∆∞u trong 'processed_data'!\nüìå S·ªë ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: 46\nüìã C√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn: ['flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number', 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius', 'Covariance', 'Variance', 'Weight']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# **CHUY·ªÇN ƒê·ªîI ƒê·∫∂C TR∆ØNG FUZZY**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport joblib\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (46 ƒë·∫∑c tr∆∞ng)\nX_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels_46features.npy\")\nY_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\nX_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels_46features.npy\")\nY_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\nX_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels_46features.npy\")\nY_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n\n# Ki·ªÉm tra shape\nprint(f\"üìå Shape d·ªØ li·ªáu ƒë·∫ßu v√†o:\")\nprint(f\"  - X_train_scaled: {X_train_scaled.shape}\")\nprint(f\"  - X_val_scaled: {X_val_scaled.shape}\")\nprint(f\"  - X_test_scaled: {X_test_scaled.shape}\")\n\n# Chia 46 ƒë·∫∑c tr∆∞ng th√†nh 8 nh√≥m (7 nh√≥m 6 ƒë·∫∑c tr∆∞ng, 1 nh√≥m 4 ƒë·∫∑c tr∆∞ng)\nn_groups = 8\ngroup_sizes = [6] * 7 + [4]  # [6, 6, 6, 6, 6, 6, 6, 4]\nX_train_grouped = []\nX_val_grouped = []\nX_test_grouped = []\n\nprint(\"üîÑ T·∫°o ƒë·∫∑c tr∆∞ng x√°c su·∫•t nh√≥m b·∫±ng XGBoost...\")\nfor i in range(n_groups):\n    start_idx = sum(group_sizes[:i])\n    end_idx = start_idx + group_sizes[i]\n    X_train_group = X_train_scaled[:, start_idx:end_idx]\n    X_val_group = X_val_scaled[:, start_idx:end_idx]\n    X_test_group = X_test_scaled[:, start_idx:end_idx]\n\n    print(f\"  - Nh√≥m {i+1}: ƒê·∫∑c tr∆∞ng t·ª´ {start_idx} ƒë·∫øn {end_idx-1} (k√≠ch th∆∞·ªõc: {group_sizes[i]})\")\n\n    # Hu·∫•n luy·ªán XGBoost tr√™n nh√≥m ƒë·∫∑c tr∆∞ng\n    xgb = XGBClassifier(\n        n_estimators=50,\n        max_depth=8,\n        min_child_weight=10,\n        tree_method=\"hist\",\n        device=\"cuda\",\n        random_state=42,\n        objective=\"multi:softprob\"\n    )\n    xgb.fit(X_train_group, Y_train_encoded)\n\n    # T·∫°o x√°c su·∫•t d·ª± ƒëo√°n\n    train_probs = xgb.predict_proba(X_train_group)  # Shape: [n_samples, 8]\n    val_probs = xgb.predict_proba(X_val_group)\n    test_probs = xgb.predict_proba(X_test_group)\n\n    X_train_grouped.append(train_probs)\n    X_val_grouped.append(val_probs)\n    X_test_grouped.append(test_probs)\n\n    # L∆∞u m√¥ h√¨nh XGBoost\n    joblib.dump(xgb, f\"{output_dir}/xgb_group_{i}_8labels_46features.joblib\")\n    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m {i+1}/{n_groups}\")\n\n# G·ªôp ƒë·∫∑c tr∆∞ng x√°c su·∫•t\nX_train_grouped = np.concatenate(X_train_grouped, axis=1)  # Shape: [n_samples, 8*8 = 64]\nX_val_grouped = np.concatenate(X_val_grouped, axis=1)\nX_test_grouped = np.concatenate(X_test_grouped, axis=1)\n\n# (T√πy ch·ªçn) K·∫øt h·ª£p v·ªõi top-k ƒë·∫∑c tr∆∞ng g·ªëc\nk = 10  # Ch·ªçn 10 ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t\nxgb_full = XGBClassifier(\n    n_estimators=100,\n    max_depth=10,\n    tree_method=\"hist\",\n    device=\"cuda\",\n    random_state=42\n)\nxgb_full.fit(X_train_scaled, Y_train_encoded)\nfeature_importance = xgb_full.feature_importances_\nsorted_idx = np.argsort(feature_importance)[::-1][:k]\n\n# K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng x√°c su·∫•t v√† ƒë·∫∑c tr∆∞ng g·ªëc\nX_train_combined = np.concatenate([X_train_grouped, X_train_scaled[:, sorted_idx]], axis=1)  # Shape: [n_samples, 64+10 = 74]\nX_val_combined = np.concatenate([X_val_grouped, X_val_scaled[:, sorted_idx]], axis=1)\nX_test_combined = np.concatenate([X_test_grouped, X_test_scaled[:, sorted_idx]], axis=1)\n\n# Chu·∫©n h√≥a l·∫°i d·ªØ li·ªáu\nscaler = StandardScaler()\nX_train_combined = scaler.fit_transform(X_train_combined)\nX_val_combined = scaler.transform(X_val_combined)\nX_test_combined = scaler.transform(X_test_combined)\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{output_dir}/X_train_combined_8labels_46features.npy\", X_train_combined)\nnp.save(f\"{output_dir}/X_val_combined_8labels_46features.npy\", X_val_combined)\nnp.save(f\"{output_dir}/X_test_combined_8labels_46features.npy\", X_test_combined)\nnp.save(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\", Y_train_encoded)\nnp.save(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\", Y_val_encoded)\nnp.save(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\", Y_test_encoded)\njoblib.dump(scaler, f\"{output_dir}/scaler_combined_8labels_46features.joblib\")\n\n# In th√¥ng tin\nprint(f\"‚úÖ ƒê√£ t·∫°o ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p!\")\nprint(f\"üìå Shape: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\nprint(f\"üìå S·ªë ƒë·∫∑c tr∆∞ng: {X_train_combined.shape[1]} (64 x√°c su·∫•t + 10 g·ªëc)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T03:57:54.836017Z","iopub.execute_input":"2025-05-01T03:57:54.836405Z","iopub.status.idle":"2025-05-01T03:59:47.371089Z","shell.execute_reply.started":"2025-05-01T03:57:54.836362Z","shell.execute_reply":"2025-05-01T03:59:47.370089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport joblib\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (46 ƒë·∫∑c tr∆∞ng)\nX_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels_46features.npy\")\nY_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\nX_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels_46features.npy\")\nY_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\nX_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels_46features.npy\")\nY_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n\n# Ki·ªÉm tra shape\nprint(f\"üìå Shape d·ªØ li·ªáu ƒë·∫ßu v√†o:\")\nprint(f\"  - X_train_scaled: {X_train_scaled.shape}\")\nprint(f\"  - X_val_scaled: {X_val_scaled.shape}\")\nprint(f\"  - X_test_scaled: {X_test_scaled.shape}\")\n\n# Chia 46 ƒë·∫∑c tr∆∞ng th√†nh 8 nh√≥m (7 nh√≥m 6 ƒë·∫∑c tr∆∞ng, 1 nh√≥m 4 ƒë·∫∑c tr∆∞ng)\nn_groups = 8\ngroup_sizes = [6] * 7 + [4]  # [6, 6, 6, 6, 6, 6, 6, 4]\nX_train_grouped = []\nX_val_grouped = []\nX_test_grouped = []\n\nprint(\"üîÑ T·∫°o ƒë·∫∑c tr∆∞ng x√°c su·∫•t nh√≥m b·∫±ng XGBoost...\")\nfor i in range(n_groups):\n    start_idx = sum(group_sizes[:i])\n    end_idx = start_idx + group_sizes[i]\n    X_train_group = X_train_scaled[:, start_idx:end_idx]\n    X_val_group = X_val_scaled[:, start_idx:end_idx]\n    X_test_group = X_test_scaled[:, start_idx:end_idx]\n\n    print(f\"  - Nh√≥m {i+1}: ƒê·∫∑c tr∆∞ng t·ª´ {start_idx} ƒë·∫øn {end_idx-1} (k√≠ch th∆∞·ªõc: {group_sizes[i]})\")\n\n    # Hu·∫•n luy·ªán XGBoost tr√™n nh√≥m ƒë·∫∑c tr∆∞ng\n    xgb = XGBClassifier(\n        n_estimators=50,\n        max_depth=8,\n        min_child_weight=10,\n        tree_method=\"hist\",\n        device=\"cuda\",\n        random_state=42,\n        objective=\"multi:softprob\"\n    )\n    xgb.fit(X_train_group, Y_train_encoded)\n\n    # T·∫°o x√°c su·∫•t d·ª± ƒëo√°n\n    train_probs = xgb.predict_proba(X_train_group)  # Shape: [n_samples, 8]\n    val_probs = xgb.predict_proba(X_val_group)\n    test_probs = xgb.predict_proba(X_test_group)\n\n    X_train_grouped.append(train_probs)\n    X_val_grouped.append(val_probs)\n    X_test_grouped.append(test_probs)\n\n    # L∆∞u m√¥ h√¨nh XGBoost\n    joblib.dump(xgb, f\"{output_dir}/xgb_group_{i}_8labels_46features.joblib\")\n    print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω nh√≥m {i+1}/{n_groups}\")\n\n# G·ªôp ƒë·∫∑c tr∆∞ng x√°c su·∫•t\nX_train_combined = np.concatenate(X_train_grouped, axis=1)  # Shape: [n_samples, 8*8 = 64]\nX_val_combined = np.concatenate(X_val_grouped, axis=1)\nX_test_combined = np.concatenate(X_test_grouped, axis=1)\n\n# Chu·∫©n h√≥a l·∫°i d·ªØ li·ªáu\nscaler = StandardScaler()\nX_train_combined = scaler.fit_transform(X_train_combined)\nX_val_combined = scaler.transform(X_val_combined)\nX_test_combined = scaler.transform(X_test_combined)\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{output_dir}/X_train_combined_8labels_46features.npy\", X_train_combined)\nnp.save(f\"{output_dir}/X_val_combined_8labels_46features.npy\", X_val_combined)\nnp.save(f\"{output_dir}/X_test_combined_8labels_46features.npy\", X_test_combined)\nnp.save(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\", Y_train_encoded)\nnp.save(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\", Y_val_encoded)\nnp.save(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\", Y_test_encoded)\njoblib.dump(scaler, f\"{output_dir}/scaler_combined_8labels_46features.joblib\")\n\n# In th√¥ng tin\nprint(f\"‚úÖ ƒê√£ t·∫°o ƒë·∫∑c tr∆∞ng x√°c su·∫•t!\")\nprint(f\"üìå Shape: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\nprint(f\"üìå S·ªë ƒë·∫∑c tr∆∞ng: {X_train_combined.shape[1]} (64 x√°c su·∫•t)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:09:06.999245Z","iopub.execute_input":"2025-05-03T13:09:07.000057Z","iopub.status.idle":"2025-05-03T13:10:16.983147Z","shell.execute_reply.started":"2025-05-03T13:09:07.000029Z","shell.execute_reply":"2025-05-03T13:10:16.982365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH TABNET**","metadata":{}},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 88.53 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\nTrain Loss trung b√¨nh: 0.1004\nVal Loss trung b√¨nh: 0.1024\nTrain Accuracy trung b√¨nh: 96.27%\nVal Accuracy trung b√¨nh: 96.24%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(results_dir, exist_ok=True)\n\n# Contrastive Loss\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_positive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2))\n        loss_negative = torch.mean(label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return (loss_positive + loss_negative) / 2\n\n# Entmax\ndef entmax15(x, dim=-1):\n    x = F.softmax(x * 1.5, dim=dim)\n    return x\n\n# Ghost Batch Normalization\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# TabNet thu·∫ßn t√∫y\nclass TabNet(nn.Module):\n    def __init__(self, input_dim, num_classes, n_d=64, n_a=64, n_steps=5, gamma=1.3, lambda_sparse=1e-8):\n        super(TabNet, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.lambda_sparse = lambda_sparse\n\n        # BatchNorm ƒë·∫ßu v√†o\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # L·ªõp FC ban ƒë·∫ßu\n        self.initial_fc = nn.Linear(input_dim, n_d + n_a)\n        nn.init.xavier_normal_(self.initial_fc.weight)\n        nn.init.zeros_(self.initial_fc.bias)\n\n        # C√°c l·ªõp ch√∫ √Ω (attention) v√† quy·∫øt ƒë·ªãnh (decision) cho t·ª´ng b∆∞·ªõc\n        self.attention_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(n_a, input_dim),\n                nn.BatchNorm1d(input_dim),\n                nn.ReLU()\n            ) for _ in range(n_steps)\n        ])\n        self.decision_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, n_d),\n                nn.BatchNorm1d(n_d),\n                nn.ReLU(),\n                nn.Dropout(0.2)\n            ) for _ in range(n_steps)\n        ])\n\n        # L·ªõp cu·ªëi ƒë·ªÉ t·∫°o embedding (Stage 1) ho·∫∑c logits (Stage 2)\n        self.fc_embed = nn.Linear(n_d * n_steps, n_d)  # D√πng trong Stage 1\n        self.fc_output = nn.Linear(n_d * n_steps, num_classes)  # D√πng trong Stage 2\n        nn.init.xavier_normal_(self.fc_embed.weight)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_embed.bias)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x, stage='classification'):\n        x = torch.clamp(self.bn(x), -50, 50)\n        prior = torch.ones_like(x)\n        outputs = []\n        sparsity_loss = 0\n        masks = []\n\n        for step in range(self.n_steps):\n            # T·∫°o ƒë·∫∑c tr∆∞ng ch√∫ √Ω v√† quy·∫øt ƒë·ªãnh\n            att = self.initial_fc(x)\n            att_d, att_a = att[:, :self.n_d], att[:, self.n_d:]\n            mask = self.attention_layers[step](att_a)\n            mask = entmax15(mask, dim=1)\n            \n            # T√≠nh sparsity loss\n            entropy = -torch.sum(mask * torch.log(mask + 1e-8), dim=1)\n            sparsity_loss += torch.mean(entropy) / self.n_steps / self.input_dim\n            masks.append(mask)\n\n            # C·∫≠p nh·∫≠t prior v√† √°p d·ª•ng mask\n            prior = prior * (self.gamma - mask)\n            masked_x = x * mask\n\n            # T·∫°o ƒë·∫ßu ra quy·∫øt ƒë·ªãnh\n            out = self.decision_layers[step](masked_x)\n            outputs.append(out)\n\n        # K·∫øt h·ª£p ƒë·∫ßu ra t·ª´ t·∫•t c·∫£ c√°c b∆∞·ªõc\n        combined = torch.cat(outputs, dim=1)  # [batch_size, n_d * n_steps]\n\n        # T·∫°o embedding (Stage 1) ho·∫∑c logits (Stage 2)\n        if stage == 'feature_learning':\n            output = self.fc_embed(combined)\n        else:  # stage == 'classification'\n            output = self.fc_output(combined)\n\n        return output, sparsity_loss, masks\n\n# T·∫£i d·ªØ li·ªáu (8 nh√£n, 30 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels.npy\")\n    X_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels.npy\")\n    X_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu scaled v√† nh√£n\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# T·∫£i soft labels t·ª´ XGBoost (8 nh√£n)\ntry:\n    soft_labels_train = np.load(f\"{results_dir}/soft_labels_train_8labels.npy\")\n    soft_labels_val = np.load(f\"{results_dir}/soft_labels_val_8labels.npy\")\n    soft_labels_test = np.load(f\"{results_dir}/soft_labels_test_8labels.npy\")\n    tqdm.write(f\"‚úÖ ƒê√£ t·∫£i soft labels t·ª´ {results_dir}\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i soft labels: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra k√≠ch th∆∞·ªõc soft labels\nif soft_labels_train.shape[0] != X_train_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_train ({soft_labels_train.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_train_scaled ({X_train_scaled.shape[0]})\")\nif soft_labels_val.shape[0] != X_val_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_val ({soft_labels_val.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_val_scaled ({X_val_scaled.shape[0]})\")\nif soft_labels_test.shape[0] != X_test_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_test ({soft_labels_test.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_test_scaled ({X_test_scaled.shape[0]})\")\n\n# N·ªëi soft labels v√†o ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o\nX_train_aug = np.concatenate([X_train_scaled, soft_labels_train], axis=1)  # Shape: (n_train, 38)\nX_val_aug = np.concatenate([X_val_scaled, soft_labels_val], axis=1)        # Shape: (n_val, 38)\nX_test_aug = np.concatenate([X_test_scaled, soft_labels_test], axis=1)      # Shape: (n_test, 38)\ntqdm.write(f\"‚úÖ ƒê√£ n·ªëi soft labels v√†o ƒë·∫∑c tr∆∞ng, shape: train {X_train_aug.shape}, val {X_val_aug.shape}, test {X_test_aug.shape}\")\n\n# Chuy·ªÉn th√†nh tensor\nX_train_tensor = torch.tensor(X_train_aug, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nsoft_labels_train_tensor = torch.tensor(soft_labels_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val_aug, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nsoft_labels_val_tensor = torch.tensor(soft_labels_val, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_aug, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 512\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor, soft_labels_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor, soft_labels_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntqdm.write(f\"üì° Thi·∫øt b·ªã: {device}\")\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_aug.shape[1]  # 38 ƒë·∫∑c tr∆∞ng (30 + 8 soft labels)\nmodel = TabNet(input_dim=input_dim, num_classes=8, n_d=64, n_a=64, n_steps=5).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_ce = nn.CrossEntropyLoss()  # D√πng cho ph√¢n lo·∫°i ƒëa l·ªõp\ncriterion_contrast = ContrastiveLoss(margin=1.0)\n\n# Danh s√°ch l∆∞u d·ªØ li·ªáu\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nepoch_times = []\n\n# Two-Stage Training\nnum_epochs_stage1 = 5\nnum_epochs_stage2 = 100\ndistillation_weight = 0.1  # Gi·ªØ nguy√™n t·ª´ m√£ tr∆∞·ªõc\ntemperature = 5.0  # Gi·ªØ nguy√™n t·ª´ m√£ tr∆∞·ªõc\n\n# Stage 1: Feature Learning\ntqdm.write(\"Stage 1: Feature Learning with Contrastive Loss\")\nfor epoch in range(num_epochs_stage1):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage1})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, _ in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            idx = torch.randperm(X_batch.size(0))\n            X_batch_2 = X_batch[idx]\n            Y_batch_2 = Y_batch[idx]\n            label = (Y_batch == Y_batch_2).float()\n            features, _, _ = model(X_batch, stage='feature_learning')\n            features_2, _, _ = model(X_batch_2, stage='feature_learning')\n            loss = criterion_contrast(features, features_2, label)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item() * X_batch.size(0)\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n    train_losses.append(running_loss / len(train_loader.dataset))\n    train_accuracies.append(0.0)  # Kh√¥ng t√≠nh accuracy trong Stage 1\n    val_losses.append(0.0)\n    val_accuracies.append(0.0)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage1}, Train Loss: {train_losses[-1]:.4f}, Time: {epoch_time:.2f}s\")\n\n# Stage 2: Classification with CE + KL + Sparsity Loss\ntqdm.write(\"Stage 2: Classification with CE + KL + Sparsity Loss\")\nbest_f1 = 0\nfor epoch in range(num_epochs_stage2):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage2})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, soft_labels in pbar:\n            X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n            optimizer.zero_grad()\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            ce_loss = criterion_ce(outputs, Y_batch)  # CrossEntropyLoss cho ƒëa l·ªõp\n            kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels, reduction='batchmean'), min=0.0)\n            loss = ce_loss + distillation_weight * kl_loss + model.lambda_sparse * sparsity_loss\n            loss.backward()\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch, soft_labels in pbar_val:\n                X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n                outputs, sparsity_loss, _ = model(X_batch, stage='classification')\n                ce_loss = criterion_ce(outputs, Y_batch)\n                kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels, reduction='batchmean'), min=0.0)\n                loss = ce_loss + distillation_weight * kl_loss + model.lambda_sparse * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)  # 8 nh√£n\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage2}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n    # L∆∞u m√¥ h√¨nh t·ªët nh·∫•t d·ª±a tr√™n F1\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_with_soft_label_input.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_with_soft_label_input_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/tabnet_8labels_with_soft_label_input_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{results_dir}/train_losses_8labels_with_soft_label_input.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_with_soft_label_input.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/epoch_times_8labels_with_soft_label_input.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\nnp.save(f\"{results_dir}/total_time_8labels_with_soft_label_input.npy\", np.array([total_time]))\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/tabnet_8labels_with_soft_label_input.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            probs = torch.softmax(outputs, dim=1)\n            test_probs.extend(probs.cpu().numpy())\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())  # L∆∞u logits\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)  # 8 nh√£n\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_with_soft_label_input.npy\", np.array(test_probs))\nnp.save(f\"{results_dir}/test_labels_8labels_with_soft_label_input.npy\", np.array(test_labels))\nnp.save(f\"{results_dir}/test_features_8labels_with_soft_label_input.npy\", np.array(test_features))\nnp.save(f\"{results_dir}/feature_importance_8labels_with_soft_label_input.npy\", avg_mask)\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T14:50:54.13372Z","iopub.execute_input":"2025-04-21T14:50:54.13444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**V·∫º C√ÅC S∆† ƒê·ªí TABNET**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\nresults_dir = \"results\"\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_with_soft_label_input.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_with_soft_label_input.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_with_soft_label_input.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_with_soft_label_input.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_with_soft_label_input.npy\")\n    test_features = np.load(f\"{results_dir}/test_features_8labels_with_soft_label_input.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input.npy\")\n    print(\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho TabNet (8 nh√£n, v·ªõi soft label input)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nexpected_epochs = 105  # 5 epoch Stage 1 + 100 epoch Stage 2\nif train_losses.shape != (expected_epochs,) or val_losses.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (expected_epochs,) or val_accuracies.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\nif test_features.shape[0] != test_labels.shape[0]:\n    raise ValueError(f\"Shape c·ªßa test_features v√† test_labels kh√¥ng kh·ªõp: {test_features.shape}, {test_labels.shape}\")\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'BENIGN',\n    1: 'BruteForce',\n    2: 'DDoS',\n    3: 'DoS',\n    4: 'Mirai',\n    5: 'Recon',\n    6: 'Spoofing',\n    7: 'Web-based'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Lo·∫°i b·ªè Stage 1 (5 epoch ƒë·∫ßu), ch·ªâ v·∫Ω Stage 2 (epoch 5 ƒë·∫øn 105)\nstage1_epochs = 5\nstart_epoch = stage1_epochs  # B·∫Øt ƒë·∫ßu t·ª´ epoch 5\nepochs = np.arange(len(train_losses))\n# L·∫•y d·ªØ li·ªáu t·ª´ epoch 5 tr·ªü ƒëi (Stage 2)\ntrain_accuracies_plot = train_accuracies[start_epoch:]\nval_accuracies_plot = val_accuracies[start_epoch:]\ntrain_losses_plot = train_losses[start_epoch:]\nval_losses_plot = val_losses[start_epoch:]\n# √Ånh x·∫° epochs t·ª´ 5-105 th√†nh 0-100 tr√™n tr·ª•c X\nepochs_mapped = (epochs[start_epoch:] - start_epoch)  # √Ånh x·∫°: epoch 5 ‚Üí 0, epoch 105 ‚Üí 100\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ d·ªÖ ƒë·ªçc\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.legend(loc=\"upper right\", fontsize=10)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, 100)\nax1.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nax1.set_ylim(loss_min - 0.005, loss_max + 0.005)  # Th√™m padding nh·ªè ƒë·ªÉ d·ªÖ nh√¨n\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.legend(loc=\"lower right\", fontsize=10)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, 100)\nax2.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nax2.set_ylim(acc_min - 0.5, acc_max + 0.5)  # Th√™m padding nh·ªè ƒë·ªÉ d·ªÖ nh√¨n\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(\"TabNet: Learning Curves (8 Labels, With Soft Label Input)\\nStage 2 (Epoch 5 to 105, Mapped to 0-100)\", \n             fontsize=14, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{results_dir}/learning_curves_tabnet_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(10, 8))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(\"TabNet: Confusion Matrix (Test, 8 Labels)\")\nplt.grid(False)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/confusion_matrix_tabnet_8labels_with_soft_label_input.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(10, 8))  # TƒÉng k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì\nroc_auc_scores = []\nfor i in range(8):\n    # T√≠nh ROC cho t·ª´ng nh√£n (one-vs-rest)\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    roc_auc_scores.append(roc_auc)\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\n\n# T√≠nh ROC-AUC trung b√¨nh (macro-average)\nroc_auc_macro = np.mean(roc_auc_scores)\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"TabNet: ROC Curves (8 Labels, Macro AUC = {roc_auc_macro:.4f})\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\n# Thu h·∫πp tr·ª•c X t·ª´ 0 ƒë·∫øn 0.2\nplt.xlim(0, 0.2)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/roc_curve_tabnet_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\nprint(f\"üìà ROC-AUC Scores (One-vs-Rest):\")\nfor i, score in enumerate(roc_auc_scores):\n    print(f\"{class_names[i]}: {score:.4f}\")\nprint(f\"üìà Macro-average ROC-AUC: {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of test_features: {test_features.shape}\")\nn_samples, n_features = test_features.shape\n\n# Ki·ªÉm tra s·ªë m·∫´u\nif n_samples < 3:\n    print(f\"Warning: Only {n_samples} samples available. Skipping PCA 3D.\")\nelse:\n    # Apply PCA v·ªõi n_components=3\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(test_features)\n        \n        # 3D Plot\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels):\n            idx = test_labels == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\")\n        ax.set_ylabel(\"PC2\")\n        ax.set_zlabel(\"PC3\")\n        ax.set_title(\"TabNet: PCA 3D Visualization (8 Labels)\")\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{results_dir}/pca_3d_tabnet_8labels_with_soft_label_input.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 7Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy ·ªü Stage 2\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(\"\\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T17:31:02.265099Z","iopub.execute_input":"2025-04-21T17:31:02.265396Z","iopub.status.idle":"2025-04-21T17:31:52.223007Z","shell.execute_reply.started":"2025-04-21T17:31:02.265376Z","shell.execute_reply":"2025-04-21T17:31:52.222177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH AUTOINT**","metadata":{}},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 71.91 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\nTrain Loss trung b√¨nh: 0.0019\nVal Loss trung b√¨nh: 0.0019\nTrain Accuracy trung b√¨nh: 93.85%\nVal Accuracy trung b√¨nh: 94.28%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# Focal Loss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.05):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# Contrastive Loss\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_positive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2))\n        loss_negative = torch.mean(label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        return (loss_positive + loss_negative) / 2\n\n# Ghost Batch Normalization\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# AutoInt (Automatic Feature Interaction Learning)\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, n_layers=3, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        # Ghost Batch Normalization\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # Embedding layer\n        self.embedding = nn.Linear(input_dim, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight)\n\n        # Multi-Head Self-Attention layers\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        # Feature importance\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight)\n\n        # Fully connected layers\n        self.fc_embed = nn.Linear(embed_dim, embed_dim)  # D√πng trong Stage 1\n        self.fc_output = nn.Linear(embed_dim, num_classes)  # D√πng trong Stage 2\n        nn.init.xavier_normal_(self.fc_embed.weight)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_embed.bias)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x, stage='classification'):\n        # Ghost Batch Normalization\n        x = torch.clamp(self.bn(x), -50, 50)  # [batch_size, input_dim]\n\n        # Feature importance\n        importance = torch.sigmoid(self.importance_layer(x))  # [batch_size, input_dim]\n        sparsity_loss = torch.mean(-importance * torch.log(importance + 1e-8))\n        masks = [importance]\n\n        # Embedding\n        x_embed = self.embedding(x).unsqueeze(1)  # [batch_size, 1, embed_dim]\n\n        # Multi-Head Self-Attention\n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)  # [batch_size, 1, embed_dim]\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))  # Residual + LayerNorm\n\n        embeddings = x_embed.squeeze(1)  # [batch_size, embed_dim]\n\n        # T·∫°o embedding (Stage 1) ho·∫∑c logits (Stage 2)\n        if stage == 'feature_learning':\n            output = self.fc_embed(embeddings)\n        else:  # stage == 'classification'\n            output = self.fc_output(embeddings)\n\n        return output, sparsity_loss, masks\n\n# T·∫£i d·ªØ li·ªáu (8 nh√£n)\ntry:\n    X_train_scaled = np.load(f\"{output_dir}/X_train_scaled_8labels.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels.npy\")\n    X_val_scaled = np.load(f\"{output_dir}/X_val_scaled_8labels.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels.npy\")\n    X_test_scaled = np.load(f\"{output_dir}/X_test_scaled_8labels.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu scaled v√† nh√£n (8 nh√£n)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# T·∫£i soft labels (8 nh√£n)\ntry:\n    soft_labels_train = np.load(f\"{results_dir}/soft_labels_train_8labels.npy\")\n    soft_labels_val = np.load(f\"{results_dir}/soft_labels_val_8labels.npy\")\n    soft_labels_test = np.load(f\"{results_dir}/soft_labels_test_8labels.npy\")\n    tqdm.write(f\"‚úÖ ƒê√£ t·∫£i soft labels t·ª´ {results_dir} (8 nh√£n)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i soft labels: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra k√≠ch th∆∞·ªõc soft labels\nif soft_labels_train.shape[0] != X_train_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_train ({soft_labels_train.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_train_scaled ({X_train_scaled.shape[0]})\")\nif soft_labels_val.shape[0] != X_val_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_val ({soft_labels_val.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_val_scaled ({X_val_scaled.shape[0]})\")\nif soft_labels_test.shape[0] != X_test_scaled.shape[0]:\n    raise ValueError(f\"K√≠ch th∆∞·ªõc soft_labels_test ({soft_labels_test.shape[0]}) kh√¥ng kh·ªõp v·ªõi X_test_scaled ({X_test_scaled.shape[0]})\")\nif soft_labels_train.shape[1] != 8:\n    raise ValueError(f\"Soft labels ph·∫£i c√≥ 8 c·ªôt (cho 8 nh√£n), nh∆∞ng c√≥ {soft_labels_train.shape[1]} c·ªôt\")\n\n# N·ªëi soft labels v√†o ƒë·∫ßu v√†o\nX_train_aug = np.concatenate([X_train_scaled, soft_labels_train], axis=1)  # Shape: (n_train, 30 + 8)\nX_val_aug = np.concatenate([X_val_scaled, soft_labels_val], axis=1)\nX_test_aug = np.concatenate([X_test_scaled, soft_labels_test], axis=1)\ntqdm.write(f\"‚úÖ Input shape (sau khi n·ªëi soft labels): train {X_train_aug.shape}, val {X_val_aug.shape}, test {X_test_aug.shape}\")\n\n# Chuy·ªÉn th√†nh tensor\nX_train_tensor = torch.tensor(X_train_aug, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nsoft_labels_train_tensor = torch.tensor(soft_labels_train, dtype=torch.float32)\nX_val_tensor = torch.tensor(X_val_aug, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nsoft_labels_val_tensor = torch.tensor(soft_labels_val, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test_aug, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 512\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor, soft_labels_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor, soft_labels_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntqdm.write(f\"üì° Thi·∫øt b·ªã: {device}\")\n\n# T√≠nh alpha cho Focal Loss (cho 8 nh√£n)\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_aug.shape[1]  # 30 ƒë·∫∑c tr∆∞ng + 8 soft labels = 38\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=192, n_layers=3, n_heads=4, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=5e-7)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.05)\ncriterion_contrast = ContrastiveLoss(margin=1.0)\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs_stage1 = 5\nnum_epochs_stage2 = 100\ndistillation_weight = 0.001\ntemperature = 2.0\n\n# Danh s√°ch l∆∞u d·ªØ li·ªáu\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nepoch_times = []\n\n# Stage 1: Feature Learning\ntqdm.write(\"Stage 1: Feature Learning with Contrastive Loss\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs_stage1):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage1})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, _ in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            idx = torch.randperm(X_batch.size(0))\n            X_batch_2 = X_batch[idx]\n            Y_batch_2 = Y_batch[idx]\n            label = (Y_batch == Y_batch_2).float()\n            features, _, _ = model(X_batch, stage='feature_learning')\n            features_2, _, _ = model(X_batch_2, stage='feature_learning')\n            loss = criterion_contrast(features, features_2, label)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item() * X_batch.size(0)\n\n            # T√≠nh accuracy trong Stage 1\n            with torch.no_grad():\n                outputs, _, _ = model(X_batch, stage='classification')\n                preds = torch.argmax(outputs, dim=1)\n                train_preds.extend(preds.cpu().numpy())\n                train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n\n    train_loss = running_loss / len(train_loader.dataset)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    # Validation trong Stage 1\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch, _ in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                outputs, _, _ = model(X_batch, stage='classification')\n                preds = torch.argmax(outputs, dim=1)\n                val_preds.extend(preds.cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                # T√≠nh contrastive loss ƒë·ªÉ b√°o c√°o (kh√¥ng d√πng ƒë·ªÉ t·ªëi ∆∞u)\n                idx_val = torch.randperm(X_batch.size(0))\n                X_batch_2 = X_batch[idx_val]\n                Y_batch_2 = Y_batch[idx_val]\n                label = (Y_batch == Y_batch_2).float()\n                features, _, _ = model(X_batch, stage='feature_learning')\n                features_2, _, _ = model(X_batch_2, stage='feature_learning')\n                loss = criterion_contrast(features, features_2, label)\n                running_val_loss += loss.item() * X_batch.size(0)\n\n    val_loss = running_val_loss / len(val_loader.dataset)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, Time: {epoch_time:.2f}s\")\n\n# Stage 2: Classification with Focal + KL + Sparsity Loss\ntqdm.write(\"Stage 2: Classification with Focal + KL + Sparsity Loss (Reduced Soft Label Influence)\")\nbest_f1 = 0\nfor epoch in range(num_epochs_stage2):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs_stage2})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch, soft_labels in pbar:\n            X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n            optimizer.zero_grad()\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            focal_loss = criterion_focal(outputs, Y_batch)\n            kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels / temperature, reduction='batchmean', log_target=False), min=0.0)\n            loss = focal_loss + distillation_weight * kl_loss + 1e-8 * sparsity_loss\n            loss.backward()\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            optimizer.step()\n            running_loss += loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean()\n                ce_loss = F.cross_entropy(outputs, Y_batch, reduction='none', label_smoothing=0.05).mean()\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Sparsity Loss: {sparsity_loss.item():.4f}, Focal Loss: {focal_loss.item():.4f}, \"\n                          f\"CE Loss: {ce_loss.item():.4f}, KL Loss: {kl_loss.item():.4f}, Grad Norm: {grad_norm:.4f}, \"\n                          f\"Running Loss: {running_loss:.4f}, \"\n                          f\"Mask max/min: {masks[-1].max():.4f}/{masks[-1].min():.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch, soft_labels in pbar_val:\n                X_batch, Y_batch, soft_labels = X_batch.to(device), Y_batch.to(device), soft_labels.to(device)\n                outputs, sparsity_loss, _ = model(X_batch, stage='classification')\n                focal_loss = criterion_focal(outputs, Y_batch)\n                kl_loss = torch.clamp(F.kl_div(F.log_softmax(outputs / temperature, dim=1), soft_labels / temperature, reduction='batchmean', log_target=False), min=0.0)\n                loss = focal_loss + distillation_weight * kl_loss + 1e-8 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)  # 8 nh√£n\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs_stage2}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_with_soft_label_input.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_with_soft_label_input_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/autoint_8labels_with_soft_label_input_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu\nnp.save(f\"{results_dir}/train_losses_8labels_with_soft_label_input_autoint.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input_autoint.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_with_soft_label_input_autoint.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input_autoint.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/epoch_times_8labels_with_soft_label_input_autoint.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_with_soft_label_input_autoint.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_with_soft_label_input_autoint.npy\", np.array([avg_epoch_time]))\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\ntqdm.write(f\"üìä Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/autoint_8labels_with_soft_label_input.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            outputs, sparsity_loss, masks = model(X_batch, stage='classification')\n            embed_features, _, _ = model(X_batch, stage='feature_learning')  # L·∫•y embedding t·ª´ Stage 1\n            probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(embed_features.detach().cpu().numpy())  # L∆∞u embedding thay v√¨ logits\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)  # 8 nh√£n\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\n# Ki·ªÉm tra k√≠ch th∆∞·ªõc Confusion Matrix\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input_autoint.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_with_soft_label_input_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_with_soft_label_input_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_with_soft_label_input_autoint.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_with_soft_label_input_autoint.npy\", avg_mask)\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:46:53.733435Z","iopub.execute_input":"2025-04-26T12:46:53.733964Z","iopub.status.idle":"2025-04-26T12:49:45.346851Z","shell.execute_reply.started":"2025-04-26T12:46:53.733938Z","shell.execute_reply":"2025-04-26T12:49:45.345542Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**¬∑V·∫º C√ÅC S∆† ƒê·ªí AUTOINT**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\nresults_dir = \"results\"\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_with_soft_label_input_autoint.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_with_soft_label_input_autoint.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_with_soft_label_input_autoint.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_with_soft_label_input_autoint.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_with_soft_label_input_autoint.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_with_soft_label_input_autoint.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_with_soft_label_input_autoint.npy\")\n    test_features = np.load(f\"{results_dir}/test_features_8labels_with_soft_label_input_autoint.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_with_soft_label_input_autoint.npy\")\n    print(\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho AutoInt (8 nh√£n, v·ªõi soft label input)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nexpected_epochs = 105  # 5 epoch Stage 1 + 100 epoch Stage 2\nif train_losses.shape != (expected_epochs,) or val_losses.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (expected_epochs,) or val_accuracies.shape != (expected_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\nif test_features.shape[0] != test_labels.shape[0]:\n    raise ValueError(f\"Shape c·ªßa test_features v√† test_labels kh√¥ng kh·ªõp: {test_features.shape}, {test_labels.shape}\")\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'BENIGN',\n    1: 'BruteForce',\n    2: 'DDoS',\n    3: 'DoS',\n    4: 'Mirai',\n    5: 'Recon',\n    6: 'Spoofing',\n    7: 'Web-based'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Lo·∫°i b·ªè Stage 1 (5 epoch ƒë·∫ßu), ch·ªâ v·∫Ω Stage 2 (epoch 5 ƒë·∫øn 105)\nstage1_epochs = 5\nstart_epoch = stage1_epochs  # B·∫Øt ƒë·∫ßu t·ª´ epoch 5\nepochs = np.arange(len(train_losses))\n# L·∫•y d·ªØ li·ªáu t·ª´ epoch 5 tr·ªü ƒëi (Stage 2)\ntrain_accuracies_plot = train_accuracies[start_epoch:]\nval_accuracies_plot = val_accuracies[start_epoch:]\ntrain_losses_plot = train_losses[start_epoch:]\nval_losses_plot = val_losses[start_epoch:]\n# √Ånh x·∫° epochs t·ª´ 5-105 th√†nh 0-100 tr√™n tr·ª•c X\nepochs_mapped = (epochs[start_epoch:] - start_epoch)  # √Ånh x·∫°: epoch 5 ‚Üí 0, epoch 105 ‚Üí 100\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ d·ªÖ ƒë·ªçc\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.legend(loc=\"upper right\", fontsize=10)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, 100)\nax1.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y theo y√™u c·∫ßu: t·ª´ 0.00 ƒë·∫øn 0.004\nax1.set_ylim(0.0016, 0.0026)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=1.5)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=1.5)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.legend(loc=\"lower right\", fontsize=10)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, 100)\nax2.set_xticks(np.arange(0, 101, 20))  # 0, 20, 40, 60, 80, 100\n# ƒêi·ªÅu ch·ªânh tr·ª•c Y d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nax2.set_ylim(acc_min - 0.5, acc_max + 0.5)  # Th√™m padding nh·ªè ƒë·ªÉ d·ªÖ nh√¨n\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(\"AutoInt: Learning Curves (8 Labels, With Soft Label Input)\\nStage 2 (Epoch 5 to 105, Mapped to 0-100)\", \n             fontsize=14, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{results_dir}/learning_curves_autoint_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(10, 8))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(\"AutoInt: Confusion Matrix (Test, 8 Labels)\")\nplt.grid(False)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/confusion_matrix_autoint_8labels_with_soft_label_input.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(10, 8))  # TƒÉng k√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì\nroc_auc_scores = []\nfor i in range(8):\n    # T√≠nh ROC cho t·ª´ng nh√£n (one-vs-rest)\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    roc_auc_scores.append(roc_auc)\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\n\n# T√≠nh ROC-AUC trung b√¨nh (macro-average)\nroc_auc_macro = np.mean(roc_auc_scores)\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"AutoInt: ROC Curves (8 Labels, Macro AUC = {roc_auc_macro:.4f})\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\n# ƒêi·ªÅu ch·ªânh tr·ª•c X theo y√™u c·∫ßu: t·ª´ 0 ƒë·∫øn 1\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{results_dir}/roc_curve_autoint_8labels_with_soft_label_input.png\", bbox_inches=\"tight\")\nplt.show()\nprint(f\"üìà ROC-AUC Scores (One-vs-Rest):\")\nfor i, score in enumerate(roc_auc_scores):\n    print(f\"{class_names[i]}: {score:.4f}\")\nprint(f\"üìà Macro-average ROC-AUC: {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of test_features: {test_features.shape}\")\nn_samples, n_features = test_features.shape\n\n# Ki·ªÉm tra s·ªë m·∫´u\nif n_samples < 3:\n    print(f\"Warning: Only {n_samples} samples available. Skipping PCA 3D.\")\nelse:\n    # Apply PCA v·ªõi n_components=3\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(test_features)\n        \n        # 3D Plot\n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels):\n            idx = test_labels == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\")\n        ax.set_ylabel(\"PC2\")\n        ax.set_zlabel(\"PC3\")\n        ax.set_title(\"AutoInt: PCA 3D Visualization (8 Labels)\")\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{results_dir}/pca_3d_autoint_8labels_with_soft_label_input.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 7Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy ·ªü Stage 2\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(\"\\nüìä Gi√° tr·ªã trung b√¨nh ·ªü Stage 2 (epoch 5 ƒë·∫øn 105):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T16:18:45.374379Z","iopub.execute_input":"2025-04-22T16:18:45.374988Z","iopub.status.idle":"2025-04-22T16:19:37.366773Z","shell.execute_reply.started":"2025-04-22T16:18:45.374961Z","shell.execute_reply":"2025-04-22T16:19:37.365867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH AUTOINT FUZZY**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.amp import GradScaler, autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, AutoInt\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.embedding = nn.Linear(input_dim, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight, gain=0.1)\n\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        x_embed = self.embedding(x).unsqueeze(1)\n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))\n\n        embeddings = x_embed.squeeze(1)\n        output = self.fc_output(embeddings)\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu cho 8 nh√£n, 64 ƒë·∫∑c tr∆∞ng (t∆∞∆°ng t·ª± DCN-V2)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng (8 nh√£n, 64 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape\nif X_train_combined.shape[1] != 64:\n    raise ValueError(f\"‚ùå Shape c·ªßa X_train_combined kh√¥ng ƒë√∫ng: {X_train_combined.shape[1]}, k·ª≥ v·ªçng 64 ƒë·∫∑c tr∆∞ng\")\ntqdm.write(f\"üìå Shape d·ªØ li·ªáu: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf trong d·ªØ li·ªáu\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\nX_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\nX_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\nX_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long).to(device)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32).to(device)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long).to(device)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long).to(device)\n\n# DataLoader\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T√≠nh alpha cho Focal Loss cho 8 nh√£n\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v·ªõi num_classes=8, input_dim=44\ninput_dim = X_train_combined.shape[1]  # 64\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler('cuda')\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150  # ƒê·ªìng b·ªô v·ªõi DCN-V2\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n cho 8 nh√£n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training AutoInt with Focal + Sparsity Loss (No Early Stopping, 8 Labels, 64 Features)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            \n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            if torch.isnan(total_loss):\n                tqdm.write(f\"NaN detected in total_loss at batch {pbar.n+1}\")\n                continue\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean()\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                with autocast('cuda'):\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top c·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    # L∆∞u m√¥ h√¨nh n·∫øu F1 t·ªët h∆°n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_64features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_64features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/autoint_8labels_64features_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/autoint_8labels_64features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n tr√™n t·∫≠p test\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"C·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_64features_autoint.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_64features_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_64features_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_64features_autoint.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_64features_autoint.npy\", avg_mask)\n\n# T√≠nh gi√° tr·ªã trung b√¨nh\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\n\n# L∆∞u k·∫øt qu·∫£ v√†o file .txt\nwith open(f\"{results_dir}/AutoInt_8labels_64features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán AutoInt (8 nh√£n, 64 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/AutoInt_8labels_64features.txt\")\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_64features_autoint.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_64features_autoint.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_64features_autoint.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_64features_autoint.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_64features_autoint.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_64features_autoint.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_64features_autoint.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_64features_autoint.npy\", np.array(epoch_times))\nnp.save(f\"{results_dir}/total_time_8labels_64features_autoint.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_64features_autoint.npy\", np.array([avg_epoch_time]))\ntqdm.write(f\"üì¶ ƒê√£ l∆∞u d·ªØ li·ªáu ƒë√°nh gi√° v√†o c√°c file .npy trong {results_dir}\")\n\n# In th√¥ng tin shape\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:12:04.127512Z","iopub.execute_input":"2025-05-03T13:12:04.127818Z","iopub.status.idle":"2025-05-03T13:40:02.737401Z","shell.execute_reply.started":"2025-05-03T13:12:04.127796Z","shell.execute_reply":"2025-05-03T13:40:02.736386Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH AUTOINT FUZZY**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"autoint_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_64features_autoint.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_64features_autoint.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_64features_autoint.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_64features_autoint.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_64features_autoint.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_64features_autoint.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_64features_autoint.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_64features_autoint.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_64features_autoint.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho AutoInt (8 nh√£n, 64 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ ch·ª©a 150 epoch\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05\nax2.set_ylim(acc_min - padding, acc_max + padding)\nax2.set_yticks(np.linspace(acc_min - padding, acc_max + padding, 8))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"AutoInt: Learning Curves (8 Labels, 64 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_autoint_8labels_64features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"AutoInt: Confusion Matrix (Test, 8 Labels, 64 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_autoint_8labels_64features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"AutoInt: ROC Curves (8 Labels, 64 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_autoint_8labels_64features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"AutoInt: PCA 3D Visualization (8 Labels, 64 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_autoint_8labels_64features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 64\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]\n\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (64,) or (n_samples, 64).\")\n\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"AutoInt: Feature Importance (8 Labels, 64 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_autoint_8labels_64features_150epochs.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:57:03.328067Z","iopub.execute_input":"2025-05-01T05:57:03.328364Z","iopub.status.idle":"2025-05-01T05:57:12.377207Z","shell.execute_reply.started":"2025-05-01T05:57:03.328342Z","shell.execute_reply":"2025-05-01T05:57:12.376565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 37.30 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh (100 epoch):\nTrain Loss trung b√¨nh: 0.0205\nVal Loss trung b√¨nh: 0.0199\nTrain Accuracy trung b√¨nh: 88.35%\nVal Accuracy trung b√¨nh: 88.68%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.cuda.amp import GradScaler, autocast\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# FocalLoss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# GhostBN1d\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\n# AutoInt\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=32, n_layers=2, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.embedding = nn.Linear(1, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight, gain=0.1)\n\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        x_embed = torch.stack([self.embedding(x[:, i:i+1]) for i in range(self.input_dim)], dim=1)\n        \n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))\n\n        embeddings = x_embed.mean(dim=1)\n        output = self.fc_output(embeddings)\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu combined (74 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} ch·ª©a gi√° tr·ªã NaN ho·∫∑c Inf\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape c·ªßa d·ªØ li·ªáu\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\naccumulation_steps = 8\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\ntorch.cuda.empty_cache()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=32, n_layers=2, n_heads=4, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler()\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# H√†m ki·ªÉm tra b·ªô nh·ªõ GPU\ndef print_gpu_memory():\n    if torch.cuda.is_available():\n        allocated = torch.cuda.memory_allocated() / 1024**3  # GB\n        reserved = torch.cuda.memory_reserved() / 1024**3    # GB\n        tqdm.write(f\"GPU Memory - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Hu·∫•n luy·ªán AutoInt v·ªõi Focal + Sparsity Loss (8 Nh√£n, 46 ƒê·∫∑c tr∆∞ng)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Batch Hu·∫•n luy·ªán (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for batch_idx, (X_batch, Y_batch) in enumerate(pbar):\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            \n            with autocast():  # ƒê√£ s·ª≠a: B·ªè 'cuda', ch·ªâ d√πng autocast() ƒë·ªÉ t·ª± ƒë·ªông √°p d·ª•ng AMP tr√™n thi·∫øt b·ªã hi·ªán t·∫°i\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n                loss = total_loss / accumulation_steps\n            \n            if torch.isnan(loss) or torch.isinf(loss):\n                tqdm.write(f\"Ph√°t hi·ªán NaN ho·∫∑c Inf trong total_loss t·∫°i batch {batch_idx+1}\")\n                continue\n            \n            scaler.scale(loss).backward()\n            \n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=False)\n            \n            if (batch_idx + 1) % accumulation_steps == 0:\n                scaler.unscale_(optimizer)\n                scaler.step(optimizer)\n                scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if batch_idx < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {batch_idx+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n                print_gpu_memory()\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, total_loss, focal_loss, loss\n            torch.cuda.empty_cache()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # ƒê√°nh gi√°\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"ƒê√°nh gi√° (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n                with autocast():  # ƒê√£ s·ª≠a: B·ªè 'cuda'\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n                \n                del X_batch, Y_batch, outputs, sparsity_loss, focal_loss, loss\n                torch.cuda.empty_cache()\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (ƒê√°nh gi√°): {pred_counts}\")\n    tqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\n    tqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n h√†ng ƒë·∫ßu: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n    print_gpu_memory()\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_46features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/autoint_8labels_46features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/autoint_8labels_46features_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_46features_autoint.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_autoint.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_autoint.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_autoint.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_autoint.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_autoint.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_autoint.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_autoint.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_autoint.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_autoint.npy\", np.array([avg_epoch_time]))\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\ntqdm.write(f\"üìä Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\")\n\n# Ki·ªÉm tra tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/autoint_8labels_46features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Ki·ªÉm tra\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            with autocast():  # ƒê√£ s·ª≠a: B·ªè 'cuda'\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(X_batch.cpu().numpy())  # L∆∞u input features\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, probs\n            torch.cuda.empty_cache()\n\n    print_gpu_memory()\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\ntqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"C·∫£nh b√°o: K√≠ch th∆∞·ªõc mask kh√¥ng ƒë·ªìng nh·∫•t: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_autoint.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_autoint.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_autoint.npy\", avg_mask)\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/AutoInt_8labels_46features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán AutoInt (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/AutoInt_8labels_46features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"T·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T14:57:19.403284Z","iopub.execute_input":"2025-04-30T14:57:19.403942Z","iopub.status.idle":"2025-04-30T15:01:38.439705Z","shell.execute_reply.started":"2025-04-30T14:57:19.403919Z","shell.execute_reply":"2025-04-30T15:01:38.438676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom xgboost import XGBClassifier\nimport joblib\nimport pickle\nimport os\nfrom tqdm import tqdm\nimport time\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, AutoInt\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\nclass AutoInt(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1):\n        super(AutoInt, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.n_layers = n_layers\n        self.n_heads = n_heads\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.embedding = nn.Linear(input_dim, embed_dim)\n        nn.init.xavier_normal_(self.embedding.weight)\n\n        self.attention_layers = nn.ModuleList([\n            nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout, batch_first=True)\n            for _ in range(n_layers)\n        ])\n        self.attention_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(n_layers)])\n        self.dropout_layer = nn.Dropout(dropout)\n\n        self.importance_layer = nn.Linear(input_dim, input_dim)\n        nn.init.xavier_normal_(self.importance_layer.weight)\n\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        x_embed = self.embedding(x).unsqueeze(1)\n        for attn, norm in zip(self.attention_layers, self.attention_norms):\n            attn_output, _ = attn(x_embed, x_embed, x_embed)\n            x_embed = norm(x_embed + self.dropout_layer(attn_output))\n\n        embeddings = x_embed.squeeze(1)\n        output = self.fc_output(embeddings)\n        return output, sparsity_loss, masks\n\n# H√†m √°nh x·∫° nh√£n\ndef change_label(df):\n    mapping = {\n        'DDoS-ICMP_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS',\n        'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-RSTFINFlood': 'DDoS',\n        'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n        'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n        'DDoS-HTTP_Flood': 'DDoS', 'DDoS-SlowLoris': 'DDoS',\n        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n        'DictionaryBruteForce': 'BruteForce',\n        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n        'BenignTraffic': 'BENIGN'\n    }\n    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n    return df\n\n# Danh s√°ch 30 ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn\nselected_features = [\n    'IAT', 'Tot size', 'Max', 'Tot sum', 'Magnitue', 'AVG', 'Min', 'Header_Length', \n    'Protocol Type', 'rst_count', 'Weight', 'Number', 'Variance', 'Std', 'Radius', \n    'Covariance', 'Duration', 'urg_count', 'flow_duration', 'Rate', 'Srate', 'TCP', \n    'ack_flag_number', 'syn_count', 'HTTPS', 'ack_count', 'syn_flag_number', 'ICMP', \n    'fin_count', 'UDP'\n]\n\n# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu t·ª´ file CSV\ntest_file = \"/kaggle/input/cic-iot-2023/part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\nprint(\"‚úÖ ƒêang t·∫£i d·ªØ li·ªáu t·ª´:\", test_file)\ndf_test = pd.read_csv(test_file)\n\n# Ki·ªÉm tra v√† √°nh x·∫° nh√£n\nunique_labels_before = df_test['label'].unique()\ndf_test = change_label(df_test)\nunique_labels_after = df_test['label'].unique()\nvalid_labels = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\nif not all(label in valid_labels for label in unique_labels_after):\n    raise ValueError(f\"‚ùå Nh√£n kh√¥ng ƒë∆∞·ª£c √°nh x·∫° ƒë√∫ng: {unique_labels_after}\")\nprint(f\"Nh√£n tr∆∞·ªõc √°nh x·∫°: {unique_labels_before}\")\nprint(f\"Nh√£n sau √°nh x·∫°: {unique_labels_after}\")\n\n# Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i\nmissing_features = [f for f in selected_features if f not in df_test.columns]\nif missing_features:\n    raise ValueError(f\"‚ùå C√°c ƒë·∫∑c tr∆∞ng sau kh√¥ng c√≥ trong d·ªØ li·ªáu: {missing_features}\")\n\n# Ch·ªçn 30 ƒë·∫∑c tr∆∞ng\nX_test = df_test[selected_features].values\nY_test = df_test['label'].values\n\n# T·∫£i label encoder\ntry:\n    with open(f\"{output_dir}/label_encoder_8labels.pkl\", 'rb') as f:\n        label_encoder = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i label encoder t·ª´:\", f\"{output_dir}/label_encoder_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i label encoder: {str(e)}\")\n\n# M√£ h√≥a nh√£n\nY_test_encoded = label_encoder.transform(Y_test)\nlabel_names = label_encoder.classes_\nexpected_label_map = {'BENIGN': 0, 'BruteForce': 1, 'DDoS': 2, 'DoS': 3, 'Mirai': 4, 'Recon': 5, 'Spoofing': 6, 'Web-based': 7}\nif not all(label_names[i] == label for label, i in expected_label_map.items()):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: √Ånh x·∫° nh√£n kh√¥ng kh·ªõp v·ªõi k·ª≥ v·ªçng: {label_names}\")\nprint(\"‚úÖ Nh√£n ƒë√£ m√£ h√≥a:\", label_names)\n\n# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu b·∫±ng KNNImputer\ntry:\n    with open(f\"{output_dir}/imputer_8labels.pkl\", 'rb') as f:\n        imputer = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i imputer t·ª´:\", f\"{output_dir}/imputer_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i imputer: {str(e)}\")\nX_test_imputed = imputer.transform(X_test)\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng RobustScaler\ntry:\n    with open(f\"{output_dir}/scaler_8labels.pkl\", 'rb') as f:\n        scaler = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i scaler t·ª´:\", f\"{output_dir}/scaler_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i scaler: {str(e)}\")\nX_test_scaled = scaler.transform(X_test_imputed)\nprint(\"‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu test\")\n\n# H√†m t·∫°o ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost\ndef convert_to_fuzzy_features_xgb(X_test, n_features=30, n_labels=8):\n    X_test_fuzzy = []\n    \n    # L·∫∑p qua t·ª´ng ƒë·∫∑c tr∆∞ng\n    for i in tqdm(range(n_features), desc=\"Processing features for fuzzy features\"):\n        X_test_feature = X_test[:, i].reshape(-1, 1)\n        \n        # T·∫£i m√¥ h√¨nh XGBoost ƒë√£ l∆∞u\n        try:\n            xgb = joblib.load(f\"{output_dir}/xgb_feature_{i}.joblib\")\n        except Exception as e:\n            print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh XGBoost cho ƒë·∫∑c tr∆∞ng {i}: {str(e)}\")\n            raise\n        \n        # D·ª± ƒëo√°n x√°c su·∫•t\n        test_probs = xgb.predict_proba(X_test_feature)\n        \n        # ƒê·∫£m b·∫£o ƒë·ªß 8 nh√£n\n        if test_probs.shape[1] < n_labels:\n            missing_labels = n_labels - test_probs.shape[1]\n            test_probs = np.pad(test_probs, ((0, 0), (0, missing_labels)), mode='constant')\n        \n        X_test_fuzzy.append(test_probs)\n    \n    # Chuy·ªÉn th√†nh ma tr·∫≠n [n_samples, n_features * n_labels]\n    X_test_fuzzy = np.concatenate(X_test_fuzzy, axis=1)\n    return X_test_fuzzy\n\n# T√≠nh ƒë·∫∑c tr∆∞ng fuzzy\nprint(\"üîÑ T√≠nh ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost...\")\nstart_time = time.time()\nX_test_fuzzy = convert_to_fuzzy_features_xgb(X_test_scaled, n_features=30, n_labels=8)\nprint(f\"‚úÖ Shape c·ªßa X_test_fuzzy: {X_test_fuzzy.shape}\")\nprint(f\"‚è± Th·ªùi gian t√≠nh fuzzy: {time.time() - start_time:.2f}s\")\n\n# Ki·ªÉm tra gi√° tr·ªã nan/inf\nprint(f\"X_test_fuzzy nan: {np.any(np.isnan(X_test_fuzzy))}\")\nprint(f\"X_test_fuzzy inf: {np.any(np.isinf(X_test_fuzzy))}\")\n\n# Ki·ªÉm tra x√°c su·∫•t fuzzy\nprint(\"M·∫´u x√°c su·∫•t fuzzy (5 m·∫´u ƒë·∫ßu ti√™n, ƒë·∫∑c tr∆∞ng 0):\")\nprint(X_test_fuzzy[:5, :8])\nprint(\"T·ªïng x√°c su·∫•t m·ªói m·∫´u:\", X_test_fuzzy[:5, :8].sum(axis=1))\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_test_tensor = torch.tensor(X_test_fuzzy, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T·∫£i m√¥ h√¨nh AutoInt ƒë√£ hu·∫•n luy·ªán\ninput_dim = X_test_fuzzy.shape[1]  # 240 (30 features * 8 labels)\nmodel = AutoInt(input_dim=input_dim, num_classes=8, embed_dim=64, n_layers=2, n_heads=4, dropout=0.1).to(device)\nmodel_path = f\"{results_dir}/autoint_8labels_fuzzy_xgb.pth\"\ntry:\n    model.load_state_dict(torch.load(model_path, weights_only=True))\n    print(f\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ {model_path}\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}\")\n    raise\n\n# Test m√¥ h√¨nh\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_probs = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            outputs, _, _ = model(X_batch)\n            probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_probs = np.array(test_probs)\n\n# T√≠nh ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ v√† theo t·ª´ng nh√£n\noverall_accuracy = accuracy_score(test_labels, test_preds) * 100\nclassification_rep = classification_report(test_labels, test_preds, target_names=label_names, digits=4)\n\n# T√≠nh confusion matrix\ncm = confusion_matrix(test_labels, test_preds)\nprint(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\n# In k·∫øt qu·∫£\nprint(\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\nprint(f\"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ: {overall_accuracy:.2f}%\")\nprint(\"\\nB√°o c√°o ph√¢n lo·∫°i theo t·ª´ng nh√£n:\")\nprint(classification_rep)\nprint(f\"Confusion Matrix:\\n{cm}\")\n\n# L∆∞u k·∫øt qu·∫£\nnp.save(f\"{results_dir}/test_preds_8labels_fuzzy_xgb_autoint.npy\", test_preds)\nnp.save(f\"{results_dir}/test_labels_8labels_fuzzy_xgb_autoint.npy\", test_labels)\nnp.save(f\"{results_dir}/test_probs_8labels_fuzzy_xgb_autoint.npy\", test_probs)\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_fuzzy_xgb_autoint.npy\", cm)\nprint(f\"üì¶ ƒê√£ l∆∞u d·ª± ƒëo√°n, nh√£n th·ª±c t·∫ø, x√°c su·∫•t v√† confusion matrix t·∫°i {results_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T07:17:14.051475Z","iopub.execute_input":"2025-04-24T07:17:14.05176Z","iopub.status.idle":"2025-04-24T07:17:20.598918Z","shell.execute_reply.started":"2025-04-24T07:17:14.051739Z","shell.execute_reply":"2025-04-24T07:17:20.598197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH TABNET FUZZY**","metadata":{}},{"cell_type":"markdown","source":"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: 39.49 gi√¢y\n\nüìä Gi√° tr·ªã trung b√¨nh (100 epoch):\nTrain Loss trung b√¨nh: 0.0102\nVal Loss trung b√¨nh: 0.0099\nTrain Accuracy trung b√¨nh: 94.88%\nVal Accuracy trung b√¨nh: 95.05%","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.cuda.amp import GradScaler, autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, TabNet\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\ndef entmax15(x, dim=-1):\n    x = F.softmax(x * 1.5, dim=dim)\n    return x\n\nclass TabNet(nn.Module):\n    def __init__(self, input_dim, num_classes, n_d=64, n_a=64, n_steps=5, gamma=1.3, lambda_sparse=5e-4):\n        super(TabNet, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.lambda_sparse = lambda_sparse\n\n        # BatchNorm ƒë·∫ßu v√†o\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # L·ªõp FC ban ƒë·∫ßu\n        self.initial_fc = nn.Linear(input_dim, n_d + n_a)\n        nn.init.xavier_normal_(self.initial_fc.weight)\n        nn.init.zeros_(self.initial_fc.bias)\n\n        # C√°c l·ªõp ch√∫ √Ω v√† quy·∫øt ƒë·ªãnh\n        self.attention_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(n_a, input_dim),\n                nn.BatchNorm1d(input_dim),\n                nn.ReLU()\n            ) for _ in range(n_steps)\n        ])\n        self.decision_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, n_d),\n                nn.BatchNorm1d(n_d),\n                nn.ReLU(),\n                nn.Dropout(0.1)\n            ) for _ in range(n_steps)\n        ])\n\n        # L·ªõp ƒë·∫ßu ra\n        self.fc_output = nn.Linear(n_d * n_steps, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        prior = torch.ones_like(x)\n        outputs = []\n        sparsity_loss = 0\n        masks = []\n\n        for step in range(self.n_steps):\n            att = self.initial_fc(x)\n            att_d, att_a = att[:, :self.n_d], att[:, self.n_d:]\n            mask = self.attention_layers[step](att_a)\n            mask = entmax15(mask, dim=1)\n            \n            entropy = -torch.sum(mask * torch.log(mask + 1e-8), dim=1)\n            sparsity_loss += torch.mean(entropy) / self.n_steps / self.input_dim\n            masks.append(mask)\n\n            prior = prior * (self.gamma - mask)\n            masked_x = x * mask\n            out = self.decision_layers[step](masked_x)\n            outputs.append(out)\n\n        combined = torch.cat(outputs, dim=1)\n        output = self.fc_output(combined)\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p (74 ƒë·∫∑c tr∆∞ng: 64 x√°c su·∫•t + 10 g·ªëc)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng k·∫øt h·ª£p (64 ƒë·∫∑c tr∆∞ng, 8 nh√£n)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape\nif X_train_combined.shape[1] != 64:\n    raise ValueError(f\"‚ùå Shape c·ªßa X_train_combined kh√¥ng ƒë√∫ng: {X_train_combined.shape[1]}, k·ª≥ v·ªçng 64 ƒë·∫∑c tr∆∞ng\")\ntqdm.write(f\"üìå Shape d·ªØ li·ªáu: train {X_train_combined.shape}, val {X_val_combined.shape}, test {X_test_combined.shape}\")\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long).to(device)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32).to(device)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long).to(device)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long).to(device)\n\n# DataLoader\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim =64 # C·∫≠p nh·∫≠t cho 74 ƒë·∫∑c tr∆∞ng\nmodel = TabNet(input_dim=input_dim, num_classes=8, n_d=64, n_a=64, n_steps=5, lambda_sparse=5e-4).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler()\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training TabNet with Focal + Sparsity Loss (No Early Stopping)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            optimizer.zero_grad()\n            \n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean()\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                with autocast():\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    # Ph√¢n t√≠ch nh·∫ßm l·∫´n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    # L∆∞u m√¥ h√¨nh n·∫øu F1 t·ªët h∆°n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_46features_tabnet.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/tabnet_8labels_46features_tabnet_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/tabnet_8labels_46features_tabnet_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/tabnet_8labels_46features_tabnet.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\n# T√≠nh to√°n c√°c ch·ªâ s·ªë\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n tr√™n t·∫≠p test\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n# L∆∞u d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_tabnet.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_tabnet.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_tabnet.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_tabnet.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_tabnet.npy\", avg_mask)\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_46features_tabnet.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_tabnet.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_tabnet.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_tabnet.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_tabnet.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_tabnet.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_tabnet.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_tabnet.npy\", np.array(epoch_times))\n\n# T√≠nh v√† l∆∞u th·ªùi gian hu·∫•n luy·ªán\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_tabnet.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_tabnet.npy\", np.array([avg_epoch_time]))\n\n# L∆∞u k·∫øt qu·∫£ v√†o file\nwith open(f\"{results_dir}/TabNet_8labels_46features_tabnet.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán TabNet (8 nh√£n, 64 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {np.mean(train_losses):.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {np.mean(val_losses):.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {np.mean(train_accuracies):.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {np.mean(val_accuracies):.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"Th·ªùi gian trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {np.mean(val_f1_scores):.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {np.mean(val_precisions):.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {np.mean(val_recalls):.4f}\\n\")\n\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/TabNet_8labels_46features_tabnet.txt\")\ntqdm.write(f\"üìä T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\")\ntqdm.write(f\"üìä Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:41:42.942485Z","iopub.execute_input":"2025-05-03T13:41:42.943011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CODE V·∫º C√ÅC S∆† ƒê·ªí TABNET**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"tabnet_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_46features_tabnet.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_46features_tabnet.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_46features_tabnet.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_46features_tabnet.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_46features_tabnet.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_46features_tabnet.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_46features_tabnet.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_46features_tabnet.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_46features_tabnet.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho TabNet (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ ch·ª©a 150 epoch\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i) - GI·ªÆ NGUY√äN\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss (gi·ªØ nguy√™n nh∆∞ ban ƒë·∫ßu)\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i) - THAY ƒê·ªîI\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\n# Thu h·∫πp kho·∫£ng Y ƒë·ªÉ l√†m r√µ s·ª± bi·∫øn thi√™n, nh∆∞ng v·∫´n bao qu√°t to√†n b·ªô d·ªØ li·ªáu\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05  # Gi·∫£m padding ƒë·ªÉ thu h·∫πp kho·∫£ng Y\n# Ch·ªçn kho·∫£ng Y sao cho t·∫≠p trung v√†o v√πng dao ƒë·ªông ch√≠nh (88% ƒë·∫øn 94.5%) nh∆∞ng v·∫´n hi·ªÉn th·ªã to√†n b·ªô d·ªØ li·ªáu\nax2.set_ylim(86, acc_max + padding)  # C·ªë ƒë·ªãnh gi·ªõi h·∫°n d∆∞·ªõi ·ªü 86% ƒë·ªÉ t·∫≠p trung v√†o v√πng dao ƒë·ªông ch√≠nh\nax2.set_yticks(np.linspace(86, acc_max + padding, 8))  # TƒÉng s·ªë l∆∞·ª£ng nh√£n Y ƒë·ªÉ th·∫•y r√µ bi·∫øn thi√™n\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"TabNet: Learning Curves (8 Labels, 46 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_tabnet_8labels_46features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"TabNet: Confusion Matrix (Test, 8 Labels, 46 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_tabnet_8labels_46features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"TabNet: ROC Curves (8 Labels, 46 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_tabnet_8labels_46features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"TabNet: PCA 3D Visualization (8 Labels, 46 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_tabnet_8labels_46features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 64\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]\n\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (64,) or (n_samples, 74).\")\n\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"TabNet: Feature Importance (8 Labels, 46 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_tabnet_8labels_46features_150epochs.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T15:33:32.587576Z","iopub.execute_input":"2025-05-03T15:33:32.588129Z","iopub.status.idle":"2025-05-03T15:33:41.432156Z","shell.execute_reply.started":"2025-05-03T15:33:32.588102Z","shell.execute_reply":"2025-05-03T15:33:41.431458Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CODE TEST TABNET_FUZZY**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom xgboost import XGBClassifier\nimport joblib\nimport pickle\nimport os\nfrom tqdm import tqdm\nimport time\nfrom torch.cuda.amp import autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d, TabNet\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\ndef entmax15(x, dim=-1):\n    x = F.softmax(x * 1.5, dim=dim)\n    return x\n\nclass TabNet(nn.Module):\n    def __init__(self, input_dim, num_classes, n_d=64, n_a=64, n_steps=5, gamma=1.3, lambda_sparse=5e-4):\n        super(TabNet, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.n_d = n_d\n        self.n_a = n_a\n        self.n_steps = n_steps\n        self.gamma = gamma\n        self.lambda_sparse = lambda_sparse\n\n        # BatchNorm ƒë·∫ßu v√†o\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n\n        # L·ªõp FC ban ƒë·∫ßu\n        self.initial_fc = nn.Linear(input_dim, n_d + n_a)\n        nn.init.xavier_normal_(self.initial_fc.weight)\n        nn.init.zeros_(self.initial_fc.bias)\n\n        # C√°c l·ªõp ch√∫ √Ω v√† quy·∫øt ƒë·ªãnh\n        self.attention_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(n_a, input_dim),\n                nn.BatchNorm1d(input_dim),\n                nn.ReLU()\n            ) for _ in range(n_steps)\n        ])\n        self.decision_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, n_d),\n                nn.BatchNorm1d(n_d),\n                nn.ReLU(),\n                nn.Dropout(0.1)  # ƒê·ªìng b·ªô v·ªõi dropout c·ªßa AutoInt\n            ) for _ in range(n_steps)\n        ])\n\n        # L·ªõp ƒë·∫ßu ra\n        self.fc_output = nn.Linear(n_d * n_steps, num_classes)\n        nn.init.xavier_normal_(self.fc_output.weight)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        prior = torch.ones_like(x)\n        outputs = []\n        sparsity_loss = 0\n        masks = []\n\n        for step in range(self.n_steps):\n            att = self.initial_fc(x)\n            att_d, att_a = att[:, :self.n_d], att[:, self.n_d:]\n            mask = self.attention_layers[step](att_a)\n            mask = entmax15(mask, dim=1)\n            \n            entropy = -torch.sum(mask * torch.log(mask + 1e-8), dim=1)\n            sparsity_loss += torch.mean(entropy) / self.n_steps / self.input_dim\n            masks.append(mask)\n\n            prior = prior * (self.gamma - mask)\n            masked_x = x * mask\n            out = self.decision_layers[step](masked_x)\n            outputs.append(out)\n\n        combined = torch.cat(outputs, dim=1)\n        output = self.fc_output(combined)\n        return output, sparsity_loss, masks\n\n# H√†m √°nh x·∫° nh√£n\ndef change_label(df):\n    mapping = {\n        'DDoS-ICMP_Flood': 'DDoS', 'DDoS-UDP_Flood': 'DDoS', 'DDoS-TCP_Flood': 'DDoS',\n        'DDoS-PSHACK_Flood': 'DDoS', 'DDoS-SYN_Flood': 'DDoS', 'DDoS-RSTFINFlood': 'DDoS',\n        'DDoS-SynonymousIP_Flood': 'DDoS', 'DDoS-ICMP_Fragmentation': 'DDoS',\n        'DDoS-UDP_Fragmentation': 'DDoS', 'DDoS-ACK_Fragmentation': 'DDoS',\n        'DDoS-HTTP_Flood': 'DDoS', 'DDoS-SlowLoris': 'DDoS',\n        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n        'DictionaryBruteForce': 'BruteForce',\n        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n        'BenignTraffic': 'BENIGN'\n    }\n    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])\n    return df\n\n# Danh s√°ch 30 ƒë·∫∑c tr∆∞ng ƒë√£ ch·ªçn\nselected_features = [\n    'IAT', 'Tot size', 'Max', 'Tot sum', 'Magnitue', 'AVG', 'Min', 'Header_Length', \n    'Protocol Type', 'rst_count', 'Weight', 'Number', 'Variance', 'Std', 'Radius', \n    'Covariance', 'Duration', 'urg_count', 'flow_duration', 'Rate', 'Srate', 'TCP', \n    'ack_flag_number', 'syn_count', 'HTTPS', 'ack_count', 'syn_flag_number', 'ICMP', \n    'fin_count', 'UDP'\n]\n\n# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu t·ª´ file CSV\ntest_file = \"/kaggle/input/cic-iot-2023/part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\nprint(\"‚úÖ ƒêang t·∫£i d·ªØ li·ªáu t·ª´:\", test_file)\ndf_test = pd.read_csv(test_file)\n\n# Ki·ªÉm tra v√† √°nh x·∫° nh√£n\nunique_labels_before = df_test['label'].unique()\ndf_test = change_label(df_test)\nunique_labels_after = df_test['label'].unique()\nvalid_labels = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\nif not all(label in valid_labels for label in unique_labels_after):\n    raise ValueError(f\"‚ùå Nh√£n kh√¥ng ƒë∆∞·ª£c √°nh x·∫° ƒë√∫ng: {unique_labels_after}\")\nprint(f\"Nh√£n tr∆∞·ªõc √°nh x·∫°: {unique_labels_before}\")\nprint(f\"Nh√£n sau √°nh x·∫°: {unique_labels_after}\")\n\n# Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i\nmissing_features = [f for f in selected_features if f not in df_test.columns]\nif missing_features:\n    raise ValueError(f\"‚ùå C√°c ƒë·∫∑c tr∆∞ng sau kh√¥ng c√≥ trong d·ªØ li·ªáu: {missing_features}\")\n\n# Ch·ªçn 30 ƒë·∫∑c tr∆∞ng\nX_test = df_test[selected_features].values\nY_test = df_test['label'].values\n\n# T·∫£i label encoder\ntry:\n    with open(f\"{output_dir}/label_encoder_8labels.pkl\", 'rb') as f:\n        label_encoder = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i label encoder t·ª´:\", f\"{output_dir}/label_encoder_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i label encoder: {str(e)}\")\n\n# M√£ h√≥a nh√£n\nY_test_encoded = label_encoder.transform(Y_test)\nlabel_names = label_encoder.classes_\nexpected_label_map = {'BENIGN': 0, 'BruteForce': 1, 'DDoS': 2, 'DoS': 3, 'Mirai': 4, 'Recon': 5, 'Spoofing': 6, 'Web-based': 7}\nif not all(label_names[i] == label for label, i in expected_label_map.items()):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: √Ånh x·∫° nh√£n kh√¥ng kh·ªõp v·ªõi k·ª≥ v·ªçng: {label_names}\")\nprint(\"‚úÖ Nh√£n ƒë√£ m√£ h√≥a:\", label_names)\n\n# X·ª≠ l√Ω gi√° tr·ªã thi·∫øu b·∫±ng KNNImputer\ntry:\n    with open(f\"{output_dir}/imputer_8labels.pkl\", 'rb') as f:\n        imputer = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i imputer t·ª´:\", f\"{output_dir}/imputer_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i imputer: {str(e)}\")\nX_test_imputed = imputer.transform(X_test)\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng RobustScaler\ntry:\n    with open(f\"{output_dir}/scaler_8labels.pkl\", 'rb') as f:\n        scaler = pickle.load(f)\n    print(\"‚úÖ ƒê√£ t·∫£i scaler t·ª´:\", f\"{output_dir}/scaler_8labels.pkl\")\nexcept Exception as e:\n    raise FileNotFoundError(f\"‚ùå L·ªói khi t·∫£i scaler: {str(e)}\")\nX_test_scaled = scaler.transform(X_test_imputed)\nprint(\"‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu test\")\n\n# H√†m t·∫°o ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost\ndef convert_to_fuzzy_features_xgb(X_test, n_features=30, n_labels=8):\n    X_test_fuzzy = []\n    \n    # L·∫∑p qua t·ª´ng ƒë·∫∑c tr∆∞ng\n    for i in tqdm(range(n_features), desc=\"Processing features for fuzzy features\"):\n        X_test_feature = X_test[:, i].reshape(-1, 1)\n        \n        # T·∫£i m√¥ h√¨nh XGBoost ƒë√£ l∆∞u\n        try:\n            xgb = joblib.load(f\"{output_dir}/xgb_feature_{i}.joblib\")\n        except Exception as e:\n            print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh XGBoost cho ƒë·∫∑c tr∆∞ng {i}: {str(e)}\")\n            raise\n        \n        # D·ª± ƒëo√°n x√°c su·∫•t\n        test_probs = xgb.predict_proba(X_test_feature)\n        \n        # ƒê·∫£m b·∫£o ƒë·ªß 8 nh√£n\n        if test_probs.shape[1] < n_labels:\n            missing_labels = n_labels - test_probs.shape[1]\n            test_probs = np.pad(test_probs, ((0, 0), (0, missing_labels)), mode='constant')\n        \n        X_test_fuzzy.append(test_probs)\n    \n    # Chuy·ªÉn th√†nh ma tr·∫≠n [n_samples, n_features * n_labels]\n    X_test_fuzzy = np.concatenate(X_test_fuzzy, axis=1)\n    return X_test_fuzzy\n\n# T√≠nh ƒë·∫∑c tr∆∞ng fuzzy\nprint(\"üîÑ T√≠nh ƒë·∫∑c tr∆∞ng fuzzy b·∫±ng XGBoost...\")\nstart_time = time.time()\nX_test_fuzzy = convert_to_fuzzy_features_xgb(X_test_scaled, n_features=30, n_labels=8)\nprint(f\"‚úÖ Shape c·ªßa X_test_fuzzy: {X_test_fuzzy.shape}\")\nprint(f\"‚è± Th·ªùi gian t√≠nh fuzzy: {time.time() - start_time:.2f}s\")\n\n# Ki·ªÉm tra gi√° tr·ªã nan/inf\nprint(f\"X_test_fuzzy nan: {np.any(np.isnan(X_test_fuzzy))}\")\nprint(f\"X_test_fuzzy inf: {np.any(np.isinf(X_test_fuzzy))}\")\n\n# Ki·ªÉm tra x√°c su·∫•t fuzzy\nprint(\"M·∫´u x√°c su·∫•t fuzzy (5 m·∫´u ƒë·∫ßu ti√™n, ƒë·∫∑c tr∆∞ng 0):\")\nprint(X_test_fuzzy[:5, :8])\nprint(\"T·ªïng x√°c su·∫•t m·ªói m·∫´u:\", X_test_fuzzy[:5, :8].sum(axis=1))\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_test_tensor = torch.tensor(X_test_fuzzy, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# T·∫£i m√¥ h√¨nh TabNet ƒë√£ hu·∫•n luy·ªán\ninput_dim = X_test_fuzzy.shape[1]  # 240 (30 features * 8 labels)\nmodel = TabNet(input_dim=input_dim, num_classes=8, n_d=64, n_a=64, n_steps=5, lambda_sparse=5e-4).to(device)\nmodel_path = f\"{results_dir}/tabnet_8labels_fuzzy_xgb.pth\"\ntry:\n    model.load_state_dict(torch.load(model_path, weights_only=True))\n    print(f\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ {model_path}\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}\")\n    raise\n\n# Test m√¥ h√¨nh\nmodel.eval()\ntabnet_test_preds = []\ntabnet_test_labels = []\ntabnet_test_probs = []\ntabnet_test_features = []\ntabnet_test_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing TabNet\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            tabnet_test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            tabnet_test_labels.extend(Y_batch.cpu().numpy())\n            tabnet_test_probs.extend(probs.cpu().numpy())\n            tabnet_test_features.extend(outputs.detach().cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                tabnet_test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n\n# Chuy·ªÉn th√†nh numpy array\ntabnet_test_preds = np.array(tabnet_test_preds)\ntabnet_test_labels = np.array(tabnet_test_labels)\ntabnet_test_probs = np.array(tabnet_test_probs)\ntabnet_test_features = np.array(tabnet_test_features)\n\n# T√≠nh ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ v√† theo t·ª´ng nh√£n\ntabnet_overall_accuracy = accuracy_score(tabnet_test_labels, tabnet_test_preds) * 100\ntabnet_classification_rep = classification_report(tabnet_test_labels, tabnet_test_preds, target_names=label_names, digits=4)\n\n# T√≠nh confusion matrix\ntabnet_cm = confusion_matrix(tabnet_test_labels, tabnet_test_preds)\nprint(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {tabnet_cm.shape}\")\nif tabnet_cm.shape != (8, 8):\n    print(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {tabnet_cm.shape}\")\n\n# In k·∫øt qu·∫£\nprint(\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test (TabNet):\")\nprint(f\"ƒê·ªô ch√≠nh x√°c t·ªïng th·ªÉ: {tabnet_overall_accuracy:.2f}%\")\nprint(\"\\nB√°o c√°o ph√¢n lo·∫°i theo t·ª´ng nh√£n:\")\nprint(tabnet_classification_rep)\nprint(f\"Confusion Matrix:\\n{tabnet_cm}\")\n\n# L∆∞u k·∫øt qu·∫£ v·ªõi t√™n file kh√°c ƒë·ªÉ tr√°nh tr√πng\nnp.save(f\"{results_dir}/tabnet_test_preds_8labels.npy\", tabnet_test_preds)\nnp.save(f\"{results_dir}/tabnet_test_labels_8labels.npy\", tabnet_test_labels)\nnp.save(f\"{results_dir}/tabnet_test_probs_8labels.npy\", tabnet_test_probs)\nnp.save(f\"{results_dir}/tabnet_test_features_8labels.npy\", tabnet_test_features)\nif tabnet_test_masks:\n    shapes = [mask.shape for mask in tabnet_test_masks]\n    if len(set(shapes)) == 1:\n        tabnet_avg_mask = np.mean(np.stack(tabnet_test_masks, axis=0), axis=(0, 1))\n    else:\n        print(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc mask kh√¥ng ƒë·ªìng nh·∫•t: {shapes}\")\n        tabnet_avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    tabnet_avg_mask = np.zeros((batch_size, input_dim))\nnp.save(f\"{results_dir}/tabnet_feature_importance_8labels.npy\", tabnet_avg_mask)\nnp.save(f\"{results_dir}/tabnet_confusion_matrix_8labels.npy\", tabnet_cm)\nprint(f\"üì¶ ƒê√£ l∆∞u d·ª± ƒëo√°n, nh√£n th·ª±c t·∫ø, x√°c su·∫•t, ƒë·∫∑c tr∆∞ng, t·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng v√† confusion matrix t·∫°i {results_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:04:43.409645Z","iopub.execute_input":"2025-04-24T09:04:43.410245Z","iopub.status.idle":"2025-04-24T09:04:53.989525Z","shell.execute_reply.started":"2025-04-24T09:04:43.410215Z","shell.execute_reply":"2025-04-24T09:04:53.988847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **M√î H√åNH NODE-GAM FUZZY**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.cuda.amp import GradScaler, autocast\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# FocalLoss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# FeatureSelector\nclass FeatureSelector(nn.Module):\n    def __init__(self, input_dim):\n        super(FeatureSelector, self).__init__()\n        self.importance_weights = nn.Parameter(torch.ones(input_dim) * 0.1)\n        \n    def forward(self, x):\n        importance = torch.sigmoid(self.importance_weights)\n        importance = importance / (importance.sum() + 1e-6)\n        mask = importance.unsqueeze(0)\n        return x * mask\n\n# ObliviousDecisionTree\nclass ObliviousDecisionTree(nn.Module):\n    def __init__(self, embed_dim, depth, input_dim):\n        super(ObliviousDecisionTree, self).__init__()\n        self.depth = depth\n        self.num_leaves = 2 ** depth\n        self.input_dim = input_dim\n        \n        self.thresholds = nn.Parameter(torch.randn(depth, input_dim) * 0.1)\n        self.feature_weights = nn.Parameter(torch.randn(depth, input_dim) * 0.1)\n        self.attention = nn.Parameter(torch.randn(input_dim) * 0.1)\n        self.leaf_projection = nn.Linear(embed_dim, self.num_leaves)\n        \n        nn.init.xavier_normal_(self.thresholds, gain=0.1)\n        nn.init.xavier_normal_(self.feature_weights, gain=0.1)\n        nn.init.xavier_normal_(self.leaf_projection.weight, gain=0.1)\n        nn.init.zeros_(self.leaf_projection.bias)\n        nn.init.normal_(self.attention, mean=0.0, std=0.1)\n\n    def forward(self, x, input_features):\n        batch_size = x.size(0)\n        \n        attention_weights = torch.sigmoid(self.attention)\n        attention_weights = attention_weights / (attention_weights.sum() + 1e-6)\n        selected_features = input_features * attention_weights.unsqueeze(0)\n        \n        scores = torch.matmul(selected_features, self.feature_weights.t())\n        scores = scores + self.thresholds.sum(dim=-1).unsqueeze(0)\n        decisions = torch.sigmoid(scores)\n        \n        leaf_indices = torch.zeros(batch_size, device=x.device, dtype=torch.long)\n        for d in range(self.depth):\n            leaf_indices = leaf_indices * 2 + (decisions[:, d] > 0.5).long()\n        \n        leaf_probs = torch.zeros(batch_size, self.num_leaves, device=x.device)\n        leaf_probs.scatter_(1, leaf_indices.unsqueeze(-1), 1.0)\n        \n        out = self.leaf_projection(x)\n        out = F.softmax(out, dim=-1) * leaf_probs\n        return out\n\n# NODEGAM\nclass NODEGAM(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, num_trees=10, depth=6, num_layers=2, dropout=0.1):\n        super(NODEGAM, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.num_trees = num_trees\n        self.depth = depth\n        self.num_layers = num_layers\n        self.dropout = dropout\n\n        self.bn = nn.BatchNorm1d(input_dim)\n        self.feature_selector = FeatureSelector(input_dim)\n        self.feature_dim = 16\n        self.feature_nets = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(1, self.feature_dim),\n                nn.ReLU(),\n                nn.Dropout(dropout),\n                nn.Linear(self.feature_dim, self.feature_dim),\n                nn.ReLU(),\n                nn.Dropout(dropout)\n            ) for _ in range(input_dim)\n        ])\n\n        self.concat_dim = self.feature_dim * input_dim\n        self.feature_projection = nn.Linear(self.concat_dim, embed_dim)\n        self.tree_layers = nn.ModuleList([\n            nn.ModuleList([\n                ObliviousDecisionTree(embed_dim, depth, input_dim)\n                for _ in range(num_trees)\n            ]) for _ in range(num_layers)\n        ])\n        self.tree_projections = nn.ModuleList([\n            nn.Linear(2**depth, embed_dim) for _ in range(num_layers)\n        ])\n        self.tree_weights = nn.ParameterList([\n            nn.Parameter(torch.ones(num_trees) / num_trees) for _ in range(num_layers)\n        ])\n        self.layer_norms = nn.ModuleList([nn.LayerNorm(embed_dim) for _ in range(num_layers)])\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        self.importance_layer = nn.Linear(embed_dim, input_dim)\n\n        for net in self.feature_nets:\n            for layer in net:\n                if isinstance(layer, nn.Linear):\n                    nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')\n                    if layer.bias is not None:\n                        nn.init.zeros_(layer.bias)\n        nn.init.kaiming_normal_(self.feature_projection.weight, nonlinearity='relu')\n        nn.init.zeros_(self.feature_projection.bias)\n        for proj in self.tree_projections:\n            nn.init.kaiming_normal_(proj.weight, nonlinearity='relu')\n            nn.init.zeros_(proj.bias)\n        nn.init.kaiming_normal_(self.fc_output.weight, nonlinearity='relu')\n        nn.init.zeros_(self.fc_output.bias)\n        nn.init.kaiming_normal_(self.importance_layer.weight, nonlinearity='relu')\n        nn.init.zeros_(self.importance_layer.bias)\n\n    def forward(self, x):\n        input_features = torch.clamp(self.bn(x), -50, 50)\n        input_features = self.feature_selector(input_features)\n        feature_outputs = []\n        for i in range(self.input_dim):\n            feat = input_features[:, i:i+1]\n            feat_out = self.feature_nets[i](feat)\n            if torch.isnan(feat_out).any():\n                tqdm.write(f\"NaN detected in feature_nets[{i}]\")\n            feature_outputs.append(feat_out)\n        x = torch.cat(feature_outputs, dim=1)\n        x = self.feature_projection(x)\n        if torch.isnan(x).any():\n            tqdm.write(\"NaN detected in feature_projection\")\n\n        for layer_idx in range(self.num_layers):\n            tree_outputs = []\n            for tree in self.tree_layers[layer_idx]:\n                tree_out = tree(x, input_features)\n                tree_outputs.append(tree_out)\n            tree_weights = F.softmax(self.tree_weights[layer_idx], dim=0)\n            tree_out = torch.stack(tree_outputs, dim=1)\n            tree_out = torch.einsum('bnt,n->bt', tree_out, tree_weights)\n            tree_out = self.tree_projections[layer_idx](tree_out)\n            x = self.layer_norms[layer_idx](x + tree_out)\n            if torch.isnan(x).any():\n                tqdm.write(f\"NaN detected in tree_layer[{layer_idx}]\")\n\n        output = self.fc_output(x)\n        importance = torch.sigmoid(self.importance_layer(x))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(\"NaN detected in output or sparsity_loss\")\n\n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu combined (74 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} ch·ª©a gi√° tr·ªã NaN ho·∫∑c Inf\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape c·ªßa d·ªØ li·ªáu\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)\n\n# DataLoader\nbatch_size = 4096\naccumulation_steps = 8\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\ntorch.cuda.empty_cache()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = NODEGAM(input_dim=input_dim, num_classes=8, embed_dim=192, num_trees=10, depth=6, num_layers=2, dropout=0.1).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler()\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Hu·∫•n luy·ªán NODE-GAM v·ªõi Focal + Sparsity Loss (8 Nh√£n, 46 ƒê·∫∑c tr∆∞ng)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Batch Hu·∫•n luy·ªán (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for batch_idx, (X_batch, Y_batch) in enumerate(pbar):\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            \n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n                loss = total_loss / accumulation_steps\n            \n            if torch.isnan(loss) or torch.isinf(loss):\n                tqdm.write(f\"Ph√°t hi·ªán NaN ho·∫∑c Inf trong total_loss t·∫°i batch {batch_idx+1}\")\n                continue\n            \n            scaler.scale(loss).backward()\n            \n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=False)\n            \n            if (batch_idx + 1) % accumulation_steps == 0:\n                scaler.unscale_(optimizer)\n                scaler.step(optimizer)\n                scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if batch_idx < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {batch_idx+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, total_loss, focal_loss, loss\n            torch.cuda.empty_cache()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # ƒê√°nh gi√°\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"ƒê√°nh gi√° (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n                with autocast():\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n                \n                del X_batch, Y_batch, outputs, sparsity_loss, focal_loss, loss\n                torch.cuda.empty_cache()\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (ƒê√°nh gi√°): {pred_counts}\")\n    tqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\n    tqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n h√†ng ƒë·∫ßu: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/nodegam_8labels_46features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/nodegam_8labels_46features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/nodegam_8labels_46features_final.pth\")\n\n# L∆∞u d·ªØ li·ªáu ƒë√°nh gi√°\nnp.save(f\"{results_dir}/train_losses_8labels_46features_nodegam.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_nodegam.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_nodegam.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_nodegam.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_nodegam.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_nodegam.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_nodegam.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_nodegam.npy\", np.array(epoch_times))\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_nodegam.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_nodegam.npy\", np.array([avg_epoch_time]))\n\n# Ki·ªÉm tra tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/nodegam_8labels_46features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Ki·ªÉm tra\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            with autocast():\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(X_batch.cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n            \n            del X_batch, Y_batch, outputs, sparsity_loss, masks, probs\n            torch.cuda.empty_cache()\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Ma tr·∫≠n nh·∫ßm l·∫´n kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n:\\n{cm}\")\ntqdm.write(f\"C√°c c·∫∑p nh·∫ßm l·∫´n: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"C·∫£nh b√°o: K√≠ch th∆∞·ªõc mask kh√¥ng ƒë·ªìng nh·∫•t: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_nodegam.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_nodegam.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_nodegam.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_nodegam.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_46features_nodegam.npy\", avg_mask)\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/NODE-GAM_8labels_46features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán NODE-GAM (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/NODE-GAM_8labels_46features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Ma tr·∫≠n nh·∫ßm l·∫´n shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"T·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T15:05:55.892700Z","iopub.execute_input":"2025-04-30T15:05:55.893007Z","iopub.status.idle":"2025-04-30T15:24:01.982701Z","shell.execute_reply.started":"2025-04-30T15:05:55.892985Z","shell.execute_reply":"2025-04-30T15:24:01.981706Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**V·∫º C√ÅC S∆† ƒê·ªí**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"nodegam_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_46features_nodegam.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_46features_nodegam.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_46features_nodegam.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_46features_nodegam.npy\")\n    val_f1_scores = np.load(f\"{results_dir}/val_f1_scores_8labels_46features_nodegam.npy\")\n    val_precisions = np.load(f\"{results_dir}/val_precisions_8labels_46features_nodegam.npy\")\n    val_recalls = np.load(f\"{results_dir}/val_recalls_8labels_46features_nodegam.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_46features_nodegam.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_46features_nodegam.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_46features_nodegam.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_46features_nodegam.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_46features_nodegam.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho NODE-GAM (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\nprint(f\"Val F1 - Min: {val_f1_scores.min():.4f}, Max: {val_f1_scores.max():.4f}, Mean: {val_f1_scores.mean():.4f}\")\nprint(f\"Val Precision - Min: {val_precisions.min():.4f}, Max: {val_precisions.max():.4f}, Mean: {val_precisions.mean():.4f}\")\nprint(f\"Val Recall - Min: {val_recalls.min():.4f}, Max: {val_recalls.max():.4f}, Mean: {val_recalls.mean():.4f}\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2.5)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2.5)\nax1.set_xlabel(\"Epoch\", fontsize=14)\nax1.set_ylabel(\"Loss\", fontsize=14)\nax1.set_title(\"Learning Curve - Loss\", fontsize=16)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, max(1, num_epochs // 5)))\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=10)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=10)\nax1.legend(loc=\"upper right\", fontsize=12)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2.5)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2.5)\nax2.set_xlabel(\"Epoch\", fontsize=14)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=14)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=16)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, max(1, num_epochs // 5)))\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.1\nax2.set_ylim(acc_min - padding, acc_max + padding)\nax2.set_yticks(np.linspace(acc_min - padding, acc_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=10)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=10)\nax2.legend(loc=\"lower right\", fontsize=12)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"NODE-GAM: Learning Curves (8 Labels, 46 Features)\\n{num_epochs} Epochs\", \n             fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_nodegam_8labels_46features.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"NODE-GAM: Confusion Matrix (Test, 8 Labels, 46 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_nodegam_8labels_46features.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"NODE-GAM: ROC Curves (8 Labels, 46 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_nodegam_8labels_46features.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"NODE-GAM: PCA 3D Visualization (8 Labels, 46 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_nodegam_8labels_46features.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 74\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]  # Kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ v·ªÅ ƒë·∫∑c tr∆∞ng\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω shape c·ªßa feature_importance\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (74,) or (n_samples, 74).\")\n\n# Ki·ªÉm tra NaN ho·∫∑c Inf trong feature_importance\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"NODE-GAM: Feature Importance (8 Labels, 46 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_nodegam_8labels_46features.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")\nprint(f\"Val F1 trung b√¨nh: {avg_f1:.4f}\")\nprint(f\"Val Precision trung b√¨nh: {avg_precision:.4f}\")\nprint(f\"Val Recall trung b√¨nh: {avg_recall:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:47:21.982282Z","iopub.execute_input":"2025-04-24T16:47:21.982999Z","iopub.status.idle":"2025-04-24T16:48:07.693472Z","shell.execute_reply.started":"2025-04-24T16:47:21.982972Z","shell.execute_reply":"2025-04-24T16:48:07.692625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nfrom IPython.display import FileLink\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\nprocessed_data_dir = \"/kaggle/working/processed_data\"\nresults_dir = \"/kaggle/working/results\"\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c processed_data\n# processed_zip = \"/kaggle/working/processed_data.zip\"\n# with zipfile.ZipFile(processed_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(processed_data_dir):\n#         for file in files:\n#             file_path = os.path.join(root, file)\n#             # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n#             zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c results\nresults_zip = \"/kaggle/working/results.zip\"\nwith zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(results_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n            zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# Hi·ªÉn th·ªã li√™n k·∫øt t·∫£i xu·ªëng\n# print(\"T·∫£i xu·ªëng processed_data.zip:\")\n# display(FileLink(\"processed_data.zip\"))\n\nprint(\"T·∫£i xu·ªëng results.zip:\")\ndisplay(FileLink(\"results.zip\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:03:36.896997Z","iopub.execute_input":"2025-04-24T09:03:36.897319Z","iopub.status.idle":"2025-04-24T09:03:38.776135Z","shell.execute_reply.started":"2025-04-24T09:03:36.897296Z","shell.execute_reply":"2025-04-24T09:03:38.775464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FT-TRAN**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.amp import GradScaler, autocast\n\n# ƒê·ªãnh nghƒ©a c√°c l·ªõp FocalLoss, GhostBN1d v√† FTTransformerPure\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\nclass GhostBN1d(nn.Module):\n    def __init__(self, num_features, virtual_batch_size=512):\n        super(GhostBN1d, self).__init__()\n        self.bn = nn.BatchNorm1d(num_features)\n        self.virtual_batch_size = virtual_batch_size\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        if batch_size <= self.virtual_batch_size:\n            return self.bn(x)\n        n_splits = batch_size // self.virtual_batch_size\n        x_splits = torch.split(x, self.virtual_batch_size, dim=0)\n        x_splits = [self.bn(split) for split in x_splits[:n_splits]]\n        remaining = batch_size % self.virtual_batch_size\n        if remaining > 0:\n            x_splits.append(self.bn(x[-remaining:]))\n        return torch.cat(x_splits, dim=0)\n\nclass FTTransformerPure(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=192, num_layers=6, num_heads=4, ff_hidden_dim=768, dropout=0.1):\n        super(FTTransformerPure, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.ff_hidden_dim = ff_hidden_dim\n        self.dropout = dropout\n\n        self.bn = GhostBN1d(input_dim, virtual_batch_size=512)\n        self.feature_embed = nn.Linear(input_dim, embed_dim)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_hidden_dim, \n            dropout=dropout, activation='gelu', batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        self.ln = nn.LayerNorm(embed_dim)\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n        self.importance_layer = nn.Linear(embed_dim, input_dim)\n\n        nn.init.xavier_normal_(self.feature_embed.weight, gain=0.1)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.xavier_normal_(self.importance_layer.weight, gain=0.1)\n        nn.init.zeros_(self.feature_embed.bias)\n        nn.init.zeros_(self.fc_output.bias)\n        nn.init.zeros_(self.importance_layer.bias)\n\n    def forward(self, x):\n        x = torch.clamp(self.bn(x), -50, 50)\n        x = self.feature_embed(x)\n        x = self.ln(x)\n        x = self.transformer(x.unsqueeze(1)).squeeze(1)\n        embeddings = self.ln(x)\n        output = self.fc_output(embeddings)\n\n        importance = torch.sigmoid(self.importance_layer(embeddings))\n        importance = torch.clamp(importance, min=1e-6, max=1-1e-6)\n        sparsity_loss = torch.mean(-importance * torch.log(importance) - (1-importance) * torch.log(1-importance + 1e-6))\n        masks = [importance]\n\n        if torch.isnan(output).any() or torch.isnan(sparsity_loss).any():\n            tqdm.write(f\"NaN detected in output or sparsity_loss\")\n        \n        return output, sparsity_loss, masks\n\n# T·∫°o th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu combined (74 ƒë·∫∑c tr∆∞ng)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    FURTHER = \"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu combined (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\"\n    tqdm.write(FURTHER)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra v√† x·ª≠ l√Ω NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Ki·ªÉm tra shape c·ªßa d·ªØ li·ªáu\nif X_train_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_train_combined to have 74 features, but got {X_train_combined.shape[1]}\")\nif X_val_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_val_combined to have 74 features, but got {X_val_combined.shape[1]}\")\nif X_test_combined.shape[1] != 74:\n    raise ValueError(f\"Expected X_test_combined to have 74 features, but got {X_test_combined.shape[1]}\")\n\n# Chu·∫©n h√≥a d·ªØ li·ªáu\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra NaN/Inf sau chu·∫©n h√≥a\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined v·∫´n ch·ª©a NaN ho·∫∑c Inf sau chu·∫©n h√≥a!\")\n\n# Chuy·ªÉn th√†nh tensor (gi·ªØ tr√™n CPU ƒë·ªÉ tr√°nh l·ªói pin_memory)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)  # Gi·ªØ tr√™n CPU\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long)      # Gi·ªØ tr√™n CPU\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32)      # Gi·ªØ tr√™n CPU\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long)          # Gi·ªØ tr√™n CPU\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)    # Gi·ªØ tr√™n CPU\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long)        # Gi·ªØ tr√™n CPU\n\n# Ki·ªÉm tra NaN/Inf trong tensor\nif torch.isnan(X_train_tensor).any() or torch.isinf(X_train_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è X_train_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(Y_train_tensor).any() or torch.isinf(Y_train_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è Y_train_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(X_val_tensor).any() or torch.isinf(X_val_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è X_val_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(Y_val_tensor).any() or torch.isinf(Y_val_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è Y_val_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(X_test_tensor).any() or torch.isinf(X_test_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è X_test_tensor ch·ª©a NaN ho·∫∑c Inf!\")\nif torch.isnan(Y_test_tensor).any() or torch.isinf(Y_test_tensor).any():\n    tqdm.write(\"‚ö†Ô∏è Y_test_tensor ch·ª©a NaN ho·∫∑c Inf!\")\n\n# DataLoader v·ªõi pin_memory=True\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n# T√≠nh alpha cho Focal Loss\ncls_num_list = np.bincount(Y_train_encoded)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\ntorch.cuda.empty_cache()\n\n# Kh·ªüi t·∫°o m√¥ h√¨nh v√† t·ªëi ∆∞u h√≥a\ninput_dim = X_train_combined.shape[1]  # 74\nmodel = FTTransformerPure(\n    input_dim=input_dim,\n    num_classes=8,\n    embed_dim=192,\n    num_layers=6,\n    num_heads=4,\n    ff_hidden_dim=768,\n    dropout=0.1\n).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler('cuda')\n\n# H√†m loss t·ªïng h·ª£p\ndef combined_loss(outputs, Y_batch, criterion_focal, sparsity_loss):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    total_loss = focal_loss + 5e-4 * sparsity_loss\n    return total_loss, focal_loss, sparsity_loss\n\n# Tham s·ªë hu·∫•n luy·ªán\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# Ph√¢n t√≠ch nh·∫ßm l·∫´n\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Hu·∫•n luy·ªán\ntqdm.write(\"Training FT-Transformer with Focal + Sparsity Loss (8 Labels, 74 Features)\")\ntorch.manual_seed(44)\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for X_batch, Y_batch in pbar:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            optimizer.zero_grad(set_to_none=True)\n            \n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                total_loss, focal_loss, sparsity_loss = combined_loss(\n                    outputs, Y_batch, criterion_focal, sparsity_loss\n                )\n            \n            if torch.isnan(total_loss) or torch.isinf(total_loss):\n                tqdm.write(f\"NaN or Inf detected in total_loss at batch {pbar.n+1}\")\n                continue\n            \n            scaler.scale(total_loss).backward()\n            scaler.unscale_(optimizer)\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=False)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                mask_sum = masks[-1].sum(dim=1).mean() if masks else 0.0\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Sparsity Loss: {sparsity_loss.item():.4f}, \"\n                          f\"Grad Norm: {grad_norm:.4f}, Mask sum: {mask_sum:.4f}\")\n            \n            # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n            del X_batch, Y_batch, outputs, sparsity_loss, masks, total_loss, focal_loss\n            torch.cuda.empty_cache()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n                with autocast('cuda'):\n                    outputs, sparsity_loss, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                    loss = focal_loss + 5e-4 * sparsity_loss\n                running_val_loss += loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n                \n                # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n                del X_batch, Y_batch, outputs, sparsity_loss, focal_loss, loss\n                torch.cuda.empty_cache()\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/fttransformer_8labels_74features.pth\")\n        tqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh t·ªët nh·∫•t t·∫°i epoch {epoch+1}\")\n\n# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\ntorch.save(model.state_dict(), f\"{results_dir}/fttransformer_8labels_74features_final.pth\")\ntqdm.write(f\"üì¶ L∆∞u m√¥ h√¨nh cu·ªëi c√πng t·∫°i {results_dir}/fttransformer_8labels_74features_final.pth\")\n\n# Test tr√™n t·∫≠p test\nmodel.load_state_dict(torch.load(f\"{results_dir}/fttransformer_8labels_74features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\ntest_masks = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device, non_blocking=True), Y_batch.to(device, non_blocking=True)\n            with autocast('cuda'):\n                outputs, sparsity_loss, masks = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n            if X_batch.size(0) == batch_size:\n                test_masks.extend([mask.detach().cpu().numpy() for mask in masks])\n            pbar_test.set_postfix({\"test_loss\": f\"{sparsity_loss.item():.4f}\"})\n            \n            # Gi·∫£i ph√≥ng b·ªô nh·ªõ\n            del X_batch, Y_batch, outputs, sparsity_loss, masks, probs\n            torch.cuda.empty_cache()\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\nf1 = f1_score(test_labels, test_preds, average='weighted')\nprecision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\nrecall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç K√≠ch th∆∞·ªõc Confusion Matrix (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è C·∫£nh b√°o: K√≠ch th∆∞·ªõc Confusion Matrix kh√¥ng ph·∫£i (8,8), l√† {cm.shape}\")\n\ntqdm.write(f\"\\nüìä K·∫øt qu·∫£ tr√™n t·∫≠p test:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\ntqdm.write(f\"Ph√¢n b·ªë d·ª± ƒëo√°n (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"Top 5 c·∫∑p nh·∫ßm l·∫´n nhi·ªÅu nh·∫•t: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\nif test_masks:\n    shapes = [mask.shape for mask in test_masks]\n    if len(set(shapes)) == 1:\n        avg_mask = np.mean(np.stack(test_masks, axis=0), axis=(0, 1))\n    else:\n        tqdm.write(f\"Warning: Inconsistent mask shapes: {shapes}\")\n        avg_mask = np.zeros((batch_size, input_dim))\nelse:\n    avg_mask = np.zeros((batch_size, input_dim))\n\n# L∆∞u k·∫øt qu·∫£ v·ªõi t√™n file ph·∫£n √°nh 74 ƒë·∫∑c tr∆∞ng\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_74features_fttransformer.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_74features_fttransformer.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_74features_fttransformer.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_74features_fttransformer.npy\", test_features)\nnp.save(f\"{results_dir}/feature_importance_8labels_74features_fttransformer.npy\", avg_mask)\nnp.save(f\"{results_dir}/train_losses_8labels_74features_fttransformer.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_74features_fttransformer.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_74features_fttransformer.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_74features_fttransformer.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_74features_fttransformer.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_74features_fttransformer.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_74features_fttransformer.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_74features_fttransformer.npy\", np.array(epoch_times))\n\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_74features_fttransformer.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_74features_fttransformer.npy\", np.array([avg_epoch_time]))\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/FTTransformer_8labels_74features.txt\", 'w') as f:\n    f.write(\"K·∫øt qu·∫£ hu·∫•n luy·ªán FT-Transformer (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Train Accuracy trung b√¨nh: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Val Accuracy trung b√¨nh: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"T·ªïng th·ªùi gian hu·∫•n luy·ªán: {total_time:.2f}s\\n\")\n    f.write(f\"F1 trung b√¨nh: {avg_f1:.4f}\\n\")\n    f.write(f\"Precision trung b√¨nh: {avg_precision:.4f}\\n\")\n    f.write(f\"Recall trung b√¨nh: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {results_dir}/FTTransformer_8labels_74features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")\ntqdm.write(f\"Feature Importance shape: {avg_mask.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T06:15:02.036646Z","iopub.execute_input":"2025-05-01T06:15:02.036927Z","iopub.status.idle":"2025-05-01T08:56:12.870822Z","shell.execute_reply.started":"2025-05-01T06:15:02.036908Z","shell.execute_reply":"2025-05-01T08:56:12.870018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"fttransformer_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_74features_fttransformer.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_74features_fttransformer.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_74features_fttransformer.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_74features_fttransformer.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_74features_fttransformer.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_74features_fttransformer.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_74features_fttransformer.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_74features_fttransformer.npy\")\n    feature_importance = np.load(f\"{results_dir}/feature_importance_8labels_74features_fttransformer.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho FT-Transformer (8 nh√£n, 74 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ ch·ª©a 150 epoch\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))  # Hi·ªÉn th·ªã nh√£n c√°ch m·ªói 25 epoch\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05\nax2.set_ylim(acc_min - padding, acc_max + padding)\nax2.set_yticks(np.linspace(acc_min - padding, acc_max + padding, 8))\n\n# T√≠nh gi√° tr·ªã trung b√¨nh v√† th√™m ƒë∆∞·ªùng ngang\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"FT-Transformer: Learning Curves (8 Labels, 74 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\n\n# ƒêi·ªÅu ch·ªânh kho·∫£ng c√°ch gi·ªØa hai bi·ªÉu ƒë·ªì\nplt.subplots_adjust(wspace=0.3)\n\n# L∆∞u bi·ªÉu ƒë·ªì\nplt.savefig(f\"{plots_dir}/learning_curves_fttransformer_8labels_74features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"FT-Transformer: Confusion Matrix (Test, 8 Labels, 74 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_fttransformer_8labels_74features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"FT-Transformer: ROC Curves (8 Labels, 74 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_fttransformer_8labels_74features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"FT-Transformer: PCA 3D Visualization (8 Labels, 74 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_fttransformer_8labels_74features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Feature Importance\nprint(f\"Shape of feature_importance: {feature_importance.shape}\")\ninput_dim = 74\nfeature_labels = [f\"Feature_{i}\" for i in range(input_dim)]\n\nif len(feature_importance.shape) == 1 and feature_importance.shape[0] == input_dim:\n    feature_importance = feature_importance.astype(np.float64)\nelif len(feature_importance.shape) == 2 and feature_importance.shape[1] == input_dim:\n    print(f\"‚ö†Ô∏è Shape of feature_importance is {feature_importance.shape}. Taking mean across samples.\")\n    feature_importance = np.mean(feature_importance, axis=0).astype(np.float64)\nelse:\n    raise ValueError(f\"Unexpected shape of feature_importance: {feature_importance.shape}. Expected (74,) or (n_samples, 74).\")\n\nif np.any(np.isnan(feature_importance)) or np.any(np.isinf(feature_importance)):\n    print(\"‚ö†Ô∏è feature_importance contains NaN or Inf values. Replacing with 0.\")\n    feature_importance = np.nan_to_num(feature_importance, nan=0.0, posinf=0.0, neginf=0.0)\n\nplt.figure(figsize=(12, 6))\nplt.bar(range(input_dim), feature_importance, tick_label=feature_labels)\nplt.xlabel(\"Feature\", fontsize=12)\nplt.ylabel(\"Importance Score\", fontsize=12)\nplt.title(f\"FT-Transformer: Feature Importance (8 Labels, 74 Features)\", fontsize=14)\nplt.xticks(rotation=90, ha=\"right\", fontsize=8)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/feature_importance_fttransformer_8labels_74features_150epochs.png\")\nplt.show()\n\n# 7Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 8Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T08:56:19.858166Z","iopub.execute_input":"2025-05-01T08:56:19.858551Z","iopub.status.idle":"2025-05-01T08:56:29.010329Z","shell.execute_reply.started":"2025-05-01T08:56:19.858531Z","shell.execute_reply":"2025-05-01T08:56:29.009628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **FT-TRAN M·ªöI L√ÄM T·ªêI N√à**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\nimport time\nfrom tqdm import tqdm\nimport os\nfrom torch.amp import GradScaler, autocast\nimport gc\nimport uuid\n\n# FocalLoss (retained from original, suitable for imbalanced classification)\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=3.5, alpha=None, reduction='mean', label_smoothing=0.1):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n        self.label_smoothing = label_smoothing\n\n    def forward(self, inputs, targets):\n        inputs = torch.clamp(inputs, -100, 100)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n        pt = torch.exp(-ce_loss)\n        loss = ((1 - pt) ** self.gamma) * ce_loss\n        if self.alpha is not None:\n            alpha_t = self.alpha[targets]\n            loss = alpha_t * loss\n        if self.reduction == 'mean':\n            return loss.mean()\n        return loss\n\n# FTTransformerPure (adjusted for 8 labels and 46 features)\nclass FTTransformerPure(nn.Module):\n    def __init__(self, input_dim, num_classes, embed_dim=64, num_layers=2, num_heads=4, ff_hidden_dim=128, dropout=0.1):\n        super(FTTransformerPure, self).__init__()\n        self.input_dim = input_dim\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.ff_hidden_dim = ff_hidden_dim\n        self.dropout = dropout\n\n        # BatchNorm standard (aligned with TabR's GhostBN1d for consistency)\n        self.bn = nn.BatchNorm1d(input_dim)\n        # Feature embedding (adjusted for smaller embed_dim to match TabR)\n        self.feature_embed = nn.Linear(input_dim, embed_dim)\n        # Transformer Encoder (parameters aligned with TabR)\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_hidden_dim, \n            dropout=dropout, activation='gelu', batch_first=True\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n        # LayerNorm after Transformer\n        self.ln = nn.LayerNorm(embed_dim)\n        # Classification output\n        self.fc_output = nn.Linear(embed_dim, num_classes)\n\n        # Initialize parameters (aligned with TabR initialization)\n        nn.init.xavier_normal_(self.feature_embed.weight, gain=0.1)\n        nn.init.xavier_normal_(self.fc_output.weight, gain=0.1)\n        nn.init.zeros_(self.feature_embed.bias)\n        nn.init.zeros_(self.fc_output.bias)\n\n    def forward(self, x, labels=None):\n        # BatchNorm\n        x = torch.clamp(self.bn(x), -50, 50)\n        # Embedding\n        x = self.feature_embed(x)\n        x = self.ln(x)\n        # Transformer Encoder\n        transformer_out = self.transformer(x.unsqueeze(1)).squeeze(1)\n        # LayerNorm\n        embeddings = self.ln(transformer_out)\n        # Output\n        output = self.fc_output(embeddings)\n\n        if torch.isnan(output).any():\n            tqdm.write(f\"NaN detected in output\")\n        \n        return output, torch.tensor(0.0, device=x.device)  # No sparsity_loss, consistent with original\n\n# Create directories for data and results\noutput_dir = \"processed_data\"\nos.makedirs(output_dir, exist_ok=True)\nresults_dir = \"results\"\nos.makedirs(results_dir, exist_ok=True)\n\n# Load data combined (46 features, 8 labels, matching TabR)\ntry:\n    X_train_combined = np.load(f\"{output_dir}/X_train_combined_8labels_46features.npy\")\n    Y_train_encoded = np.load(f\"{output_dir}/Y_train_encoded_8labels_46features.npy\")\n    X_val_combined = np.load(f\"{output_dir}/X_val_combined_8labels_46features.npy\")\n    Y_val_encoded = np.load(f\"{output_dir}/Y_val_encoded_8labels_46features.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    Y_test_encoded = np.load(f\"{output_dir}/Y_test_encoded_8labels_46features.npy\")\n    tqdm.write(f\"‚úÖ Loaded data combined (46 features, 8 labels)\")\n    tqdm.write(f\"X_train_combined shape: {X_train_combined.shape}\")\n    tqdm.write(f\"X_val_combined shape: {X_val_combined.shape}\")\n    tqdm.write(f\"X_test_combined shape: {X_test_combined.shape}\")\nexcept Exception as e:\n    tqdm.write(f\"‚ùå Error loading data: {str(e)}\")\n    raise\n\n# Check and clean NaN/Inf\ndef check_and_clean_data(X, name):\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        tqdm.write(f\"‚ö†Ô∏è {name} contains NaN or Inf values\")\n        X = np.nan_to_num(X, nan=0.0, posinf=1e6, neginf=-1e6)\n    return X\n\nX_train_combined = check_and_clean_data(X_train_combined, \"X_train_combined\")\nX_val_combined = check_and_clean_data(X_val_combined, \"X_val_combined\")\nX_test_combined = check_and_clean_data(X_test_combined, \"X_test_combined\")\n\n# Normalize data\ntry:\n    X_train_combined = (X_train_combined - X_train_combined.mean(axis=0)) / (X_train_combined.std(axis=0) + 1e-6)\n    X_val_combined = (X_val_combined - X_val_combined.mean(axis=0)) / (X_val_combined.std(axis=0) + 1e-6)\n    X_test_combined = (X_test_combined - X_test_combined.mean(axis=0)) / (X_test_combined.std(axis=0) + 1e-6)\nexcept Exception as e:\n    tqdm.write(f\"‚ùå Error normalizing data: {str(e)}\")\n    raise\n\n# Check NaN/Inf after normalization\nif np.any(np.isnan(X_train_combined)) or np.any(np.isinf(X_train_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_train_combined still contains NaN or Inf after normalization!\")\nif np.any(np.isnan(X_val_combined)) or np.any(np.isinf(X_val_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_val_combined still contains NaN or Inf after normalization!\")\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    tqdm.write(\"‚ö†Ô∏è X_test_combined still contains NaN or Inf after normalization!\")\n\n# Convert to tensors\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntqdm.write(f\"Device: {device}\")\nX_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\nY_train_tensor = torch.tensor(Y_train_encoded, dtype=torch.long).to(device)\nX_val_tensor = torch.tensor(X_val_combined, dtype=torch.float32).to(device)\nY_val_tensor = torch.tensor(Y_val_encoded, dtype=torch.long).to(device)\nX_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\nY_test_tensor = torch.tensor(Y_test_encoded, dtype=torch.long).to(device)\ndel X_train_combined, X_val_combined, X_test_combined, Y_train_encoded, Y_val_encoded, Y_test_encoded\ngc.collect()\ntorch.cuda.empty_cache()\n\n# DataLoader\nbatch_size = 4096\ntrain_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\ntest_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Calculate alpha for Focal Loss\ncls_num_list = np.bincount(Y_train_tensor.cpu().numpy(), minlength=8)\nalpha = torch.FloatTensor(1.0 / (cls_num_list + 1e-6)).to(device)\nalpha /= alpha.sum()\n\n# Initialize model\ninput_dim = X_train_tensor.shape[1]  # 46\nmodel = FTTransformerPure(\n    input_dim=input_dim,\n    num_classes=8,\n    embed_dim=64,      # Aligned with TabR\n    num_layers=2,      # Aligned with TabR\n    num_heads=4,       # Aligned with TabR\n    ff_hidden_dim=128, # Aligned with TabR\n    dropout=0.1\n).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\ncriterion_focal = FocalLoss(gamma=3.5, alpha=alpha, label_smoothing=0.1)\nscaler = GradScaler('cuda')\n\n# Combined loss function (no sparsity_loss)\ndef combined_loss(outputs, Y_batch, criterion_focal):\n    focal_loss = criterion_focal(outputs, Y_batch)\n    return focal_loss, focal_loss\n\n# Training parameters\nnum_epochs = 150\nbest_f1 = 0\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1_scores = []\nval_precisions = []\nval_recalls = []\nepoch_times = []\n\n# List of 8 labels (from TabR)\nlabel_names = ['DDoS', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n\n# Analyze confusion matrix\ndef analyze_confusion_matrix(cm, label_names):\n    confusion_pairs = []\n    for i in range(len(label_names)):\n        for j in range(i + 1, len(label_names)):\n            if cm[i, j] > 0 or cm[j, i] > 0:\n                confusion_pairs.append((label_names[i], label_names[j], cm[i, j] + cm[j, i]))\n    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n    return confusion_pairs[:5]\n\n# Training with gradient accumulation\ntqdm.write(\"Starting training FT-Transformer Pure (8 labels, 46 features)\")\ntorch.manual_seed(44)\naccumulation_steps = 16\nfor epoch in range(num_epochs):\n    epoch_start_time = time.time()\n    model.train()\n    running_loss = 0\n    train_preds = []\n    train_labels = []\n    optimizer.zero_grad()\n    with tqdm(train_loader, desc=f\"Training Batch (Epoch {epoch+1}/{num_epochs})\", unit=\"batch\", leave=False) as pbar:\n        for i, (X_batch, Y_batch) in enumerate(pbar):\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast('cuda'):\n                outputs, _ = model(X_batch)\n                total_loss, focal_loss = combined_loss(outputs, Y_batch, criterion_focal)\n            \n            if torch.isnan(total_loss):\n                tqdm.write(f\"NaN detected in total_loss at batch {pbar.n+1}\")\n                continue\n            \n            scaler.scale(total_loss / accumulation_steps).backward()\n            grad_norm = 0.0\n            if (i + 1) % accumulation_steps == 0:\n                scaler.unscale_(optimizer)\n                grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n            \n            running_loss += total_loss.item()\n            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            train_labels.extend(Y_batch.cpu().numpy())\n            pbar.set_postfix({\"loss\": f\"{total_loss.item():.4f}\"})\n            \n            if pbar.n < 5 and epoch == 0:\n                tqdm.write(f\"Batch {pbar.n+1}: Outputs max/min: {outputs.max():.4f}/{outputs.min():.4f}, \"\n                          f\"Focal Loss: {focal_loss.item():.4f}, Grad Norm: {grad_norm:.4f}\")\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = accuracy_score(train_labels, train_preds) * 100\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    running_val_loss = 0\n    val_preds = []\n    val_labels = []\n    with torch.no_grad():\n        with tqdm(val_loader, desc=f\"Validation (Epoch {epoch+1})\", unit=\"batch\", leave=False) as pbar_val:\n            for X_batch, Y_batch in pbar_val:\n                X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n                with autocast('cuda'):\n                    outputs, _ = model(X_batch)\n                    focal_loss = criterion_focal(outputs, Y_batch)\n                running_val_loss += focal_loss.item()\n                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n                val_labels.extend(Y_batch.cpu().numpy())\n                pbar_val.set_postfix({\"val_loss\": f\"{focal_loss.item():.4f}\"})\n\n    val_loss = running_val_loss / len(val_loader)\n    val_acc = accuracy_score(val_labels, val_preds) * 100\n    f1 = f1_score(val_labels, val_preds, average='weighted')\n    precision = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='weighted')\n    cm = confusion_matrix(val_labels, val_preds)\n\n    pred_counts = np.bincount(val_preds, minlength=8)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1_scores.append(f1)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    epoch_time = time.time() - epoch_start_time\n    epoch_times.append(epoch_time)\n\n    confusion_pairs = analyze_confusion_matrix(cm, label_names)\n    tqdm.write(f\"‚úÖ Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Time: {epoch_time:.2f}s\")\n    tqdm.write(f\"Prediction distribution (Validation): {pred_counts}\")\n    tqdm.write(f\"Confusion Matrix:\\n{cm}\")\n    tqdm.write(f\"Top confusion pairs: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(model.state_dict(), f\"{results_dir}/fttransformer_pure_8labels_46features.pth\")\n        tqdm.write(f\"üì¶ Saved best model at epoch {epoch+1}\")\n\n# Save final model\ntorch.save(model.state_dict(), f\"{results_dir}/fttransformer_pure_8labels_46features_final.pth\")\ntqdm.write(f\"üì¶ Saved final model at {results_dir}/fttransformer_pure_8labels_46features_final.pth\")\n\n# Test on test set\nmodel.load_state_dict(torch.load(f\"{results_dir}/fttransformer_pure_8labels_46features.pth\", weights_only=True))\nmodel.eval()\ntest_preds = []\ntest_labels = []\ntest_features = []\ntest_probs = []\nwith torch.no_grad():\n    with tqdm(test_loader, desc=\"Testing\", unit=\"batch\") as pbar_test:\n        for X_batch, Y_batch in pbar_test:\n            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n            with autocast('cuda'):\n                outputs, _ = model(X_batch)\n                probs = torch.softmax(outputs, dim=1)\n            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n            test_labels.extend(Y_batch.cpu().numpy())\n            test_features.extend(outputs.detach().cpu().numpy())\n            test_probs.extend(probs.cpu().numpy())\n\ntest_preds = np.array(test_preds)\ntest_labels = np.array(test_labels)\ntest_features = np.array(test_features)\ntest_probs = np.array(test_probs)\n\npred_counts = np.bincount(test_preds, minlength=8)\ntest_acc = accuracy_score(test_labels, test_preds) * 100\ntest_f1 = f1_score(test_labels, test_preds, average='weighted')\ntest_precision = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='weighted')\ncm = confusion_matrix(test_labels, test_preds)\n\nconfusion_pairs = analyze_confusion_matrix(cm, label_names)\n\ntqdm.write(f\"üîç Confusion Matrix size (Test): {cm.shape}\")\nif cm.shape != (8, 8):\n    tqdm.write(f\"‚ö†Ô∏è Warning: Confusion Matrix size is not (8,8), it is {cm.shape}\")\n\ntqdm.write(f\"\\nüìä Test set results:\")\ntqdm.write(f\"Test Acc: {test_acc:.2f}%, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")\ntqdm.write(f\"Prediction distribution (Test): {pred_counts}\")\ntqdm.write(f\"Confusion Matrix:\\n{cm}\")\ntqdm.write(f\"Confusion pairs: {[(pair[0], pair[1], pair[2]) for pair in confusion_pairs]}\")\n\n# Save results\nnp.save(f\"{results_dir}/confusion_matrix_test_8labels_46features_fttransformer_pure.npy\", cm)\nnp.save(f\"{results_dir}/test_probs_8labels_46features_fttransformer_pure.npy\", test_probs)\nnp.save(f\"{results_dir}/test_labels_8labels_46features_fttransformer_pure.npy\", test_labels)\nnp.save(f\"{results_dir}/test_features_8labels_46features_fttransformer_pure.npy\", test_features)\nnp.save(f\"{results_dir}/train_losses_8labels_46features_fttransformer_pure.npy\", np.array(train_losses))\nnp.save(f\"{results_dir}/train_accuracies_8labels_46features_fttransformer_pure.npy\", np.array(train_accuracies))\nnp.save(f\"{results_dir}/val_losses_8labels_46features_fttransformer_pure.npy\", np.array(val_losses))\nnp.save(f\"{results_dir}/val_accuracies_8labels_46features_fttransformer_pure.npy\", np.array(val_accuracies))\nnp.save(f\"{results_dir}/val_f1_scores_8labels_46features_fttransformer_pure.npy\", np.array(val_f1_scores))\nnp.save(f\"{results_dir}/val_precisions_8labels_46features_fttransformer_pure.npy\", np.array(val_precisions))\nnp.save(f\"{results_dir}/val_recalls_8labels_46features_fttransformer_pure.npy\", np.array(val_recalls))\nnp.save(f\"{results_dir}/epoch_times_8labels_46features_fttransformer_pure.npy\", np.array(epoch_times))\n\ntotal_time = sum(epoch_times)\navg_epoch_time = total_time / len(epoch_times) if epoch_times else 0\nnp.save(f\"{results_dir}/total_time_8labels_46features_fttransformer_pure.npy\", np.array([total_time]))\nnp.save(f\"{results_dir}/avg_epoch_time_8labels_46features_fttransformer_pure.npy\", np.array([avg_epoch_time]))\n\navg_train_loss = np.mean(train_losses)\navg_val_loss = np.mean(val_losses)\navg_train_acc = np.mean(train_accuracies)\navg_val_acc = np.mean(val_accuracies)\navg_f1 = np.mean(val_f1_scores)\navg_precision = np.mean(val_precisions)\navg_recall = np.mean(val_recalls)\n\nwith open(f\"{results_dir}/FTTransformer_pure_8labels_46features.txt\", 'w') as f:\n    f.write(\"Training results FT-Transformer Pure (8 labels, 46 features)\\n\")\n    f.write(\"=====================\\n\")\n    f.write(f\"Average Train Loss: {avg_train_loss:.4f}\\n\")\n    f.write(f\"Average Val Loss: {avg_val_loss:.4f}\\n\")\n    f.write(f\"Average Train Accuracy: {avg_train_acc:.2f}%\\n\")\n    f.write(f\"Average Val Accuracy: {avg_val_acc:.2f}%\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n    f.write(f\"Total training time: {total_time:.2f}s\\n\")\n    f.write(f\"Average F1: {avg_f1:.4f}\\n\")\n    f.write(f\"Average Precision: {avg_precision:.4f}\\n\")\n    f.write(f\"Average Recall: {avg_recall:.4f}\\n\")\ntqdm.write(f\"üìù Saved results to {results_dir}/FTTransformer_pure_8labels_46features.txt\")\n\ntqdm.write(f\"Train Losses shape: {np.array(train_losses).shape}\")\ntqdm.write(f\"Train Accuracies shape: {np.array(train_accuracies).shape}\")\ntqdm.write(f\"Val Losses shape: {np.array(val_losses).shape}\")\ntqdm.write(f\"Val Accuracies shape: {np.array(val_accuracies).shape}\")\ntqdm.write(f\"Val F1 Scores shape: {np.array(val_f1_scores).shape}\")\ntqdm.write(f\"Val Precisions shape: {np.array(val_precisions).shape}\")\ntqdm.write(f\"Val Recalls shape: {np.array(val_recalls).shape}\")\ntqdm.write(f\"Epoch Times shape: {np.array(epoch_times).shape}\")\ntqdm.write(f\"Average Epoch Time: {avg_epoch_time:.2f}s\")\ntqdm.write(f\"Confusion Matrix shape: {cm.shape}\")\ntqdm.write(f\"Test Probs shape: {np.array(test_probs).shape}\")\ntqdm.write(f\"Test Labels shape: {np.array(test_labels).shape}\")\ntqdm.write(f\"Test Features shape: {np.array(test_features).shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T15:50:03.770570Z","iopub.execute_input":"2025-05-03T15:50:03.770996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, roc_curve\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu\noutput_dir = \"processed_data\"\nresults_dir = \"results\"\nplots_dir = os.path.join(results_dir, \"fttransformer_plots\")\nos.makedirs(plots_dir, exist_ok=True)\n\n# T·∫£i d·ªØ li·ªáu v·ªõi ki·ªÉm tra l·ªói\ntry:\n    train_losses = np.load(f\"{results_dir}/train_losses_8labels_46features_fttransformer_pure.npy\")\n    val_losses = np.load(f\"{results_dir}/val_losses_8labels_46features_fttransformer_pure.npy\")\n    train_accuracies = np.load(f\"{results_dir}/train_accuracies_8labels_46features_fttransformer_pure.npy\")\n    val_accuracies = np.load(f\"{results_dir}/val_accuracies_8labels_46features_fttransformer_pure.npy\")\n    epoch_times = np.load(f\"{results_dir}/epoch_times_8labels_46features_fttransformer_pure.npy\")\n    test_labels = np.load(f\"{results_dir}/test_labels_8labels_46features_fttransformer_pure.npy\")\n    test_probs = np.load(f\"{results_dir}/test_probs_8labels_46features_fttransformer_pure.npy\")\n    X_test_combined = np.load(f\"{output_dir}/X_test_combined_8labels_46features.npy\")\n    cm = np.load(f\"{results_dir}/confusion_matrix_test_8labels_46features_fttransformer_pure.npy\")\n    print(f\"‚úÖ ƒê√£ t·∫£i t·∫•t c·∫£ d·ªØ li·ªáu c·∫ßn thi·∫øt cho FT-Transformer Pure (8 nh√£n, 46 ƒë·∫∑c tr∆∞ng)\")\nexcept Exception as e:\n    print(f\"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {str(e)}\")\n    raise\n\n# Ki·ªÉm tra shape v√† gi√° tr·ªã\nnum_epochs = len(train_losses)\nif num_epochs != 150:\n    print(f\"‚ö†Ô∏è S·ªë epoch ({num_epochs}) kh√¥ng kh·ªõp v·ªõi 150. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.\")\nif train_losses.shape != (num_epochs,) or val_losses.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_losses ho·∫∑c val_losses kh√¥ng ƒë√∫ng: {train_losses.shape}, {val_losses.shape}\")\nif train_accuracies.shape != (num_epochs,) or val_accuracies.shape != (num_epochs,):\n    raise ValueError(f\"Shape c·ªßa train_accuracies ho·∫∑c val_accuracies kh√¥ng ƒë√∫ng: {train_accuracies.shape}, {val_accuracies.shape}\")\nif np.any(train_losses < 0) or np.any(val_losses < 0) or np.any(np.isnan(train_losses)) or np.any(np.isnan(val_losses)):\n    raise ValueError(\"train_losses ho·∫∑c val_losses ch·ª©a gi√° tr·ªã √¢m ho·∫∑c NaN\")\nif np.any(train_accuracies < 0) or np.any(train_accuracies > 100) or np.any(val_accuracies < 0) or np.any(val_accuracies > 100):\n    raise ValueError(\"train_accuracies ho·∫∑c val_accuracies ch·ª©a gi√° tr·ªã ngo√†i kho·∫£ng [0, 100]\")\nif test_probs.shape[1] != 8 or np.any(test_probs < 0) or np.any(test_probs > 1):\n    raise ValueError(f\"test_probs ph·∫£i c√≥ shape (n_samples, 8) v√† gi√° tr·ªã trong [0, 1], nh∆∞ng c√≥ shape {test_probs.shape}\")\nif cm.shape != (8, 8):\n    raise ValueError(f\"Confusion matrix ph·∫£i c√≥ shape (8, 8), nh∆∞ng c√≥ shape {cm.shape}\")\n\n# Ki·ªÉm tra s·ªë m·∫´u ƒë·ªìng b·ªô\nn_samples = len(test_labels)\nif X_test_combined.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong X_test_combined ({X_test_combined.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    X_test_combined = X_test_combined[:n_samples]\nif test_probs.shape[0] != n_samples:\n    print(f\"‚ö†Ô∏è S·ªë m·∫´u trong test_probs ({test_probs.shape[0]}) kh√¥ng kh·ªõp v·ªõi test_labels ({n_samples}). C·∫Øt b·ªõt ƒë·ªÉ ƒë·ªìng b·ªô.\")\n    test_probs = test_probs[:n_samples]\n\n# √Ånh x·∫° nh√£n cho b√†i to√°n 8 nh√£n\nlabel_map = {\n    0: 'DDoS',\n    1: 'DoS',\n    2: 'Recon',\n    3: 'Spoofing',\n    4: 'BruteForce',\n    5: 'Web-based',\n    6: 'Mirai',\n    7: 'BENIGN'\n}\nclass_names = [label_map[i] for i in range(len(label_map))]\n\n# Ki·ªÉm tra d·ªØ li·ªáu Loss v√† Accuracy ƒë·ªÉ debug\nprint(f\"Train Loss - Min: {train_losses.min():.4f}, Max: {train_losses.max():.4f}, Mean: {train_losses.mean():.4f}\")\nprint(f\"Val Loss - Min: {val_losses.min():.4f}, Max: {val_losses.max():.4f}, Mean: {val_losses.mean():.4f}\")\nprint(f\"Train Accuracy - Min: {train_accuracies.min():.2f}%, Max: {train_accuracies.max():.2f}%, Mean: {train_accuracies.mean():.2f}%\")\nprint(f\"Val Accuracy - Min: {val_accuracies.min():.2f}%, Max: {val_accuracies.max():.2f}%, Mean: {val_accuracies.mean():.2f}%\")\n\n# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\nepochs = np.arange(num_epochs)\ntrain_accuracies_plot = train_accuracies\nval_accuracies_plot = val_accuracies\ntrain_losses_plot = train_losses\nval_losses_plot = val_losses\nepochs_mapped = epochs\n\n# 1Ô∏è‚É£ & 2Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì Loss v√† Accuracy c·∫°nh nhau\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n\n# Bi·ªÉu ƒë·ªì Loss (b√™n tr√°i)\nax1.plot(epochs_mapped, train_losses_plot, label=\"Train Loss\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax1.plot(epochs_mapped, val_losses_plot, label=\"Val Loss\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax1.set_xlabel(\"Epoch\", fontsize=12)\nax1.set_ylabel(\"Loss\", fontsize=12)\nax1.set_title(\"Learning Curve - Loss\", fontsize=14)\nax1.grid(True, linestyle=\"--\", alpha=0.7)\nax1.set_xlim(0, num_epochs - 1)\nax1.set_xticks(np.arange(0, num_epochs, 25))\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Loss\nloss_min = min(train_losses_plot.min(), val_losses_plot.min())\nloss_max = max(train_losses_plot.max(), val_losses_plot.max())\nloss_range = loss_max - loss_min\npadding = loss_range * 0.1\nax1.set_ylim(loss_min - padding, loss_max + padding)\nax1.set_yticks(np.linspace(loss_min - padding, loss_max + padding, 6))\n\n# Th√™m ƒë∆∞·ªùng trung b√¨nh\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\nax1.axhline(y=avg_train_loss, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Loss ({avg_train_loss:.4f})\")\nax1.axhline(y=avg_val_loss, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Loss ({avg_val_loss:.4f})\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax1.annotate(f\"{train_losses_plot[-1]:.4f}\", \n             (num_epochs-1, train_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax1.annotate(f\"{val_losses_plot[-1]:.4f}\", \n             (num_epochs-1, val_losses_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax1.legend(loc=\"upper right\", fontsize=9)\n\n# Bi·ªÉu ƒë·ªì Accuracy (b√™n ph·∫£i)\nax2.plot(epochs_mapped, train_accuracies_plot, label=\"Train Accuracy\", linestyle=\"-\", color=\"blue\", linewidth=2)\nax2.plot(epochs_mapped, val_accuracies_plot, label=\"Val Accuracy\", linestyle=\"-\", color=\"orange\", linewidth=2)\nax2.set_xlabel(\"Epoch\", fontsize=12)\nax2.set_ylabel(\"Accuracy (%)\", fontsize=12)\nax2.set_title(\"Learning Curve - Accuracy\", fontsize=14)\nax2.grid(True, linestyle=\"--\", alpha=0.7)\nax2.set_xlim(0, num_epochs - 1)\nax2.set_xticks(np.arange(0, num_epochs, 25))\n\n# T·ªëi ∆∞u h√≥a tr·ª•c Y cho Accuracy\nacc_min = min(train_accuracies_plot.min(), val_accuracies_plot.min())\nacc_max = max(train_accuracies_plot.max(), val_accuracies_plot.max())\nacc_range = acc_max - acc_min\npadding = acc_range * 0.05\nax2.set_ylim(86, acc_max + padding)\nax2.set_yticks(np.linspace(86, acc_max + padding, 8))\n\n# Th√™m ƒë∆∞·ªùng trung b√¨nh\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\nax2.axhline(y=avg_train_accuracy, color=\"blue\", linestyle=\"--\", alpha=0.5, label=f\"Avg Train Accuracy ({avg_train_accuracy:.2f}%)\")\nax2.axhline(y=avg_val_accuracy, color=\"orange\", linestyle=\"--\", alpha=0.5, label=f\"Avg Val Accuracy ({avg_val_accuracy:.2f}%)\")\n\n# Th√™m ch√∫ th√≠ch gi√° tr·ªã t·∫°i epoch cu·ªëi\nax2.annotate(f\"{train_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, train_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, 10), ha=\"left\", color=\"blue\", fontsize=9)\nax2.annotate(f\"{val_accuracies_plot[-1]:.2f}%\", \n             (num_epochs-1, val_accuracies_plot[-1]), \n             textcoords=\"offset points\", xytext=(10, -15), ha=\"left\", color=\"orange\", fontsize=9)\nax2.legend(loc=\"lower right\", fontsize=9)\n\n# Th√™m ti√™u ƒë·ªÅ ch√≠nh\nplt.suptitle(f\"FT-Transformer Pure: Learning Curves (8 Labels, 46 Features)\\n{num_epochs} Epochs\", fontsize=16, y=1.05)\nplt.subplots_adjust(wspace=0.3)\nplt.savefig(f\"{plots_dir}/learning_curves_fttransformer_8labels_46features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# 3Ô∏è‚É£ Confusion Matrix\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\ndisp.plot(cmap=\"Blues\", values_format=\"d\", ax=ax, colorbar=True)\nplt.title(f\"FT-Transformer Pure: Confusion Matrix (Test, 8 Labels, 46 Features)\")\nplt.grid(False)\nplt.xticks(rotation=45, ha=\"right\")\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/confusion_matrix_fttransformer_8labels_46features_150epochs.png\")\nplt.show()\n\n# 4Ô∏è‚É£ ROC-AUC (Multi-class, One-vs-Rest)\nplt.figure(figsize=(8, 6))\nfor i in range(8):\n    fpr, tpr, _ = roc_curve(test_labels == i, test_probs[:, i])\n    roc_auc = roc_auc_score(test_labels == i, test_probs[:, i])\n    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.4f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\nplt.xlabel(\"False Positive Rate\", fontsize=12)\nplt.ylabel(\"True Positive Rate\", fontsize=12)\nplt.title(f\"FT-Transformer Pure: ROC Curves (8 Labels, 46 Features, One-vs-Rest)\", fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=10)\nplt.grid(True, linestyle=\"--\", alpha=0.7)\nplt.xlim(0, 1)\nplt.tight_layout()\nplt.savefig(f\"{plots_dir}/roc_curve_fttransformer_8labels_46features_150epochs.png\", bbox_inches=\"tight\")\nplt.show()\n\n# T√≠nh ROC-AUC trung b√¨nh (macro)\nroc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class=\"ovr\", average=\"macro\")\nprint(f\"üìà ROC-AUC Score (Macro, One-vs-Rest): {roc_auc_macro:.4f}\")\n\n# 5Ô∏è‚É£ PCA 3D\nprint(f\"Shape of X_test_combined: {X_test_combined.shape}\")\nn_samples, n_features = X_test_combined.shape\n\nif np.any(np.isnan(X_test_combined)) or np.any(np.isinf(X_test_combined)):\n    print(\"‚ö†Ô∏è X_test_combined contains NaN or Inf values. Cleaning data...\")\n    X_test_combined = np.nan_to_num(X_test_combined, nan=0.0, posinf=1e6, neginf=-1e6)\n\nif n_samples < 3:\n    print(f\"‚ö†Ô∏è Only {n_samples} samples available. Skipping PCA 3D.\")\nelif n_features < 3:\n    print(f\"‚ö†Ô∏è X_test_combined has only {n_features} features (required at least 3 for PCA 3D). Skipping PCA 3D.\")\nelse:\n    max_samples = 10000\n    if n_samples > max_samples:\n        indices = np.random.choice(n_samples, max_samples, replace=False)\n        X_test_combined_reduced = X_test_combined[indices]\n        test_labels_reduced = test_labels[indices]\n        print(f\"Reduced to {max_samples} samples for PCA 3D visualization.\")\n    else:\n        X_test_combined_reduced = X_test_combined\n        test_labels_reduced = test_labels\n\n    pca = PCA(n_components=3)\n    try:\n        pca_result = pca.fit_transform(X_test_combined_reduced)\n        print(f\"PCA transformed shape: {pca_result.shape}\")\n        \n        fig = plt.figure(figsize=(10, 8))\n        ax = fig.add_subplot(111, projection='3d')\n        for label in np.unique(test_labels_reduced):\n            idx = test_labels_reduced == label\n            ax.scatter(pca_result[idx, 0], pca_result[idx, 1], pca_result[idx, 2], \n                       label=label_map[label], alpha=0.7)\n        ax.set_xlabel(\"PC1\", fontsize=12)\n        ax.set_ylabel(\"PC2\", fontsize=12)\n        ax.set_zlabel(\"PC3\", fontsize=12)\n        ax.set_title(f\"FT-Transformer Pure: PCA 3D Visualization (8 Labels, 46 Features)\", fontsize=14)\n        ax.legend(title=\"Classes\")\n        plt.tight_layout()\n        plt.savefig(f\"{plots_dir}/pca_3d_fttransformer_8labels_46features_150epochs.png\")\n        plt.show()\n    except ValueError as e:\n        print(f\"‚ùå PCA failed: {e}\")\n        print(\"Consider increasing the number of samples or features.\")\n\n# 6Ô∏è‚É£ Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh\navg_time = np.mean(epoch_times)\nprint(f\"‚è±Ô∏è Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh m·ªói epoch: {avg_time:.2f} gi√¢y\")\n\n# 7Ô∏è‚É£ In gi√° tr·ªã trung b√¨nh c·ªßa Loss v√† Accuracy\navg_train_loss = np.mean(train_losses_plot)\navg_val_loss = np.mean(val_losses_plot)\navg_train_accuracy = np.mean(train_accuracies_plot)\navg_val_accuracy = np.mean(val_accuracies_plot)\n\nprint(f\"\\nüìä Gi√° tr·ªã trung b√¨nh ({num_epochs} epoch):\")\nprint(f\"Train Loss trung b√¨nh: {avg_train_loss:.4f}\")\nprint(f\"Val Loss trung b√¨nh: {avg_val_loss:.4f}\")\nprint(f\"Train Accuracy trung b√¨nh: {avg_train_accuracy:.2f}%\")\nprint(f\"Val Accuracy trung b√¨nh: {avg_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:57:06.644498Z","iopub.execute_input":"2025-05-03T17:57:06.644776Z","iopub.status.idle":"2025-05-03T17:57:14.167945Z","shell.execute_reply.started":"2025-05-03T17:57:06.644754Z","shell.execute_reply":"2025-05-03T17:57:14.167085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nfrom IPython.display import FileLink\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\nprocessed_data_dir = \"/kaggle/working/processed_data\"\nresults_dir = \"/kaggle/working/results\"\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c processed_data\n# processed_zip = \"/kaggle/working/processed_data.zip\"\n# with zipfile.ZipFile(processed_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(processed_data_dir):\n#         for file in files:\n#             file_path = os.path.join(root, file)\n#             # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n#             zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# T·∫°o file ZIP cho th∆∞ m·ª•c results\nresults_zip = \"/kaggle/working/results.zip\"\nwith zipfile.ZipFile(results_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, dirs, files in os.walk(results_dir):\n        for file in files:\n            file_path = os.path.join(root, file)\n            # Th√™m file v√†o ZIP v·ªõi ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi\n            zipf.write(file_path, os.path.relpath(file_path, \"/kaggle/working\"))\n\n# Hi·ªÉn th·ªã li√™n k·∫øt t·∫£i xu·ªëng\n# print(\"T·∫£i xu·ªëng processed_data.zip:\")\n# display(FileLink(\"processed_data.zip\"))\n\nprint(\"T·∫£i xu·ªëng results.zip:\")\ndisplay(FileLink(\"results.zip\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T17:58:39.143759Z","iopub.execute_input":"2025-05-03T17:58:39.144027Z","iopub.status.idle":"2025-05-03T17:58:42.817147Z","shell.execute_reply.started":"2025-05-03T17:58:39.144008Z","shell.execute_reply":"2025-05-03T17:58:42.816565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **V·∫º L·∫†I C√ÅC S∆† ƒê·ªí**","metadata":{}}]}